Epoch: 2760  loss: 78.69904413005865
Learned parameters: [2.349285688380157, 3.5217786436239518, 5.30811146651829, -2.0637360066436012]
Epoch: 2761  loss: 78.66825450202663
Learned parameters: [2.3491131661228923, 3.5220243939264484, 5.308460032280178, -2.0642134544025024]
Epoch: 2762  loss: 78.63751084255512
Learned parameters: [2.3489407246671594, 3.5222700239216382, 5.3088084330307606, -2.0646906713342537]
Epoch: 2763  loss: 78.60681308597216
Learned parameters: [2.3487683639883454, 3.522515533654145, 5.309156668822867, -2.0651676575213034]
Epoch: 2764  loss: 78.57616116675246
Learned parameters: [2.3485960840587152, 3.522760923169415, 5.309504739704794, -2.0656444130453178]
Epoch: 2765  loss: 78.54555501947756
Learned parameters: [2.348423884850907, 3.5230061925126215, 5.309852645725268, -2.066120937987908]
Epoch: 2766  loss: 78.51499457887172
Learned parameters: [2.3482517663406806, 3.523251341727718, 5.3102003869372805, -2.0665972324311777]
Epoch: 2767  loss: 78.48447977966032
Learned parameters: [2.348079728506422, 3.5234963708579965, 5.310547963397677, -2.0670732964577145]
Epoch: 2768  loss: 78.45401055659482
Learned parameters: [2.3479077713258407, 3.5237412799469854, 5.310895375162356, -2.0675491301498656]
Epoch: 2769  loss: 78.42358684462411
Learned parameters: [2.347735894773697, 3.5239860690391085, 5.311242622283004, -2.0680247335892505]
Epoch: 2770  loss: 78.39320857879517
Learned parameters: [2.3475640988227937, 3.524230738179387, 5.311589704808506, -2.0685001068569675]
Epoch: 2771  loss: 78.36287569424152
Learned parameters: [2.3473923834468566, 3.5244752874125234, 5.311936622789031, -2.068975250034211]
Epoch: 2772  loss: 78.33258812617706
Learned parameters: [2.347220748622209, 3.5247197167823203, 5.312283376278357, -2.069450163202594]
Epoch: 2773  loss: 78.30234580993437
Learned parameters: [2.3470491943266674, 3.524964026332024, 5.312629965332285, -2.069924846443901]
Epoch: 2774  loss: 78.27214868095464
Learned parameters: [2.3468777205370652, 3.5252082161051703, 5.312976390005177, -2.070399299839599]
Epoch: 2775  loss: 78.24199667476037
Learned parameters: [2.3467063272280324, 3.525452286146014, 5.313322650348256, -2.070873523470599]
Epoch: 2776  loss: 78.21188972698508
Learned parameters: [2.3465350143731203, 3.525696236499089, 5.313668746411117, -2.071347517417452]
Epoch: 2777  loss: 78.1818277733849
Learned parameters: [2.3463637819469447, 3.5259400672085097, 5.314014678244754, -2.071821281760787]
Epoch: 2778  loss: 78.15181074981558
Learned parameters: [2.3461926299260636, 3.526183778317659, 5.31436044590277, -2.0722948165814867]
Epoch: 2779  loss: 78.12183859222505
Learned parameters: [2.346021558287858, 3.526427369869613, 5.314706049439839, -2.0727681219604794]
Epoch: 2780  loss: 78.09191123664786
Learned parameters: [2.345850567008696, 3.526670841907755, 5.315051488909126, -2.0732411979783714]
Epoch: 2781  loss: 78.06202861922989
Learned parameters: [2.34567965606333, 3.526914194475971, 5.315396764361435, -2.0737140447153255]
Epoch: 2782  loss: 78.03219067619041
Learned parameters: [2.3455088254260223, 3.5271574276182873, 5.315741875846796, -2.074186662251296]
Epoch: 2783  loss: 78.00239734387058
Learned parameters: [2.3453380750720716, 3.527400541378357, 5.316086823416595, -2.0746590506663325]
Epoch: 2784  loss: 77.97264855871902
Learned parameters: [2.345167404978136, 3.5276435357992306, 5.316431607123943, -2.0751312100406145]
Epoch: 2785  loss: 77.94294425731711
Learned parameters: [2.344996815121219, 3.5278864109236743, 5.316776227022224, -2.075603140454238]
Epoch: 2786  loss: 77.91328437638899
Learned parameters: [2.3448263054774916, 3.5281291667947032, 5.317120683163551, -2.076074841987023]
Epoch: 2787  loss: 77.8836688525424
Learned parameters: [2.344655876022198, 3.5283718034560083, 5.3174649755989165, -2.0765463147185885]
Epoch: 2788  loss: 77.85409762253516
Learned parameters: [2.3444855267302396, 3.5286143209513527, 5.3178091043787195, -2.0770175587283766]
Epoch: 2789  loss: 77.82457062327437
Learned parameters: [2.344315257577207, 3.5288567193242444, 5.318153069554222, -2.0774885740958657]
Epoch: 2790  loss: 77.7950877917591
Learned parameters: [2.3441450685396648, 3.5290989986178403, 5.318496871177946, -2.0779593609006266]
Epoch: 2791  loss: 77.76564906509265
Learned parameters: [2.343974959594443, 3.529341158875171, 5.318840509302671, -2.0784299192221685]
Epoch: 2792  loss: 77.73625438047966
Learned parameters: [2.3438049307177593, 3.5295832001394305, 5.319183983980192, -2.0789002491397626]
Epoch: 2793  loss: 77.70690367522442
Learned parameters: [2.3436349818851006, 3.5298251224540222, 5.319527295261163, -2.0793703507324235]
Epoch: 2794  loss: 77.6775968867012
Learned parameters: [2.343465113071887, 3.5300669258623842, 5.319870443196077, -2.0798402240790814]
Epoch: 2795  loss: 77.64833395238944
Learned parameters: [2.343295324254155, 3.530308610407716, 5.320213427836178, -2.080309869258684]
Epoch: 2796  loss: 77.61911480987004
Learned parameters: [2.343125615408587, 3.530550176132973, 5.320556249233508, -2.0807792863502073]
Epoch: 2797  loss: 77.58993939680819
Learned parameters: [2.3429559865119103, 3.530791623081076, 5.320898907440076, -2.0812484754325427]
Epoch: 2798  loss: 77.56080765099023
Learned parameters: [2.342786437540324, 3.5310329512950314, 5.321241402506983, -2.0817174365843414]
Epoch: 2799  loss: 77.53171951030718
Learned parameters: [2.3426169684695757, 3.5312741608179334, 5.32158373448457, -2.0821861698840474]
Epoch: 2800  loss: 77.5026749127441
Learned parameters: [2.3424475792755457, 3.5315152516927846, 5.321925903423235, -2.082654675410022]
Epoch: 2801  loss: 77.47367379636614
Learned parameters: [2.342278269934647, 3.531756223962372, 5.322267909374017, -2.083122953240629]
Epoch: 2802  loss: 77.4447160993519
Learned parameters: [2.3421090404236784, 3.531997077669285, 5.322609752388358, -2.0835910034541945]
Epoch: 2803  loss: 77.41580175995809
Learned parameters: [2.3419398907193525, 3.5322378128561245, 5.322951432517485, -2.0840588261289303]
Epoch: 2804  loss: 77.38693071654345
Learned parameters: [2.3417708207979526, 3.5324784295655545, 5.32329294981188, -2.0845264213428463]
Epoch: 2805  loss: 77.3581029076041
Learned parameters: [2.341601830635453, 3.5327189278400684, 5.32363430432131, -2.0849937891737205]
Epoch: 2806  loss: 77.32931827180376
Learned parameters: [2.3414329202081614, 3.5329593077221, 5.323975496095961, -2.0854609296993134]
Epoch: 2807  loss: 77.30057674763991
Learned parameters: [2.341264089492937, 3.53319956925415, 5.324316525186905, -2.085927842997472]
Epoch: 2808  loss: 77.27187827380956
Learned parameters: [2.341095338466663, 3.533439712478666, 5.324657391645146, -2.0863945291459545]
Epoch: 2809  loss: 77.2432227891281
Learned parameters: [2.340926667105881, 3.533679737438173, 5.3249980955211065, -2.0868609882223548]
Epoch: 2810  loss: 77.21461023250008
Learned parameters: [2.3407580753868458, 3.5339196441752563, 5.325338636864714, -2.087327220304118]
Epoch: 2811  loss: 77.18604054292021
Learned parameters: [2.3405895632858984, 3.5341594327324404, 5.32567901572593, -2.0877932254686224]
Epoch: 2812  loss: 77.15751365947446
Learned parameters: [2.340421130779739, 3.5343991031520985, 5.326019232155131, -2.08825900379323]
Epoch: 2813  loss: 77.12902952134455
Learned parameters: [2.3402527778453237, 3.5346386554764875, 5.326359286202965, -2.0887245553552662]
Epoch: 2814  loss: 77.10058806779661
Learned parameters: [2.3400845044595466, 3.5348780897478385, 5.3266991779198944, -2.0891898802319417]
Epoch: 2815  loss: 77.07218923821321
Learned parameters: [2.3399163105990293, 3.535117406008416, 5.327038907355884, -2.0896549785003016]
Epoch: 2816  loss: 77.04383297206263
Learned parameters: [2.3397481962402558, 3.5353566043004823, 5.3273784745606045, -2.09011985023726]
Epoch: 2817  loss: 77.01551920888926
Learned parameters: [2.339580161359865, 3.5355956846662404, 5.327717879583884, -2.0905844955196886]
Epoch: 2818  loss: 76.98724788833047
Learned parameters: [2.3394122059347655, 3.5358346471477584, 5.328057122475831, -2.091048914424413]
Epoch: 2819  loss: 76.9590189501229
Learned parameters: [2.3392443299419887, 3.536073491787029, 5.32839620328664, -2.0915131070281894]
Epoch: 2820  loss: 76.93083233410428
Learned parameters: [2.339076533358453, 3.536312218625984, 5.328735122066204, -2.091977073407623]
Epoch: 2821  loss: 76.90268798023715
Learned parameters: [2.338908816160896, 3.5365508277065043, 5.329073878864014, -2.0924408136391492]
Epoch: 2822  loss: 76.87458582854725
Learned parameters: [2.3387411783260723, 3.5367893190704303, 5.329412473729493, -2.0929043277991117]
Epoch: 2823  loss: 76.84652581916524
Learned parameters: [2.3385736198309024, 3.5370276927594664, 5.329750906712174, -2.0933676159637726]
Epoch: 2824  loss: 76.81850789229692
Learned parameters: [2.3384061406524896, 3.5372659488152185, 5.33008917786176, -2.093830678209334]
Epoch: 2825  loss: 76.79053198827742
Learned parameters: [2.338238740767901, 3.5375040872790673, 5.330427287227658, -2.0942935146118344]
Epoch: 2826  loss: 76.76259804757069
Learned parameters: [2.3380714201542223, 3.5377421081925213, 5.330765234859338, -2.094756125247258]
Epoch: 2827  loss: 76.73470601050985
Learned parameters: [2.3379041787884898, 3.537980011597289, 5.331103020806274, -2.095218510191542]
Epoch: 2828  loss: 76.70685581763175
Learned parameters: [2.3377370166475955, 3.5382177975350673, 5.331440645117639, -2.0956806695204975]
Epoch: 2829  loss: 76.67904740959477
Learned parameters: [2.337569933708475, 3.538455466047483, 5.331778107842568, -2.0961426033098496]
Epoch: 2830  loss: 76.6512807271336
Learned parameters: [2.33740292994825, 3.5386930171760476, 5.332115409030357, -2.0966043116352653]
Epoch: 2831  loss: 76.6235557110792
Learned parameters: [2.337236005344199, 3.538930450962165, 5.33245254873043, -2.097065794572349]
Epoch: 2832  loss: 76.59587230235186
Learned parameters: [2.337069159873594, 3.539167767447189, 5.3327895269921, -2.0975270521966083]
Epoch: 2833  loss: 76.56823044196193
Learned parameters: [2.3369023935135873, 3.5394049666724596, 5.333126343864416, -2.0979880845834336]
Epoch: 2834  loss: 76.54063007100612
Learned parameters: [2.336735706241251, 3.5396420486792937, 5.333462999396225, -2.0984488918081086]
Epoch: 2835  loss: 76.51307113067587
Learned parameters: [2.33656909803373, 3.539879013508941, 5.33379949363639, -2.0989094739458527]
Epoch: 2836  loss: 76.48555356223355
Learned parameters: [2.3364025688683325, 3.540115861202557, 5.334135826633919, -2.0993698310718356]
Epoch: 2837  loss: 76.4580773070372
Learned parameters: [2.3362361187224545, 3.540352591801228, 5.33447199843786, -2.0998299632611617]
Epoch: 2838  loss: 76.43064230654073
Learned parameters: [2.3360697475734504, 3.5405892053459986, 5.3348080090971015, -2.100289870588827]
Epoch: 2839  loss: 76.40324850229318
Learned parameters: [2.335903455398578, 3.5408257018778815, 5.335143858660287, -2.1007495531297025]
Epoch: 2840  loss: 76.37589583592231
Learned parameters: [2.3357372421751035, 3.5410620814378713, 5.335479547176007, -2.101209010958589]
Epoch: 2841  loss: 76.34858424913303
Learned parameters: [2.335571107880385, 3.5412983440668895, 5.335815074692892, -2.1016682441502144]
Epoch: 2842  loss: 76.32131368375293
Learned parameters: [2.335405052491857, 3.5415344898057013, 5.33615044125951, -2.10212725277918]
Epoch: 2843  loss: 76.29408408171693
Learned parameters: [2.3352390759870203, 3.541770518694978, 5.3364856469244035, -2.1025860369199902]
Epoch: 2844  loss: 76.26689538502671
Learned parameters: [2.3350731783433734, 3.542006430775323, 5.336820691735999, -2.103044596647043]
Epoch: 2845  loss: 76.2397475357717
Learned parameters: [2.3349073595383585, 3.5422422260872213, 5.337155575742476, -2.1035029320346017]
Epoch: 2846  loss: 76.21264047618874
Learned parameters: [2.334741619549492, 3.5424779046712187, 5.337490298992118, -2.1039610431568745]
Epoch: 2847  loss: 76.18557414838577
Learned parameters: [2.334575958354372, 3.542713466568035, 5.337824861533411, -2.1044189300880585]
Epoch: 2848  loss: 76.15854849467541
Learned parameters: [2.334410375930495, 3.5429489118183586, 5.3381592634145925, -2.1048765929022353]
Epoch: 2849  loss: 76.13156345747718
Learned parameters: [2.3342448722553333, 3.543184240462824, 5.338493504683762, -2.1053340316733884]
Epoch: 2850  loss: 76.10461897929696
Learned parameters: [2.334079447306439, 3.543419452541978, 5.338827585389027, -2.105791246475424]
Epoch: 2851  loss: 76.07771500272791
Learned parameters: [2.3339141010614997, 3.543654548096266, 5.339161505578586, -2.1062482373821823]
Epoch: 2852  loss: 76.05085147045287
Learned parameters: [2.3337488334982646, 3.543889527166052, 5.339495265300621, -2.1067050044674236]
Epoch: 2853  loss: 76.02402832524044
Learned parameters: [2.3335836445944422, 3.5441243897916603, 5.339828864603159, -2.1071615478048074]
Epoch: 2854  loss: 75.99724550994418
Learned parameters: [2.3334185343276777, 3.5443591360133793, 5.340162303534036, -2.107617867467888]
Epoch: 2855  loss: 75.97050296750578
Learned parameters: [2.333253502675636, 3.5445937658714377, 5.340495582141021, -2.1080739635301335]
Epoch: 2856  loss: 75.94380064095111
Learned parameters: [2.333088549616066, 3.5448282794059853, 5.340828700471903, -2.1085298360649367]
Epoch: 2857  loss: 75.9171384733983
Learned parameters: [2.3329236751268105, 3.54506267665709, 5.341161658574504, -2.1089854851456185]
Epoch: 2858  loss: 75.89051640804556
Learned parameters: [2.332758879185742, 3.545296957664761, 5.341494456496595, -2.1094409108454153]
Epoch: 2859  loss: 75.8639343881759
Learned parameters: [2.3325941617706927, 3.5455311224689714, 5.3418270942857955, -2.1098961132374643]
Epoch: 2860  loss: 75.83739235573391
Learned parameters: [2.332429522857581, 3.545765171109612, 5.342159571988503, -2.110351092399225]
Epoch: 2861  loss: 75.81089025547737
Learned parameters: [2.332264962425012, 3.545999103626391, 5.342491889653082, -2.11080584840326]
Epoch: 2862  loss: 75.78442803095803
Learned parameters: [2.3321004804521057, 3.5462329200588187, 5.342824047328576, -2.111260381322202]
Epoch: 2863  loss: 75.75800562581463
Learned parameters: [2.3319360769172315, 3.5464666204465938, 5.343156045062901, -2.111714691228469]
Epoch: 2864  loss: 75.73162298198903
Learned parameters: [2.3317717517923904, 3.546700204830049, 5.343487882901949, -2.112168778205127]
Epoch: 2865  loss: 75.70528004234788
Learned parameters: [2.3316075050562564, 3.5469336732486627, 5.343819560893046, -2.1126226423231476]
Epoch: 2866  loss: 75.67897675328504
Learned parameters: [2.33144333668949, 3.5471670257410635, 5.344151079086212, -2.113076283653914]
Epoch: 2867  loss: 75.65271305883037
Learned parameters: [2.331279246672256, 3.547400262346396, 5.344482437531034, -2.1135297022687816]
Epoch: 2868  loss: 75.62648890300468
Learned parameters: [2.331115234982143, 3.5476333831045936, 5.344813636273465, -2.1139828982386266]
Epoch: 2869  loss: 75.60030422998092
Learned parameters: [2.33095130159516, 3.5478663880560557, 5.345144675357212, -2.114435871634038]
Epoch: 2870  loss: 75.57415898401412
Learned parameters: [2.3307874464883076, 3.5480992772408007, 5.345475554827335, -2.114888622525818]
Epoch: 2871  loss: 75.54805310944187
Learned parameters: [2.3306236696408558, 3.548332050698049, 5.345806274732033, -2.1153411509852296]
Epoch: 2872  loss: 75.52198655067299
Learned parameters: [2.3304599710330978, 3.5485647084666336, 5.346136835120888, -2.1157934570837447]
Epoch: 2873  loss: 75.49595925220872
Learned parameters: [2.33029635064417, 3.5487972505857113, 5.346467236041795, -2.116245540892607]
Epoch: 2874  loss: 75.46997115862371
Learned parameters: [2.330132808451303, 3.5490296770950076, 5.346797477539902, -2.1166974024826777]
Epoch: 2875  loss: 75.44402221457095
Learned parameters: [2.3299693444311864, 3.549261988034373, 5.347127559659527, -2.1171490419247005]
Epoch: 2876  loss: 75.41811236479262
Learned parameters: [2.329805958561792, 3.549494183443183, 5.3474574824467105, -2.1176004592896573]
Epoch: 2877  loss: 75.39224155410494
Learned parameters: [2.32964265082267, 3.5497262633602453, 5.347787245949629, -2.1180516546488226]
Epoch: 2878  loss: 75.366409727409
Learned parameters: [2.3294794211935685, 3.5499582278242503, 5.348116850216654, -2.118502628073484]
Epoch: 2879  loss: 75.3406168296847
Learned parameters: [2.329316269652996, 3.5501900768742414, 5.348446295294333, -2.1189533796346565]
Epoch: 2880  loss: 75.31486280598853
Learned parameters: [2.3291531961782566, 3.5504218105496057, 5.348775581227438, -2.119403909403082]
Epoch: 2881  loss: 75.28914760147151
Learned parameters: [2.3289902007467895, 3.550653428889635, 5.3491047080608425, -2.1198542174494914]
Epoch: 2882  loss: 75.2634711613481
Learned parameters: [2.3288272833372465, 3.550884931933175, 5.349433675841039, -2.1203043038448155]
Epoch: 2883  loss: 75.23783343092968
Learned parameters: [2.328664443929203, 3.551116319718721, 5.349762484615728, -2.120754168660121]
Epoch: 2884  loss: 75.21223435559371
Learned parameters: [2.328501682501938, 3.5513475922848166, 5.35009113443211, -2.1212038119663656]
Epoch: 2885  loss: 75.18667388080512
Learned parameters: [2.3283389990336736, 3.551578749670302, 5.350419625335816, -2.121653233834248]
Epoch: 2886  loss: 75.1611519521157
Learned parameters: [2.3281763935020297, 3.551809791914167, 5.350747957371542, -2.122102434334289]
Epoch: 2887  loss: 75.1356685151507
Learned parameters: [2.328013865885098, 3.552040719055201, 5.351076130584569, -2.1225514135370434]
Epoch: 2888  loss: 75.11022351561434
Learned parameters: [2.327851416161941, 3.5522715311318387, 5.35140414502146, -2.123000171513205]
Epoch: 2889  loss: 75.0848168992855
Learned parameters: [2.327689044312002, 3.5525022281822913, 5.351732000729201, -2.123448708333469]
Epoch: 2890  loss: 75.05944861209866
Learned parameters: [2.3275267503141817, 3.5527328102448203, 5.35205969775385, -2.1238970240682975]
Epoch: 2891  loss: 75.03411859998506
Learned parameters: [2.327364534146671, 3.5529632773579816, 5.352387236140466, -2.124345118787962]
Epoch: 2892  loss: 75.00882680896507
Learned parameters: [2.3272023957875114, 3.5531936295603392, 5.35271461593382, -2.1247929925626368]
Epoch: 2893  loss: 74.98357318514869
Learned parameters: [2.327040335215332, 3.5534238668902254, 5.353041837179437, -2.1252406454625397]
Epoch: 2894  loss: 74.95835767472803
Learned parameters: [2.326878352409396, 3.553653989385726, 5.3533688999236535, -2.1256880775579408]
Epoch: 2895  loss: 74.9331802239654
Learned parameters: [2.3267164473489945, 3.553883997084878, 5.353695804212772, -2.1261352889190404]
Epoch: 2896  loss: 74.90804077921706
Learned parameters: [2.326554620012888, 3.5541138900258535, 5.354022550092275, -2.1265822796158567]
Epoch: 2897  loss: 74.88293928690652
Learned parameters: [2.3263928703793906, 3.55434366824693, 5.354349137606947, -2.127029049718242]
Epoch: 2898  loss: 74.85787569354102
Learned parameters: [2.326231198426945, 3.554573331786306, 5.354675566801676, -2.127475599295993]
Epoch: 2899  loss: 74.8328499457059
Learned parameters: [2.326069604134524, 3.554802880681971, 5.355001837722026, -2.1279219284189335]
Epoch: 2900  loss: 74.80786199006626
Learned parameters: [2.325908087481454, 3.5550323149717613, 5.355327950413982, -2.1283680371568745]
Epoch: 2901  loss: 74.7829117733641
Learned parameters: [2.325746648446883, 3.5552616346935353, 5.355653904923209, -2.128813925579508]
Epoch: 2902  loss: 74.75799924242189
Learned parameters: [2.325585287009533, 3.5554908398852523, 5.355979701294697, -2.129259593756358]
Epoch: 2903  loss: 74.73312434414808
Learned parameters: [2.3254240031479347, 3.555719930584897, 5.356305339573096, -2.1297050417568255]
Epoch: 2904  loss: 74.70828702551228
Learned parameters: [2.3252627968408857, 3.5559489068303316, 5.356630819803355, -2.130150269650278]
Epoch: 2905  loss: 74.68348723358109
Learned parameters: [2.325101668067585, 3.5561777686592517, 5.356956142030916, -2.1305952775060764]
Epoch: 2906  loss: 74.65872491548754
Learned parameters: [2.324940616807354, 3.5564065161092775, 5.357281306301317, -2.1310400653935186]
Epoch: 2907  loss: 74.63400001845011
Learned parameters: [2.32477964303927, 3.5566351492180734, 5.35760631265968, -2.1314846333817683]
Epoch: 2908  loss: 74.6093124897607
Learned parameters: [2.324618746742123, 3.556863668023363, 5.357931161150648, -2.1319289815398457]
Epoch: 2909  loss: 74.58466227679065
Learned parameters: [2.324457927894708, 3.557092072562833, 5.358255851818798, -2.1323731099366863]
Epoch: 2910  loss: 74.56004932698931
Learned parameters: [2.3242971864761053, 3.557320362874043, 5.3585803847090325, -2.132817018641194]
Epoch: 2911  loss: 74.53547358788384
Learned parameters: [2.32413652246565, 3.557548538994437, 5.358904759866536, -2.1332607077222376]
Epoch: 2912  loss: 74.51093500707739
Learned parameters: [2.3239759358426513, 3.5577766009614322, 5.359228977336382, -2.1337041772485947]
Epoch: 2913  loss: 74.48643353224409
Learned parameters: [2.323815426586244, 3.558004548812618, 5.359553037163421, -2.134147427288938]
Epoch: 2914  loss: 74.46196911109108
Learned parameters: [2.3236549946752825, 3.558232382585568, 5.359876939391972, -2.1345904579117647]
Epoch: 2915  loss: 74.43754169151956
Learned parameters: [2.323494640088661, 3.558460102317677, 5.360200684066235, -2.135033269185452]
Epoch: 2916  loss: 74.41315122146625
Learned parameters: [2.3233343628056633, 3.558687708046191, 5.360524271230893, -2.1354758611783846]
Epoch: 2917  loss: 74.38879764891233
Learned parameters: [2.32317416280586, 3.558915199808242, 5.360847700930968, -2.1359182339589315]
Epoch: 2918  loss: 74.36448092193368
Learned parameters: [2.3230140400687147, 3.559142577640966, 5.361170973211256, -2.1363603875953583]
Epoch: 2919  loss: 74.34020098866905
Learned parameters: [2.322853994573375, 3.559369841581572, 5.361494088116034, -2.136802322155787]
Epoch: 2920  loss: 74.31595779734269
Learned parameters: [2.322694026298849, 3.5595969916672843, 5.361817045689309, -2.137244037708232]
Epoch: 2921  loss: 74.29175129625278
Learned parameters: [2.3225341352243336, 3.559824027935238, 5.362139845975275, -2.1376855343206667]
Epoch: 2922  loss: 74.26758143377228
Learned parameters: [2.322374321329331, 3.560050950422439, 5.362462489018481, -2.1381268120610417]
Epoch: 2923  loss: 74.2434481583476
Learned parameters: [2.3222145845934494, 3.560277759165828, 5.362784974863545, -2.1385678709972464]
Epoch: 2924  loss: 74.21935141851117
Learned parameters: [2.3220549249961318, 3.560504454202369, 5.363107303554774, -2.139008711197057]
Epoch: 2925  loss: 74.19529116286213
Learned parameters: [2.3218953425166164, 3.560731035569061, 5.363429475136108, -2.1394493327281263]
Epoch: 2926  loss: 74.1712673400791
Learned parameters: [2.3217358371341428, 3.560957503302873, 5.363751489651411, -2.139889735658027]
Epoch: 2927  loss: 74.14727989891189
Learned parameters: [2.3215764088281623, 3.5611838574406725, 5.364073347144764, -2.1403299200542922]
Epoch: 2928  loss: 74.12332878819335
Learned parameters: [2.321417057578323, 3.561410098019234, 5.3643950476604445, -2.1407698859844113]
Epoch: 2929  loss: 74.09941395682203
Learned parameters: [2.321257783364269, 3.561636225075301, 5.364716591242647, -2.1412096335157926]
Epoch: 2930  loss: 74.07553535378567
Learned parameters: [2.321098586165488, 3.561862238645638, 5.365037977935265, -2.141649162715735]
Epoch: 2931  loss: 74.0516929281319
Learned parameters: [2.3209394659613625, 3.5620881387670122, 5.365359207781969, -2.1420884736514374]
Epoch: 2932  loss: 74.02788662898456
Learned parameters: [2.320780422731361, 3.5623139254761322, 5.365680280826468, -2.142527566390036]
Epoch: 2933  loss: 74.00411640555731
Learned parameters: [2.3206214564551404, 3.562539598809613, 5.366001197112657, -2.1429664409986224]
Epoch: 2934  loss: 73.9803822071197
Learned parameters: [2.3204625671124495, 3.562765158804008, 5.36632195668448, -2.143405097544226]
Epoch: 2935  loss: 73.95668398302944
Learned parameters: [2.320303754682979, 3.5629906054958567, 5.366642559585721, -2.1438435360937844]
Epoch: 2936  loss: 73.93302168271472
Learned parameters: [2.3201450191463064, 3.563215938921699, 5.366963005859922, -2.144281756714132]
Epoch: 2937  loss: 73.90939525562904
Learned parameters: [2.3199863604821, 3.5634411591183586, 5.367283295550902, -2.1447197594720824]
Epoch: 2938  loss: 73.88580465128547
Learned parameters: [2.3198277786698864, 3.5636662661224996, 5.367603428702088, -2.1451575444343116]
Epoch: 2939  loss: 73.86224981938399
Learned parameters: [2.3196692736892444, 3.563891259970614, 5.367923405356816, -2.145595111667405]
Epoch: 2940  loss: 73.83873070968383
Learned parameters: [2.3195108455199493, 3.564116140698988, 5.368243225558539, -2.146032461237874]
Epoch: 2941  loss: 73.81524727201106
Learned parameters: [2.3193524941419597, 3.564340908343791, 5.36856288935087, -2.1464695932121822]
Epoch: 2942  loss: 73.7917994562475
Learned parameters: [2.3191942195352175, 3.564565562941184, 5.368882396777344, -2.146906507656724]
Epoch: 2943  loss: 73.76838721234111
Learned parameters: [2.3190360216794863, 3.5647901045273285, 5.3692017478811405, -2.1473432046377665]
Epoch: 2944  loss: 73.7450104903159
Learned parameters: [2.3188779005544418, 3.5650145331384087, 5.36952094270527, -2.1477796842215047]
Epoch: 2945  loss: 73.72166924025649
Learned parameters: [2.318719856139868, 3.565238848810557, 5.3698399812928335, -2.148215946474094]
Epoch: 2946  loss: 73.69836341232116
Learned parameters: [2.3185618884157235, 3.56546305157982, 5.370158863687101, -2.148651991461647]
Epoch: 2947  loss: 73.67509295675605
Learned parameters: [2.318403997362047, 3.565687141482186, 5.3704775899313795, -2.14908781925021]
Epoch: 2948  loss: 73.651857823872
Learned parameters: [2.318246182958799, 3.5659111185536396, 5.370796160068789, -2.1495234299057384]
Epoch: 2949  loss: 73.62865796405319
Learned parameters: [2.31808844518583, 3.5661349828301705, 5.37111457414222, -2.1499588234940887]
Epoch: 2950  loss: 73.6054933277525
Learned parameters: [2.3179307840229963, 3.5663587343477365, 5.3714328321944995, -2.1503940000810426]
Epoch: 2951  loss: 73.58236386550102
Learned parameters: [2.3177731994502775, 3.566582373142228, 5.3717509342685545, -2.1508289597323347]
Epoch: 2952  loss: 73.55926952789923
Learned parameters: [2.3176156914477803, 3.566805899249465, 5.372068880407418, -2.151263702513648]
Epoch: 2953  loss: 73.53621026561905
Learned parameters: [2.31745825999561, 3.5670293127052357, 5.372386670654044, -2.1516982284905866]
Epoch: 2954  loss: 73.51318602940411
Learned parameters: [2.3173009050737923, 3.5672526135453233, 5.372704305051203, -2.152132537728663]
Epoch: 2955  loss: 73.49019677007446
Learned parameters: [2.317143626662303, 3.5674758018054953, 5.3730217836415175, -2.1525666302933018]
Epoch: 2956  loss: 73.46724243851756
Learned parameters: [2.316986424741184, 3.567698877521467, 5.37333910646763, -2.153000506249864]
Epoch: 2957  loss: 73.44432298569446
Learned parameters: [2.3168292992905877, 3.5679218407288853, 5.373656273572263, -2.1534341656636538]
Epoch: 2958  loss: 73.42143836263563
Learned parameters: [2.3166722502907247, 3.5681446914633472, 5.373973284998147, -2.153867608599911]
Epoch: 2959  loss: 73.39858852044804
Learned parameters: [2.3165152777217743, 3.568367429760428, 5.3742901407878945, -2.1543008351237907]
Epoch: 2960  loss: 73.37577341031013
Learned parameters: [2.316358381563847, 3.5685900556556653, 5.374606840983928, -2.1547338453003566]
Epoch: 2961  loss: 73.35299298339521
Learned parameters: [2.3162015617972314, 3.5688125691850376, 5.374923385629205, -2.1551666391946966]
Epoch: 2962  loss: 73.33024719094473
Learned parameters: [2.316044818401944, 3.5690349703843, 5.375239774766037, -2.1555992168717286]
Epoch: 2963  loss: 73.3075359843863
Learned parameters: [2.31588815135802, 3.5692572592891474, 5.375556008436681, -2.156031578396305]
Epoch: 2964  loss: 73.28485931518853
Learned parameters: [2.315731560645665, 3.569479435935048, 5.375872086683466, -2.156463723833208]
Epoch: 2965  loss: 73.26221713489242
Learned parameters: [2.315575046245313, 3.569701500357334, 5.376188009548947, -2.1568956532471835]
Epoch: 2966  loss: 73.23960939513594
Learned parameters: [2.3154186081374113, 3.5699234525912025, 5.3765037770755555, -2.1573273667028756]
Epoch: 2967  loss: 73.2170360476077
Learned parameters: [2.315262246302276, 3.5701452926718424, 5.37681938930545, -2.157758864264827]
Epoch: 2968  loss: 73.19449704405534
Learned parameters: [2.315105960720127, 3.5703670206344515, 5.3771348462805975, -2.158190145997496]
Epoch: 2969  loss: 73.17199233628207
Learned parameters: [2.314949751371236, 3.5705886365141972, 5.377450148042979, -2.1586212119652903]
Epoch: 2970  loss: 73.14952187617843
Learned parameters: [2.314793618236015, 3.5708101403461496, 5.3777652946346866, -2.1590520622325577]
Epoch: 2971  loss: 73.12708561570427
Learned parameters: [2.314637561294978, 3.5710315321653088, 5.378080286097873, -2.1594826968635883]
Epoch: 2972  loss: 73.10468350688416
Learned parameters: [2.314481580528609, 3.571252812006668, 5.378395122474597, -2.159913115922608]
Epoch: 2973  loss: 73.08231550180429
Learned parameters: [2.3143256759173063, 3.571473979905228, 5.378709803806734, -2.160343319473763]
Epoch: 2974  loss: 73.05998155261753
Learned parameters: [2.3141698474414336, 3.571695035895977, 5.379024330136047, -2.1607733075811266]
Epoch: 2975  loss: 73.03768161155911
Learned parameters: [2.3140140950814274, 3.571915980013848, 5.379338701504329, -2.1612030803087126]
Epoch: 2976  loss: 73.01541563092731
Learned parameters: [2.31385841881784, 3.572136812293705, 5.379652917953462, -2.1616326377204786]
Epoch: 2977  loss: 72.99318356309357
Learned parameters: [2.3137028186312714, 3.5723575327703654, 5.379966979525319, -2.162061979880316]
Epoch: 2978  loss: 72.97098536049819
Learned parameters: [2.3135472945022766, 3.5725781414786297, 5.380280886261639, -2.162491106852033]
Epoch: 2979  loss: 72.94882097564974
Learned parameters: [2.313391846411356, 3.572798638453287, 5.380594638204013, -2.1629200186993542]
Epoch: 2980  loss: 72.92669036112372
Learned parameters: [2.313236474339029, 3.5730190237290893, 5.380908235393985, -2.163348715485933]
Epoch: 2981  loss: 72.90459346956565
Learned parameters: [2.3130811782658967, 3.573239297340733, 5.381221677873145, -2.1637771972753668]
Epoch: 2982  loss: 72.8825302536905
Learned parameters: [2.3129259581726416, 3.57345945932286, 5.381534965683128, -2.164205464131197]
Epoch: 2983  loss: 72.86050066628232
Learned parameters: [2.3127708140399497, 3.573679509710081, 5.381848098865502, -2.1646335161168926]
Epoch: 2984  loss: 72.8385046601893
Learned parameters: [2.3126157458484324, 3.573899448536953, 5.382161077461627, -2.1650613532958287]
Epoch: 2985  loss: 72.81654218827791
Learned parameters: [2.3124607535789017, 3.5741192758385387, 5.382473901513481, -2.1654889757314257]
Epoch: 2986  loss: 72.7946132033961
Learned parameters: [2.3123058372118757, 3.574338991649768, 5.3827865710624225, -2.1659163834869424]
Epoch: 2987  loss: 72.77271765866087
Learned parameters: [2.3121509967277776, 3.574558596005441, 5.383099086149524, -2.166343576625532]
Epoch: 2988  loss: 72.75085550718725
Learned parameters: [2.311996232107289, 3.5747780889402687, 5.383411446816173, -2.166770555210339]
Epoch: 2989  loss: 72.72902670216115
Learned parameters: [2.3118415433313078, 3.574997470488734, 5.383723653103905, -2.1671973193044516]
Epoch: 2990  loss: 72.70723119686252
Learned parameters: [2.3116869303807883, 3.5752167406852604, 5.384035705054261, -2.167623868970905]
Epoch: 2991  loss: 72.68546894461423
Learned parameters: [2.3115323932364973, 3.5754358995642206, 5.384347602708394, -2.1680502042726055]
Epoch: 2992  loss: 72.66373989883522
Learned parameters: [2.3113779318790626, 3.5756549471599284, 5.3846593461071395, -2.168476325272345]
Epoch: 2993  loss: 72.64204401300758
Learned parameters: [2.3112235462892086, 3.5758738835066084, 5.384970935291382, -2.1689022320328584]
Epoch: 2994  loss: 72.62038124066986
Learned parameters: [2.3110692364478864, 3.5760927086383725, 5.38528237030225, -2.1693279246168538]
Epoch: 2995  loss: 72.59875153541412
Learned parameters: [2.310915002336152, 3.5763114225892707, 5.3855936511809555, -2.169753403086995]
Epoch: 2996  loss: 72.57715485090681
Learned parameters: [2.310760843934962, 3.5765300253933816, 5.385904777968525, -2.1701786675058767]
Epoch: 2997  loss: 72.55559114086694
Learned parameters: [2.3106067612251056, 3.576748517084801, 5.38621575070568, -2.17060371793599]
Epoch: 2998  loss: 72.5340603590991
Learned parameters: [2.3104527541873647, 3.5769668976975777, 5.386526569433043, -2.17102855443974]
Epoch: 2999  loss: 72.51256245947835
Learned parameters: [2.31029882280268, 3.577185167265668, 5.386837234191378, -2.1714531770794845]
Epoch: 3000  loss: 72.49109739593706
Learned parameters: [2.3101449670521688, 3.5774033258229583, 5.387147745021644, -2.171877585917558]
Epoch: 3001  loss: 72.46966512246487
Learned parameters: [2.3099911869169385, 3.577621373403316, 5.387458101964727, -2.1723017810162304]
Epoch: 3002  loss: 72.4482655931246
Learned parameters: [2.3098374823779575, 3.577839310040631, 5.387768305061253, -2.172725762437682]
Epoch: 3003  loss: 72.42689876203633
Learned parameters: [2.30968385341612, 3.578057135768792, 5.388078354351682, -2.173149530244014]
Epoch: 3004  loss: 72.40556458339805
Learned parameters: [2.3095303000124012, 3.5782748506216353, 5.388388249876521, -2.1735730844972716]
Epoch: 3005  loss: 72.38426301146987
Learned parameters: [2.3093768221479256, 3.578492454632918, 5.388697991676414, -2.1739964252594572]
Epoch: 3006  loss: 72.36299400057692
Learned parameters: [2.30922341980389, 3.5787099478363453, 5.389007579792036, -2.1744195525925125]
Epoch: 3007  loss: 72.34175750511861
Learned parameters: [2.3090700929614325, 3.57892733026561, 5.3893170142639075, -2.1748424665582946]
Epoch: 3008  loss: 72.32055347955395
Learned parameters: [2.308916841601576, 3.5791446019543556, 5.389626295132281, -2.17526516721856]
Epoch: 3009  loss: 72.29938187840321
Learned parameters: [2.308763665705476, 3.5793617629364753, 5.389935422437745, -2.175687654635063]
Epoch: 3010  loss: 72.27824265610126
Learned parameters: [2.308610565254327, 3.5795788132460458, 5.390244396221026, -2.1761099288695256]
Epoch: 3011  loss: 72.25713576732065
Learned parameters: [2.3084575402291083, 3.5797957529169397, 5.390553216522317, -2.176531989983522]
Epoch: 3012  loss: 72.23606116678405
Learned parameters: [2.308304590610884, 3.5800125819830084, 5.390861883381893, -2.1769538380385858]
Epoch: 3013  loss: 72.21501880925538
Learned parameters: [2.308151716380907, 3.580229300478016, 5.391170396840234, -2.177375473096227]
Epoch: 3014  loss: 72.19400864956495
Learned parameters: [2.307998917520491, 3.5804459084356015, 5.391478756937788, -2.177796895217886]
Epoch: 3015  loss: 72.17303064266736
Learned parameters: [2.30784619401087, 3.5806624058892456, 5.391786963714716, -2.1782181044648845]
Epoch: 3016  loss: 72.15208474354378
Learned parameters: [2.3076935458332755, 3.580878792872442, 5.392095017211144, -2.178639100898496]
Epoch: 3017  loss: 72.13117090723478
Learned parameters: [2.3075409729689333, 3.5810950694185837, 5.392402917467074, -2.1790598845799045]
Epoch: 3018  loss: 72.11028908887562
Learned parameters: [2.3073884753991365, 3.581311235560944, 5.3927106645224825, -2.1794804555702196]
Epoch: 3019  loss: 72.08943924365464
Learned parameters: [2.307236053105275, 3.5815272913327036, 5.393018258417396, -2.179900813930494]
Epoch: 3020  loss: 72.06862132682
Learned parameters: [2.307083706068771, 3.5817432367670112, 5.393325699191826, -2.180320959721725]
Epoch: 3021  loss: 72.04783529367245
Learned parameters: [2.306931434270998, 3.581959071897008, 5.393632986885657, -2.180740893004837]
Epoch: 3022  loss: 72.02708109957457
Learned parameters: [2.306779237693289, 3.582174796755829, 5.393940121538658, -2.181160613840687]
Epoch: 3023  loss: 72.00635869995443
Learned parameters: [2.3066271163169976, 3.5823904113765876, 5.3942471031905725, -2.181580122290076]
Epoch: 3024  loss: 71.98566805030372
Learned parameters: [2.30647507012356, 3.5826059157923553, 5.394553931881208, -2.181999418413762]
Epoch: 3025  loss: 71.96500910617463
Learned parameters: [2.3063230990944574, 3.5828213100361554, 5.394860607650361, -2.18241850227244]
Epoch: 3026  loss: 71.9443818231916
Learned parameters: [2.3061712032111723, 3.583036594140974, 5.395167130537754, -2.1828373739267293]
Epoch: 3027  loss: 71.92378615705248
Learned parameters: [2.306019382455154, 3.5832517681397507, 5.39547350058297, -2.183256033437155]
Epoch: 3028  loss: 71.90322206351459
Learned parameters: [2.3058676368078688, 3.583466832065401, 5.395779717825557, -2.1836744808641835]
Epoch: 3029  loss: 71.8826894983846
Learned parameters: [2.305715966250842, 3.5836817859508057, 5.396085782305093, -2.184092716268235]
Epoch: 3030  loss: 71.86218841753622
Learned parameters: [2.305564370765647, 3.5838966298288124, 5.396391694061163, -2.18451073970968]
Epoch: 3031  loss: 71.84171877690271
Learned parameters: [2.3054128503338442, 3.5841113637322484, 5.396697453133274, -2.18492855124882]
Epoch: 3032  loss: 71.82128053248756
Learned parameters: [2.305261404936971, 3.5843259876938802, 5.397003059560808, -2.185346150945886]
Epoch: 3033  loss: 71.80087364037391
Learned parameters: [2.305110034556561, 3.58454050174642, 5.397308513383059, -2.185763538861037]
Epoch: 3034  loss: 71.78049805660117
Learned parameters: [2.3049587391744235, 3.584754905923075, 5.397613814640055, -2.1861807150544985]
Epoch: 3035  loss: 71.7601537372611
Learned parameters: [2.3048075187720816, 3.5849692002569573, 5.397918963371248, -2.186597679586352]
Epoch: 3036  loss: 71.7398406386472
Learned parameters: [2.304656373330855, 3.5851833847810566, 5.398223959615637, -2.1870144325165493]
Epoch: 3037  loss: 71.71955871706726
Learned parameters: [2.3045053028322724, 3.5853974595282834, 5.39852880341246, -2.18743097390502]
Epoch: 3038  loss: 71.6993079288898
Learned parameters: [2.304354307258163, 3.5856114245314177, 5.398833494801312, -2.1878473038116892]
Epoch: 3039  loss: 71.67908823052423
Learned parameters: [2.3042033865904332, 3.5858252798232173, 5.399138033821858, -2.1882634222964406]
Epoch: 3040  loss: 71.65889957847315
Learned parameters: [2.304052540810737, 3.586039025436361, 5.399442420513256, -2.1886793294190157]
Epoch: 3041  loss: 71.63874192933412
Learned parameters: [2.303901769900557, 3.58625266140346, 5.39974665491429, -2.1890950252390384]
Epoch: 3042  loss: 71.61861523973181
Learned parameters: [2.303751073841539, 3.586466187757089, 5.400050737063951, -2.189510509816117]
Epoch: 3043  loss: 71.59851946633987
Learned parameters: [2.3036004526155605, 3.586679604529706, 5.400354667001478, -2.189925783209838]
Epoch: 3044  loss: 71.57845456592503
Learned parameters: [2.303449906204544, 3.586892911753614, 5.400658444766031, -2.190340845479696]
Epoch: 3045  loss: 71.55842049648561
Learned parameters: [2.3032994345914273, 3.5871061094615033, 5.4009620703945656, -2.1907556966794735]
Epoch: 3046  loss: 71.53841721445382
Learned parameters: [2.3031490377564676, 3.587319197685934, 5.4012655439240245, -2.191170336868758]
Epoch: 3047  loss: 71.51844467624069
Learned parameters: [2.3029987156818987, 3.5875321764588315, 5.401568865394032, -2.191584766107414]
Epoch: 3048  loss: 71.49850283883077
Learned parameters: [2.3028484683511747, 3.5877450458117286, 5.401872034845841, -2.191998984455445]
Epoch: 3049  loss: 71.47859165926621
Learned parameters: [2.302698295746903, 3.587957805776414, 5.4021750523194285, -2.192412991972596]
Epoch: 3050  loss: 71.4587110946554
Learned parameters: [2.3025481978499913, 3.5881704563852015, 5.4024779178523055, -2.192826788718195]
Epoch: 3051  loss: 71.43886110216565
Learned parameters: [2.3023981746408655, 3.588382997670549, 5.402780631481225, -2.193240374751386]
Epoch: 3052  loss: 71.41904163902645
Learned parameters: [2.3022482261011454, 3.5885954296645304, 5.403083193244545, -2.1936537501314493]
Epoch: 3053  loss: 71.39925266253081
Learned parameters: [2.3020983522138136, 3.588807752398773, 5.4033856031824605, -2.194066914917832]
Epoch: 3054  loss: 71.37949413002744
Learned parameters: [2.3019485529618184, 3.5890199659049005, 5.40368786133504, -2.1944798691698812]
Epoch: 3055  loss: 71.35976599894151
Learned parameters: [2.301798828326892, 3.5892320702148908, 5.403989967740562, -2.194892612946612]
Epoch: 3056  loss: 71.34006822675636
Learned parameters: [2.301649178289904, 3.589444065360949, 5.4042919224359895, -2.1953051463067625]
Epoch: 3057  loss: 71.32040077102232
Learned parameters: [2.301499602832204, 3.5896559513750965, 5.404593725458888, -2.195717469309079]
Epoch: 3058  loss: 71.30076358935544
Learned parameters: [2.3013501019362974, 3.5898677282889166, 5.404895376848343, -2.1961295820124493]
Epoch: 3059  loss: 71.2811566394079
Learned parameters: [2.3012006755852386, 3.5900793961340045, 5.405196876644277, -2.196541484475797]
Epoch: 3060  loss: 71.2615798787909
Learned parameters: [2.3010513237614503, 3.59029095494252, 5.405498224885907, -2.1969531767578783]
Epoch: 3061  loss: 71.24203326522996
Learned parameters: [2.300902046446124, 3.5905024047468763, 5.405799421610581, -2.1973646589171243]
Epoch: 3062  loss: 71.22251675659763
Learned parameters: [2.300752843620297, 3.590713745579377, 5.406100466855286, -2.1977759310118516]
Epoch: 3063  loss: 71.20303031079176
Learned parameters: [2.3006037152660914, 3.5909249774719534, 5.406401360658467, -2.1981869931005087]
Epoch: 3064  loss: 71.18357388575745
Learned parameters: [2.300454661366554, 3.591136100456219, 5.4067021030598035, -2.1985978452416464]
Epoch: 3065  loss: 71.16414743950861
Learned parameters: [2.300305681904477, 3.5913471145638676, 5.407002694098573, -2.1990084874936975]
Epoch: 3066  loss: 71.14475093009185
Learned parameters: [2.3001567768616358, 3.591558019826929, 5.4073031338125945, -2.199418919914839]
Epoch: 3067  loss: 71.12538431564019
Learned parameters: [2.3000079462192486, 3.5917688162774892, 5.407603422238782, -2.1998291425630536]
Epoch: 3068  loss: 71.10604755438109
Learned parameters: [2.2998591899591094, 3.5919795039473033, 5.407903559414708, -2.2002391554963374]
Epoch: 3069  loss: 71.08674060458463
Learned parameters: [2.299710508064017, 3.5921900828677917, 5.408203545379302, -2.2006489587728115]
Epoch: 3070  loss: 71.06746342455713
Learned parameters: [2.2995619005169794, 3.592400553070314, 5.408503380171754, -2.2010585524505775]
Epoch: 3071  loss: 71.04821597266584
Learned parameters: [2.2994133673002666, 3.592610914586408, 5.408803063830133, -2.2014679365875223]
Epoch: 3072  loss: 71.02899820736774
Learned parameters: [2.299264908395411, 3.592821167447735, 5.409102596391351, -2.2018771112413034]
Epoch: 3073  loss: 71.00981008716627
Learned parameters: [2.299116523784155, 3.5930313116858645, 5.409401977892559, -2.2022860764695533]
Epoch: 3074  loss: 70.99065157062559
Learned parameters: [2.2989682134490446, 3.593241347332056, 5.409701208371946, -2.2026948323299793]
Epoch: 3075  loss: 70.97152261636353
Learned parameters: [2.298819977373072, 3.5934512744174087, 5.410000287868271, -2.2031033788803103]
Epoch: 3076  loss: 70.9524231830504
Learned parameters: [2.298671815538846, 3.59366109297313, 5.410299216419704, -2.203511716178142]
Epoch: 3077  loss: 70.93335322941846
Learned parameters: [2.298523727928309, 3.5938708030306166, 5.41059799406342, -2.203919844280881]
Epoch: 3078  loss: 70.91431271425301
Learned parameters: [2.2983757145232753, 3.5940804046212875, 5.4108966208363585, -2.204327763245851]
Epoch: 3079  loss: 70.89530159640042
Learned parameters: [2.298227775306086, 3.594289897776376, 5.41119509677614, -2.2047354731304125]
Epoch: 3080  loss: 70.87631983476572
Learned parameters: [2.298079910259605, 3.594499282526934, 5.411493421921063, -2.2051429739919635]
Epoch: 3081  loss: 70.85736738830829
Learned parameters: [2.2979321193666298, 3.594708558904021, 5.411791596309275, -2.2055502658878305]
Epoch: 3082  loss: 70.83844421604527
Learned parameters: [2.2977844026094494, 3.5949177269388337, 5.412089619978152, -2.2059573488751814]
Epoch: 3083  loss: 70.81955027705698
Learned parameters: [2.2976367599700667, 3.5951267866626417, 5.412387492964611, -2.206364223011069]
Epoch: 3084  loss: 70.80068553047944
Learned parameters: [2.2974891914307096, 3.5953357381065456, 5.4126852153057765, -2.206770888352523]
Epoch: 3085  loss: 70.78184993554025
Learned parameters: [2.2973416969741036, 3.595544581301404, 5.41298278703936, -2.2071773449565804]
Epoch: 3086  loss: 70.76304345148696
Learned parameters: [2.2971942765832574, 3.5957533162782385, 5.41328020820358, -2.2075835928802783]
Epoch: 3087  loss: 70.74426603752555
Learned parameters: [2.2970469302408274, 3.595961943068388, 5.413577478836249, -2.2079896321805514]
Epoch: 3088  loss: 70.72551765299934
Learned parameters: [2.296899657928837, 3.596170461703256, 5.413874598974167, -2.208395462914156]
Epoch: 3089  loss: 70.70679825736312
Learned parameters: [2.2967524596292876, 3.5963788722140535, 5.414171568653932, -2.208801085137769]
Epoch: 3090  loss: 70.6881078101102
Learned parameters: [2.296605335324846, 3.5965871746317553, 5.414468387913019, -2.209206498908146]
Epoch: 3091  loss: 70.66944627076816
Learned parameters: [2.2964582849986646, 3.5967953689871597, 5.414765056789532, -2.209611704282079]
Epoch: 3092  loss: 70.65081359892977
Learned parameters: [2.2963113086336495, 3.5970034553111043, 5.415061575321164, -2.2100167013162575]
Epoch: 3093  loss: 70.63220975422178
Learned parameters: [2.296164406212158, 3.597211433634694, 5.415357943544862, -2.2104214900672354]
Epoch: 3094  loss: 70.61363469632747
Learned parameters: [2.2960175777162974, 3.5974193039890787, 5.415654161497164, -2.210826070591463]
Epoch: 3095  loss: 70.59508838500696
Learned parameters: [2.295870823128511, 3.5976270664051677, 5.415950229214943, -2.2112304429453746]
Epoch: 3096  loss: 70.57657078011525
Learned parameters: [2.2957241424317862, 3.597834720913597, 5.416246146735728, -2.2116346071854367]
Epoch: 3097  loss: 70.55808184153055
Learned parameters: [2.2955775356092447, 3.5980422675449453, 5.416541914097188, -2.212038563368088]
Epoch: 3098  loss: 70.53962152917735
Learned parameters: [2.2954310026436158, 3.598249706329931, 5.416837531336416, -2.212442311549649]
Epoch: 3099  loss: 70.5211898030345
Learned parameters: [2.295284543517216, 3.5984570372993665, 5.417132998489864, -2.212845851786307]
Epoch: 3100  loss: 70.50278662315957
Learned parameters: [2.2951381582124335, 3.598664260483939, 5.4174283155939715, -2.2132491841341815]
Epoch: 3101  loss: 70.48441194966705
Learned parameters: [2.294991846712135, 3.5988713759141486, 5.417723482685783, -2.213652308649421]
Epoch: 3102  loss: 70.46606574272107
Learned parameters: [2.29484560899948, 3.599078383620362, 5.418018499802688, -2.2140552253881673]
Epoch: 3103  loss: 70.44774796254623
Learned parameters: [2.294699445057428, 3.5992852836329656, 5.418313366981721, -2.214457934406462]
Epoch: 3104  loss: 70.42945856941884
Learned parameters: [2.2945533548685613, 3.5994920759824423, 5.418608084259339, -2.214860435760219]
Epoch: 3105  loss: 70.41119752366225
Learned parameters: [2.2944073384153745, 3.5996987606992836, 5.418902651671819, -2.21526272950528]
Epoch: 3106  loss: 70.3929647856618
Learned parameters: [2.2942613956806595, 3.599905337813869, 5.419197069255805, -2.2156648156974854]
Epoch: 3107  loss: 70.37476031585766
Learned parameters: [2.294115526647528, 3.600111807356456, 5.419491337048335, -2.2160666943926794]
Epoch: 3108  loss: 70.35658407474244
Learned parameters: [2.2939697312990655, 3.6003181693572897, 5.419785455086355, -2.216468365646642]
Epoch: 3109  loss: 70.3384360228664
Learned parameters: [2.2938240096180595, 3.6005244238466885, 5.420079423406341, -2.2168698295150415]
Epoch: 3110  loss: 70.32031612083178
Learned parameters: [2.293678361587149, 3.6007305708550046, 5.420373242044513, -2.2172710860534637]
Epoch: 3111  loss: 70.30222432930707
Learned parameters: [2.2935327871890827, 3.6009366104124383, 5.42066691103713, -2.2176721353174558]
Epoch: 3112  loss: 70.28416060902356
Learned parameters: [2.293387286406923, 3.601142542549057, 5.420960430420833, -2.2180729773625667]
Epoch: 3113  loss: 70.26612492074517
Learned parameters: [2.2932418592239476, 3.6013483672950772, 5.421253800232662, -2.218473612244347]
Epoch: 3114  loss: 70.2481172251889
Learned parameters: [2.2930965056232298, 3.6015540846810556, 5.421547020509504, -2.2188740400182754]
Epoch: 3115  loss: 70.23013748320008
Learned parameters: [2.292951225587348, 3.601759694737603, 5.421840091287442, -2.2192742607396534]
Epoch: 3116  loss: 70.21218565575606
Learned parameters: [2.292806019098785, 3.6019651974950584, 5.422133012602185, -2.219674274463667]
Epoch: 3117  loss: 70.19426170387197
Learned parameters: [2.292660886140601, 3.6021705929835433, 5.42242578449019, -2.220074081245559]
Epoch: 3118  loss: 70.17636558858709
Learned parameters: [2.292515826696303, 3.6023758812330304, 5.422718406988508, -2.220473681140616]
Epoch: 3119  loss: 70.15849727098933
Learned parameters: [2.2923708407492063, 3.6025810622735333, 5.423010880133875, -2.2208730742040395]
Epoch: 3120  loss: 70.14065671222596
Learned parameters: [2.2922259282821, 3.6027861361351943, 5.423303203962226, -2.2212722604908794]
Epoch: 3121  loss: 70.12284387347997
Learned parameters: [2.292081089277636, 3.6029911028483226, 5.423595378509364, -2.2216712400561436]
Epoch: 3122  loss: 70.10505871597798
Learned parameters: [2.291936323718738, 3.6031959624430954, 5.423887403811401, -2.2220700129548336]
Epoch: 3123  loss: 70.0873012010323
Learned parameters: [2.291791631588714, 3.603400714949458, 5.424179279904881, -2.222468579241955]
Epoch: 3124  loss: 70.06957129004175
Learned parameters: [2.2916470128709174, 3.6036053603972142, 5.424471006826288, -2.2228669389724502]
Epoch: 3125  loss: 70.05186894443366
Learned parameters: [2.2915024675484665, 3.6038098988162113, 5.42476258461172, -2.223265092201166]
Epoch: 3126  loss: 70.03419412567987
Learned parameters: [2.291357995604277, 3.6040143302363647, 5.425054013296964, -2.2236630389828647]
Epoch: 3127  loss: 70.01654679529997
Learned parameters: [2.291213597021311, 3.604218654687554, 5.42534529291782, -2.224060779372267]
Epoch: 3128  loss: 69.99892691487366
Learned parameters: [2.2910692717827796, 3.60442287219954, 5.425636423510374, -2.224458313424081]
Epoch: 3129  loss: 69.98133444605355
Learned parameters: [2.29092501987203, 3.6046269828019537, 5.425927405110804, -2.2248556411929687]
Epoch: 3130  loss: 69.96376935053543
Learned parameters: [2.2907808412723507, 3.604830986524421, 5.426218237755155, -2.225252762733527]
Epoch: 3131  loss: 69.94623159006572
Learned parameters: [2.290636735966847, 3.6050348833965877, 5.426508921479148, -2.225649678100258]
Epoch: 3132  loss: 69.9287211264517
Learned parameters: [2.290492703938585, 3.6052386734480697, 5.426799456318385, -2.2260463873475964]
Epoch: 3133  loss: 69.91123792154981
Learned parameters: [2.2903487451707836, 3.6054423567084175, 5.42708984230863, -2.2264428905299507]
Epoch: 3134  loss: 69.8937819372589
Learned parameters: [2.2902048596468263, 3.605645933207118, 5.427380079485836, -2.2268391877017093]
Epoch: 3135  loss: 69.87635313554134
Learned parameters: [2.290061047350088, 3.6058494029736474, 5.427670167885895, -2.227235278917206]
Epoch: 3136  loss: 69.85895147840341
Learned parameters: [2.289917308263802, 3.6060527660375077, 5.427960107544452, -2.227631164230694]
Epoch: 3137  loss: 69.84157692790694
Learned parameters: [2.289773642371132, 3.6062560224282003, 5.428249898496999, -2.2280268436963575]
Epoch: 3138  loss: 69.82422944617838
Learned parameters: [2.289630049655297, 3.6064591721751, 5.428539540778996, -2.22842231736833]
Epoch: 3139  loss: 69.80690899541472
Learned parameters: [2.2894865300996843, 3.606662215307465, 5.428829034426064, -2.2288175853007215]
Epoch: 3140  loss: 69.78961553783991
Learned parameters: [2.2893430836877973, 3.6068651518545174, 5.429118379473947, -2.2292126475476115]
Epoch: 3141  loss: 69.77234903567121
Learned parameters: [2.289199710403227, 3.607067981845952, 5.429407575958795, -2.2296075041630834]
Epoch: 3142  loss: 69.75510945114847
Learned parameters: [2.2890564102291266, 3.607270705311551, 5.4296966239160716, -2.2300021552010825]
Epoch: 3143  loss: 69.73789674664859
Learned parameters: [2.2889131831484564, 3.607473322281058, 5.429985523380872, -2.2303966007154616]
Epoch: 3144  loss: 69.72071088461695
Learned parameters: [2.288770029144441, 3.607675832783957, 5.430274274388516, -2.2307908407600565]
Epoch: 3145  loss: 69.7035518275533
Learned parameters: [2.288626948200769, 3.607878236849551, 5.4305628769749115, -2.231184875388736]
Epoch: 3146  loss: 69.68641953798867
Learned parameters: [2.288483940301199, 3.6080805345070477, 5.430851331175968, -2.2315787046552917]
Epoch: 3147  loss: 69.66931397852062
Learned parameters: [2.288341005429152, 3.6082827257857435, 5.431139637027078, -2.2319723286134057]
Epoch: 3148  loss: 69.65223511178193
Learned parameters: [2.2881981435677483, 3.608484810714996, 5.431427794563156, -2.2323657473166554]
Epoch: 3149  loss: 69.63518290044868
Learned parameters: [2.2880553547002624, 3.60868678932419, 5.431715803819362, -2.2327589608186282]
Epoch: 3150  loss: 69.61815730722992
Learned parameters: [2.287912638810299, 3.6088886616426037, 5.432003664831279, -2.2331519691729285]
Epoch: 3151  loss: 69.60115829491474
Learned parameters: [2.2877699958815696, 3.609090427699435, 5.432291377634581, -2.2335447724331283]
Epoch: 3152  loss: 69.58418582635598
Learned parameters: [2.287627425897564, 3.6092920875237997, 5.432578942264493, -2.2339373706526904]
Epoch: 3153  loss: 69.56723986446555
Learned parameters: [2.287484928841614, 3.6094936411448173, 5.432866358755956, -2.234329763884997]
Epoch: 3154  loss: 69.5503203721968
Learned parameters: [2.2873425046971363, 3.609695088591553, 5.43315362714398, -2.2347219521833956]
Epoch: 3155  loss: 69.5334273125398
Learned parameters: [2.2872001534477677, 3.609896429893014, 5.433440747463859, -2.2351139356012344]
Epoch: 3156  loss: 69.51656064853572
Learned parameters: [2.2870578750772266, 3.610097665078155, 5.433727719750948, -2.235505714191826]
Epoch: 3157  loss: 69.49972034328866
Learned parameters: [2.2869156695690953, 3.610298794175942, 5.434014544040358, -2.2358972880084056]
Epoch: 3158  loss: 69.48290635995883
Learned parameters: [2.2867735369068005, 3.610499817215287, 5.434301220366872, -2.2362886571041045]
Epoch: 3159  loss: 69.46611866176329
Learned parameters: [2.2866314770738514, 3.6107007342250554, 5.43458774876534, -2.23667982153202]
Epoch: 3160  loss: 69.4493572119592
Learned parameters: [2.2864894900539428, 3.6109015452340376, 5.4348741292708285, -2.237070781345234]
Epoch: 3161  loss: 69.4326219738543
Learned parameters: [2.28634757583084, 3.611102250270945, 5.435160361918425, -2.237461536596778]
Epoch: 3162  loss: 69.41591291081815
Learned parameters: [2.286205734388229, 3.6113028493644994, 5.435446446743059, -2.2378520873396166]
Epoch: 3163  loss: 69.39922998625477
Learned parameters: [2.286063965709677, 3.6115033425434437, 5.43573238377945, -2.2382424336266435]
Epoch: 3164  loss: 69.3825731636253
Learned parameters: [2.2859222697787693, 3.6117037298365124, 5.436018173062305, -2.23863257551071]
Epoch: 3165  loss: 69.36594240643456
Learned parameters: [2.285780646579209, 3.6119040112723813, 5.436303814626448, -2.239022513044638]
Epoch: 3166  loss: 69.34933767825177
Learned parameters: [2.2856390960947675, 3.6121041868796326, 5.436589308506714, -2.239412246281207]
Epoch: 3167  loss: 69.33275894269188
Learned parameters: [2.285497618309209, 3.6123042566868375, 5.436874654737887, -2.239801775273144]
Epoch: 3168  loss: 69.31620616341428
Learned parameters: [2.2853562132062706, 3.6125042207226525, 5.4371598533547205, -2.240191100073125]
Epoch: 3169  loss: 69.29967930406204
Learned parameters: [2.285214880769747, 3.6127040790160567, 5.437444904392237, -2.2405802207338184]
Epoch: 3170  loss: 69.28317832834267
Learned parameters: [2.2850736209832445, 3.612903831596029, 5.437729807885119, -2.240969137307804]
Epoch: 3171  loss: 69.26670320006174
Learned parameters: [2.284932433830323, 3.613103478491462, 5.43801456386789, -2.2413578498475983]
Epoch: 3172  loss: 69.25025388310348
Learned parameters: [2.2847913192946887, 3.6133030197310023, 5.438299172375111, -2.2417463584056767]
Epoch: 3173  loss: 69.23383034139027
Learned parameters: [2.2846502773603072, 3.613502455343183, 5.4385836334416595, -2.2421346630345163]
Epoch: 3174  loss: 69.21743253887894
Learned parameters: [2.2845093080111725, 3.6137017853565134, 5.438867947102409, -2.2425227637865564]
Epoch: 3175  loss: 69.20106043956321
Learned parameters: [2.2843684112310667, 3.6139010097995743, 5.439152113391911, -2.242910660714154]
Epoch: 3176  loss: 69.18471400749908
Learned parameters: [2.284227587003599, 3.614100128700964, 5.43943613234442, -2.2432983538695845]
Epoch: 3177  loss: 69.16839320679637
Learned parameters: [2.284086835312483, 3.614299142089182, 5.439720003994243, -2.2436858433050615]
Epoch: 3178  loss: 69.15209800160463
Learned parameters: [2.283946156141729, 3.614498049992734, 5.440003728376144, -2.2440731290728273]
Epoch: 3179  loss: 69.13582835610686
Learned parameters: [2.2838055494753697, 3.614696852440077, 5.440287305524861, -2.2444602112250807]
Epoch: 3180  loss: 69.11958423455685
Learned parameters: [2.2836650152972426, 3.614895549459694, 5.4405707354748065, -2.2448470898139448]
Epoch: 3181  loss: 69.10336560126615
Learned parameters: [2.2835245535910222, 3.615094141079975, 5.440854018260037, -2.2452337648914473]
Epoch: 3182  loss: 69.08717242060223
Learned parameters: [2.2833841643405304, 3.6152926273292305, 5.441137153914764, -2.2456202365095956]
Epoch: 3183  loss: 69.07100465697283
Learned parameters: [2.283243847529834, 3.6154910082356704, 5.441420142473493, -2.2460065047203956]
Epoch: 3184  loss: 69.05486227482119
Learned parameters: [2.2831036031430516, 3.615689283827506, 5.441702983970793, -2.246392569575838]
Epoch: 3185  loss: 69.03874523863388
Learned parameters: [2.2829634311641094, 3.61588745413299, 5.4419856784409175, -2.2467784311278316]
Epoch: 3186  loss: 69.02265351296198
Learned parameters: [2.282823331576781, 3.616085519180394, 5.442268225917856, -2.247164089428207]
Epoch: 3187  loss: 69.00658706240401
Learned parameters: [2.2826833043649044, 3.6162834789979077, 5.442550626435613, -2.2475495445287477]
Epoch: 3188  loss: 68.99054585162008
Learned parameters: [2.282543349512546, 3.616481333613593, 5.4428328800284405, -2.2479347964812226]
Epoch: 3189  loss: 68.9745298453102
Learned parameters: [2.2824034670038884, 3.616679083055455, 5.443114986730704, -2.248319845337373]
Epoch: 3190  loss: 68.95853900821956
Learned parameters: [2.2822636568229986, 3.61687672735151, 5.443396946576562, -2.2487046911488684]
Epoch: 3191  loss: 68.94257330515049
Learned parameters: [2.282123918953768, 3.617074266529774, 5.44367875959985, -2.2490893339672837]
Epoch: 3192  loss: 68.92663270094953
Learned parameters: [2.2819842533801205, 3.617271700618239, 5.443960425834408, -2.2494737738441555]
Epoch: 3193  loss: 68.91071716050614
Learned parameters: [2.281844660086153, 3.6174690296448504, 5.444241945314292, -2.2498580108310056]
Epoch: 3194  loss: 68.89482664874954
Learned parameters: [2.281705139056083, 3.6176662536375574, 5.444523318073719, -2.2502420449793377]
Epoch: 3195  loss: 68.87896113065543
Learned parameters: [2.281565690274016, 3.617863372624325, 5.444804544146703, -2.250625876340588]
Epoch: 3196  loss: 68.86312057125724
Learned parameters: [2.281426313723929, 3.6180603866331644, 5.445085623567055, -2.2510095049661247]
Epoch: 3197  loss: 68.84730493557848
Learned parameters: [2.281287009389941, 3.618257295692404, 5.445366556368978, -2.2513929309073255]
Epoch: 3198  loss: 68.83151418869946
Learned parameters: [2.281147777256084, 3.61845409983032, 5.445647342586473, -2.251776154215497]
Epoch: 3199  loss: 68.81574829579151
Learned parameters: [2.2810086173063704, 3.6186507990751284, 5.4459279822534405, -2.2521591749418937]
Epoch: 3200  loss: 68.80000722208683
Learned parameters: [2.2808695295248484, 3.6188473934548107, 5.446208475403656, -2.252541993137713]
Epoch: 3201  loss: 68.78429093289294
Learned parameters: [2.2807305138957363, 3.6190438829972162, 5.446488822071055, -2.2529246088541335]
Epoch: 3202  loss: 68.76859939352508
Learned parameters: [2.2805915704033195, 3.619240267730138, 5.446769022289615, -2.253307022142303]
Epoch: 3203  loss: 68.75293256935137
Learned parameters: [2.28045269903181, 3.6194365476813894, 5.447049076093182, -2.2536892330533163]
Epoch: 3204  loss: 68.73729042577028
Learned parameters: [2.2803138997652854, 3.619632722878823, 5.447328983515384, -2.2540712416382043]
Epoch: 3205  loss: 68.72167292824494
Learned parameters: [2.2801751725878217, 3.6198287933502575, 5.447608744589797, -2.2544530479479534]
Epoch: 3206  loss: 68.70608004227992
Learned parameters: [2.2800365174836292, 3.6200247591234436, 5.447888359350138, -2.2548346520335327]
Epoch: 3207  loss: 68.69051173340992
Learned parameters: [2.2798979344370656, 3.6202206202261626, 5.448167827830357, -2.255216053945912]
Epoch: 3208  loss: 68.674967967226
Learned parameters: [2.279759423432391, 3.6204163766861663, 5.4484471500641956, -2.2555972537359867]
Epoch: 3209  loss: 68.65944870939072
Learned parameters: [2.279620984453718, 3.620612028531176, 5.448726326085098, -2.255978251454553]
Epoch: 3210  loss: 68.64395392560712
Learned parameters: [2.2794826174851757, 3.620807575788803, 5.449005355926431, -2.256359047152352]
Epoch: 3211  loss: 68.62848358164594
Learned parameters: [2.279344322511078, 3.6210030184865336, 5.449284239621746, -2.2567396408801073]
Epoch: 3212  loss: 68.61303764330373
Learned parameters: [2.2792060995158674, 3.6211983566518, 5.4495629772047405, -2.25712003268853]
Epoch: 3213  loss: 68.59761607641194
Learned parameters: [2.279067948483922, 3.6213935903120436, 5.449841568708987, -2.257500222628284]
Epoch: 3214  loss: 68.58221884685345
Learned parameters: [2.2789298693994615, 3.621588719494766, 5.450120014167816, -2.257880210749969]
Epoch: 3215  loss: 68.56684592055481
Learned parameters: [2.278791862246664, 3.621783744227458, 5.450398313614454, -2.2582599971041315]
Epoch: 3216  loss: 68.55149726349264
Learned parameters: [2.2786539270098456, 3.621978664537552, 5.450676467082284, -2.2586395817413063]
Epoch: 3217  loss: 68.53617284168888
Learned parameters: [2.27851606367345, 3.6221734804523975, 5.450954474604804, -2.259018964712002]
Epoch: 3218  loss: 68.52087262123007
Learned parameters: [2.278378272221914, 3.622368191999299, 5.451232336215442, -2.259398146066671]
Epoch: 3219  loss: 68.50559656823326
Learned parameters: [2.2782405526395832, 3.622562799205572, 5.451510051947452, -2.2597771258557042]
Epoch: 3220  loss: 68.49034464886508
Learned parameters: [2.278102904910746, 3.6227573020985355, 5.45178762183397, -2.2601559041294377]
Epoch: 3221  loss: 68.47511682933639
Learned parameters: [2.2779653290197563, 3.6229517007054493, 5.45206504590816, -2.2605344809381647]
Epoch: 3222  loss: 68.45991307590951
Learned parameters: [2.2778278249510877, 3.623145995053553, 5.452342324203335, -2.2609128563321548]
Epoch: 3223  loss: 68.44473335488031
Learned parameters: [2.2776903926892254, 3.6233401851700653, 5.452619456752782, -2.261291030361635]
Epoch: 3224  loss: 68.42957763260054
Learned parameters: [2.277553032218583, 3.623534271082211, 5.452896443589642, -2.2616690030767748]
Epoch: 3225  loss: 68.41444587544392
Learned parameters: [2.277415743523619, 3.6237282528174446, 5.453173284747256, -2.262046774527738]
Epoch: 3226  loss: 68.3993380497721
Learned parameters: [2.277278526588741, 3.6239221304033533, 5.453449980258933, -2.2624243447646477]
Epoch: 3227  loss: 68.38425412205214
Learned parameters: [2.277141381398261, 3.6241159038674926, 5.453726530157782, -2.2628017138375607]
Epoch: 3228  loss: 68.36919405881304
Learned parameters: [2.277004307936552, 3.6243095732373307, 5.454002934476928, -2.2631788817964975]
Epoch: 3229  loss: 68.35415782665302
Learned parameters: [2.276867306188073, 3.6245031385400472, 5.454279193249409, -2.26355584869142]
Epoch: 3230  loss: 68.3391453922149
Learned parameters: [2.276730376137452, 3.6246965998027396, 5.454555306508459, -2.263932614572279]
Epoch: 3231  loss: 68.32415672216926
Learned parameters: [2.2765935177693, 3.6248899570524813, 5.454831274287238, -2.2643091794889796]
Epoch: 3232  loss: 68.30919178322685
Learned parameters: [2.2764567310680883, 3.6250832103163675, 5.455107096618673, -2.2646855434913613]
Epoch: 3233  loss: 68.29425054214477
Learned parameters: [2.2763200160182198, 3.625276359621501, 5.4553827735355584, -2.2650617066292105]
Epoch: 3234  loss: 68.27933296572465
Learned parameters: [2.2761833726041916, 3.6254694049949276, 5.4556583050707745, -2.265437668952287]
Epoch: 3235  loss: 68.26443902081562
Learned parameters: [2.276046800810632, 3.625662346463626, 5.45593369125734, -2.265813430510331]
Epoch: 3236  loss: 68.2495686743024
Learned parameters: [2.2759103006222214, 3.6258551840546107, 5.456208932128357, -2.266188991353065]
Epoch: 3237  loss: 68.23472189310132
Learned parameters: [2.275773872023514, 3.6260479177949434, 5.456484027716727, -2.266564351530153]
Epoch: 3238  loss: 68.21989864419486
Learned parameters: [2.2756375149989525, 3.626240547711684, 5.456758978055149, -2.266939511091193]
Epoch: 3239  loss: 68.20509889460428
Learned parameters: [2.2755012295330386, 3.62643307383184, 5.457033783176349, -2.2673144700857497]
Epoch: 3240  loss: 68.19032261141666
Learned parameters: [2.2753650156104253, 3.6266254961822617, 5.45730844311316, -2.2676892285633476]
Epoch: 3241  loss: 68.17556976220233
Learned parameters: [2.2752288732185506, 3.6268178147902015, 5.457582957897391, -2.268063786566183]
Epoch: 3242  loss: 68.16084031525799
Learned parameters: [2.275092802339491, 3.6270100296830274, 5.457857327558621, -2.2684381441440196]
Epoch: 3243  loss: 68.14613423639182
Learned parameters: [2.274956802957446, 3.6272021408874457, 5.4581315521293075, -2.2688123013469097]
Epoch: 3244  loss: 68.13145149283798
Learned parameters: [2.274820875058891, 3.6273941484294876, 5.458405631645039, -2.269186258225234]
Epoch: 3245  loss: 68.11679205187342
Learned parameters: [2.2746850186298735, 3.6275860523353174, 5.458679566140729, -2.2695600148292123]
Epoch: 3246  loss: 68.10215588081903
Learned parameters: [2.2745492336541266, 3.6277778526317923, 5.458953355647963, -2.2699335712085507]
Epoch: 3247  loss: 68.08754294704643
Learned parameters: [2.2744135201143454, 3.6279695493460737, 5.459227000196791, -2.270306927412675]
Epoch: 3248  loss: 68.07295321798462
Learned parameters: [2.2742778779946526, 3.628161142504829, 5.459500499819164, -2.2706800834911682]
Epoch: 3249  loss: 68.05838666110363
Learned parameters: [2.274142307281092, 3.628352632134139, 5.459773854549668, -2.2710530394938853]
Epoch: 3250  loss: 68.04384324390911
Learned parameters: [2.2740068079596485, 3.628544018260111, 5.4600470644227554, -2.271425795470591]
Epoch: 3251  loss: 68.02932293394744
Learned parameters: [2.27387138001458, 3.6287353009094465, 5.460320129470445, -2.2717983514706557]
Epoch: 3252  loss: 68.01482569880827
Learned parameters: [2.2737360234290596, 3.6289264801091385, 5.460593049723151, -2.2721707075431636]
Epoch: 3253  loss: 68.00035150614588
Learned parameters: [2.2736007381871928, 3.6291175558858795, 5.460865825212542, -2.272542863737292]
Epoch: 3254  loss: 67.98590032364275
Learned parameters: [2.2734655242747013, 3.6293085282659088, 5.461138455972531, -2.2729148201024425]
Epoch: 3255  loss: 67.97147211898329
Learned parameters: [2.273330381677578, 3.6294993972756906, 5.461410942037559, -2.2732865766880095]
Epoch: 3256  loss: 67.95706685990639
Learned parameters: [2.273195310380299, 3.6296901629421114, 5.461683283439875, -2.273658133543044]
Epoch: 3257  loss: 67.9426845142223
Learned parameters: [2.2730603103662896, 3.6298808252923367, 5.461955480210192, -2.2740294907163405]
Epoch: 3258  loss: 67.9283250497912
Learned parameters: [2.272925381619671, 3.6300713843532577, 5.462227532380124, -2.274400648256754]
Epoch: 3259  loss: 67.91398843453638
Learned parameters: [2.2727905241259387, 3.6302618401511353, 5.46249943998305, -2.274771606213314]
Epoch: 3260  loss: 67.89967463642802
Learned parameters: [2.2726557378709797, 3.63045219271209, 5.4627712030528475, -2.2751423646350624]
Epoch: 3261  loss: 67.88538362346276
Learned parameters: [2.2725210228396437, 3.63064244206253, 5.46304282162189, -2.2755129235707905]
Epoch: 3262  loss: 67.87111536367843
Learned parameters: [2.272386379015799, 3.6308325882291452, 5.46331429572113, -2.275883283069056]
Epoch: 3263  loss: 67.85686982515875
Learned parameters: [2.2722518063836468, 3.6310226312385137, 5.463585625381946, -2.276253443178423]
Epoch: 3264  loss: 67.84264697602723
Learned parameters: [2.272117304928486, 3.6312125711168624, 5.463856810637221, -2.276623403947601]
Epoch: 3265  loss: 67.82844678445527
Learned parameters: [2.2719828746360315, 3.631402407890273, 5.464127851520371, -2.276993165425321]
Epoch: 3266  loss: 67.81426921865206
Learned parameters: [2.271848515491288, 3.631592141585027, 5.4643987480637755, -2.2773627276601354]
Epoch: 3267  loss: 67.80011424686185
Learned parameters: [2.2717142274784865, 3.631781772227754, 5.464669500298772, -2.2777320907004253]
Epoch: 3268  loss: 67.78598183735858
Learned parameters: [2.2715800105819386, 3.631971299845049, 5.4649401082567755, -2.2781012545945387]
Epoch: 3269  loss: 67.77187195847625
Learned parameters: [2.2714458647867577, 3.632160724463239, 5.465210571970279, -2.2784702193909236]
Epoch: 3270  loss: 67.75778457860116
Learned parameters: [2.2713117900784985, 3.6323500461084897, 5.465480891472348, -2.2788389851380613]
Epoch: 3271  loss: 67.74371966615692
Learned parameters: [2.2711777864422666, 3.6325392648070123, 5.465751066795324, -2.279207551884292]
Epoch: 3272  loss: 67.72967718963142
Learned parameters: [2.2710438538625435, 3.6327283805851533, 5.466021097970606, -2.279575919677791]
Epoch: 3273  loss: 67.71565711754066
Learned parameters: [2.2709099923238405, 3.6329173934692247, 5.4662909850295875, -2.27994408856669]
Epoch: 3274  loss: 67.70165941844571
Learned parameters: [2.2707762018112767, 3.6331063034853006, 5.466560728004436, -2.2803120585991596]
Epoch: 3275  loss: 67.68768406095549
Learned parameters: [2.2706424823103313, 3.6332951106593465, 5.466830326927796, -2.2806798298234012]
Epoch: 3276  loss: 67.67373101370613
Learned parameters: [2.270508833806187, 3.633483815017425, 5.467099781831873, -2.2810474022875273]
Epoch: 3277  loss: 67.65980024537409
Learned parameters: [2.270375256283508, 3.6336724165857404, 5.467369092748103, -2.281414776039517]
Epoch: 3278  loss: 67.64589172468796
Learned parameters: [2.2702417497269325, 3.6338609153904953, 5.467638259707854, -2.2817819511273125]
Epoch: 3279  loss: 67.63200542040849
Learned parameters: [2.2701083141215506, 3.634049311457741, 5.467907282743089, -2.282148927598901]
Epoch: 3280  loss: 67.61814130135609
Learned parameters: [2.269974949452769, 3.6342376048133627, 5.468176161886133, -2.282515705502272]
Epoch: 3281  loss: 67.60429933638423
Learned parameters: [2.269841655705849, 3.6344257954833252, 5.4684448971691, -2.2828822848853507]
Epoch: 3282  loss: 67.59047949437662
Learned parameters: [2.269708432865627, 3.6346138834937376, 5.468713488623485, -2.283248665795951]
Epoch: 3283  loss: 67.57668174426374
Learned parameters: [2.269575280916835, 3.6348018688707318, 5.468981936280611, -2.2836148482818426]
Epoch: 3284  loss: 67.56290605502178
Learned parameters: [2.2694421998445407, 3.634989751640293, 5.469250240172211, -2.283980832390809]
Epoch: 3285  loss: 67.549152395671
Learned parameters: [2.2693091896341597, 3.635177531828368, 5.469518400330514, -2.28434661817066]
Epoch: 3286  loss: 67.53542073523485
Learned parameters: [2.2691762502710255, 3.6353652094610576, 5.469786416787691, -2.2847122056691638]
Epoch: 3287  loss: 67.52171104279986
Learned parameters: [2.26904338174002, 3.635552784564556, 5.47005428957522, -2.2850775949339686]
Epoch: 3288  loss: 67.50802328750461
Learned parameters: [2.2689105840258916, 3.635740257165061, 5.470322018724351, -2.285442786012667]
Epoch: 3289  loss: 67.49435743852808
Learned parameters: [2.268777857113726, 3.6359276272886207, 5.4705896042667534, -2.285807778952883]
Epoch: 3290  loss: 67.48071346512157
Learned parameters: [2.268645200988883, 3.6361148949609383, 5.470857046234292, -2.2861725738022343]
Epoch: 3291  loss: 67.46709133657697
Learned parameters: [2.268512615636775, 3.6363020602076874, 5.47112434465887, -2.286537170608316]
Epoch: 3292  loss: 67.45349102220453
Learned parameters: [2.268380101042534, 3.6364891230546124, 5.471391499571969, -2.2869015694186365]
Epoch: 3293  loss: 67.43991249135613
Learned parameters: [2.2682476571910892, 3.636676083527498, 5.471658511004745, -2.2872657702806296]
Epoch: 3294  loss: 67.42635571342883
Learned parameters: [2.2681152840675143, 3.6368629416520926, 5.471925378988534, -2.2876297732417203]
Epoch: 3295  loss: 67.41282065784837
Learned parameters: [2.2679829816571586, 3.6370496974540543, 5.472192103555033, -2.287993578349348]
Epoch: 3296  loss: 67.39930729409107
Learned parameters: [2.2678507499454184, 3.6372363509590127, 5.472458684735969, -2.288357185650925]
Epoch: 3297  loss: 67.3858155916736
Learned parameters: [2.2677185889174822, 3.6374229021926454, 5.472725122562746, -2.2887205951937886]
Epoch: 3298  loss: 67.37234552014752
Learned parameters: [2.267586498558409, 3.637609351180714, 5.472991417066592, -2.289083807025229]
Epoch: 3299  loss: 67.35889704908186
Learned parameters: [2.2674544788533586, 3.637795697949031, 5.473257568278909, -2.2894468211925325]
Epoch: 3300  loss: 67.34547014810639
Learned parameters: [2.267322529787618, 3.6379819425233384, 5.47352357623123, -2.289809637742968]
Epoch: 3301  loss: 67.33206478689681
Learned parameters: [2.267190651346517, 3.6381680849293345, 5.473789440955109, -2.2901722567237752]
Epoch: 3302  loss: 67.3186809351655
Learned parameters: [2.267058843515304, 3.638354125192717, 5.474055162481945, -2.2905346781821425]
Epoch: 3303  loss: 67.30531856268003
Learned parameters: [2.266927106279133, 3.638540063339122, 5.4743207408429235, -2.2908969021651946]
Epoch: 3304  loss: 67.29197763924597
Learned parameters: [2.2667954396232317, 3.63872589939413, 5.47458617606929, -2.2912589287200307]
Epoch: 3305  loss: 67.27865813470525
Learned parameters: [2.266663843532966, 3.6389116333832607, 5.474851468192449, -2.2916207578937384]
Epoch: 3306  loss: 67.26536001894118
Learned parameters: [2.266532317993714, 3.6390972653320124, 5.475116617243789, -2.291982389733371]
Epoch: 3307  loss: 67.25208326187749
Learned parameters: [2.26640086299076, 3.6392827952658693, 5.475381623254509, -2.292343824285909]
Epoch: 3308  loss: 67.23882783348475
Learned parameters: [2.2662694785093302, 3.639468223210306, 5.475646486255681, -2.292705061598277]
Epoch: 3309  loss: 67.22559370376632
Learned parameters: [2.266138164534726, 3.639653549190761, 5.475911206278455, -2.2930661017173777]
Epoch: 3310  loss: 67.21238084276828
Learned parameters: [2.2660069210523535, 3.6398387732326274, 5.476175783354094, -2.293426944690101]
Epoch: 3311  loss: 67.19918922057248
Learned parameters: [2.26587574804762, 3.6400238953612845, 5.476440217513836, -2.2937875905633023]
Epoch: 3312  loss: 67.18601880730306
Learned parameters: [2.2657446455058468, 3.6402089156021034, 5.4767045087887505, -2.2941480393837845]
Epoch: 3313  loss: 67.17286957312714
Learned parameters: [2.265613613412311, 3.640393833980447, 5.47696865720981, -2.2945082911983072]
Epoch: 3314  loss: 67.15974148825336
Learned parameters: [2.2654826517523814, 3.6405786505216393, 5.477232662808087, -2.2948683460536126]
Epoch: 3315  loss: 67.14663452291796
Learned parameters: [2.265351760511504, 3.64076336525097, 5.477496525614732, -2.2952282039964214]
Epoch: 3316  loss: 67.13354864740917
Learned parameters: [2.265220939675137, 3.6409479781937595, 5.4777602456609085, -2.295587865073425]
Epoch: 3317  loss: 67.12048383201432
Learned parameters: [2.2650901892287054, 3.6411324893755284, 5.478023822977829, -2.2959473293312804]
Epoch: 3318  loss: 67.10744004707391
Learned parameters: [2.2649595091574706, 3.6413168988218096, 5.478287257596431, -2.2963065968165814]
Epoch: 3319  loss: 67.09441726298503
Learned parameters: [2.264828899446709, 3.6415012065580936, 5.478550549547629, -2.2966656675758923]
Epoch: 3320  loss: 67.08141545018596
Learned parameters: [2.2646983600818795, 3.6416854126097795, 5.478813698862549, -2.297024541655777]
Epoch: 3321  loss: 67.06843457916474
Learned parameters: [2.2645678910484777, 3.6418695170020587, 5.479076705572227, -2.2973832191027617]
Epoch: 3322  loss: 67.0554746204786
Learned parameters: [2.26443749233198, 3.642053519760026, 5.47933956970759, -2.297741699963338]
Epoch: 3323  loss: 67.04253554468896
Learned parameters: [2.2643071639178323, 3.6422374209087804, 5.479602291299498, -2.2980999842839633]
Epoch: 3324  loss: 67.02961732239652
Learned parameters: [2.264176905791475, 3.6424212204734157, 5.479864870378779, -2.298458072111059]
Epoch: 3325  loss: 67.01671992424116
Learned parameters: [2.264046717938372, 3.642604918479012, 5.480127306976264, -2.298815963491018]
Epoch: 3326  loss: 67.00384332089985
Learned parameters: [2.2639166003440194, 3.6427885149506354, 5.480389601122807, -2.299173658470204]
Epoch: 3327  loss: 66.99098748308951
Learned parameters: [2.2637865529939236, 3.642972009913341, 5.480651752849245, -2.2995311570949473]
Epoch: 3328  loss: 66.97815238157041
Learned parameters: [2.2636565758735707, 3.643155403392182, 5.4809137621863595, -2.2998884594115396]
Epoch: 3329  loss: 66.96533798713357
Learned parameters: [2.2635266689684483, 3.6433386954122016, 5.481175629164903, -2.3002455654662355]
Epoch: 3330  loss: 66.95254427061445
Learned parameters: [2.2633968322640885, 3.6435218859984797, 5.481437353815701, -2.3006024753052716]
Epoch: 3331  loss: 66.93977120285052
Learned parameters: [2.2632670657460556, 3.6437049751762123, 5.481698936169687, -2.300959188974879]
Epoch: 3332  loss: 66.92701875474043
Learned parameters: [2.2631373693998214, 3.6438879629706005, 5.481960376257629, -2.301315706521239]
Epoch: 3333  loss: 66.91428689722801
Learned parameters: [2.2630077432108253, 3.644070849406825, 5.482221674110209, -2.30167202799049]
Epoch: 3334  loss: 66.9015756012992
Learned parameters: [2.2628781871645804, 3.6442536345100165, 5.48248282975817, -2.3020281534287452]
Epoch: 3335  loss: 66.88888483798333
Learned parameters: [2.262748701246698, 3.644436318305233, 5.482743843232343, -2.302384082882099]
Epoch: 3336  loss: 66.87621457834447
Learned parameters: [2.262619285442781, 3.6446189008175023, 5.483004714563508, -2.3027398163966093]
Epoch: 3337  loss: 66.86356479348419
Learned parameters: [2.2624899397383618, 3.6448013820718543, 5.483265443782315, -2.303095354018291]
Epoch: 3338  loss: 66.85093545454562
Learned parameters: [2.2623606641189564, 3.644983762093301, 5.483526030919355, -2.3034506957931216]
Epoch: 3339  loss: 66.83832653270538
Learned parameters: [2.262231458570133, 3.6451660409068167, 5.483786476005259, -2.3038058417670535]
Epoch: 3340  loss: 66.82573799918433
Learned parameters: [2.262102323077518, 3.6453482185373387, 5.484046779070707, -2.3041607919860185]
Epoch: 3341  loss: 66.81316982523981
Learned parameters: [2.261973257626744, 3.6455302950097703, 5.484306940146341, -2.3045155464959044]
Epoch: 3342  loss: 66.80062198217539
Learned parameters: [2.261844262203401, 3.6457122703489815, 5.48456695926269, -2.3048701053425407]
Epoch: 3343  loss: 66.78809444132995
Learned parameters: [2.2617153367930736, 3.64589414457982, 5.484826836450235, -2.305224468571724]
Epoch: 3344  loss: 66.77558717408125
Learned parameters: [2.261586481381373, 3.6460759177270794, 5.485086571739452, -2.3055786362292263]
Epoch: 3345  loss: 66.76310015184592
Learned parameters: [2.2614576959539523, 3.6462575898154888, 5.485346165160819, -2.305932608360785]
Epoch: 3346  loss: 66.75063334608585
Learned parameters: [2.261328980496506, 3.6464391608697473, 5.485605616744838, -2.306286385012115]
Epoch: 3347  loss: 66.73818672828075
Learned parameters: [2.261200334994709, 3.6466206309145615, 5.485864926521972, -2.306639966228906]
Epoch: 3348  loss: 66.72576026995677
Learned parameters: [2.2610717594342384, 3.6468019999747314, 5.486124094522724, -2.3069933520568227]
Epoch: 3349  loss: 66.71335394264239
Learned parameters: [2.2609432538007397, 3.6469832680751737, 5.486383120777597, -2.3073465425415]
Epoch: 3350  loss: 66.7009677179247
Learned parameters: [2.260814818079794, 3.6471644352407693, 5.4866420053169485, -2.3076995377285234]
Epoch: 3351  loss: 66.68860156745231
Learned parameters: [2.2606864522570387, 3.6473455014963454, 5.486900748171172, -2.308052337663456]
Epoch: 3352  loss: 66.67625546289007
Learned parameters: [2.2605581563182167, 3.6475264668666783, 5.48715934937078, -2.3084049423918587]
Epoch: 3353  loss: 66.66392937596336
Learned parameters: [2.2604299302490207, 3.647707331376345, 5.4874178089460655, -2.3087573519592395]
Epoch: 3354  loss: 66.65162327846784
Learned parameters: [2.2603017740351348, 3.647888095049802, 5.487676126927205, -2.309109566411065]
Epoch: 3355  loss: 66.6393371422009
Learned parameters: [2.260173687662345, 3.6480687579114934, 5.487934303344518, -2.309461585792797]
Epoch: 3356  loss: 66.62707093898679
Learned parameters: [2.2600456711164387, 3.648249319985874, 5.48819233822831, -2.3098134101498724]
Epoch: 3357  loss: 66.61482464069199
Learned parameters: [2.25991772438315, 3.6484297812974176, 5.488450231608794, -2.3101650395276865]
Epoch: 3358  loss: 66.60259821921301
Learned parameters: [2.2597898474481743, 3.6486101418706403, 5.48870798351613, -2.3105164739716058]
Epoch: 3359  loss: 66.5903916464864
Learned parameters: [2.2596620402972323, 3.648790401730059, 5.4889655939804936, -2.310867713526969]
Epoch: 3360  loss: 66.57820489448554
Learned parameters: [2.259534302916113, 3.6489705609001697, 5.489223063032138, -2.3112187582390953]
Epoch: 3361  loss: 66.56603793522284
Learned parameters: [2.2594066352906235, 3.6491506194054613, 5.489480390701315, -2.3115696081532735]
Epoch: 3362  loss: 66.55389074074884
Learned parameters: [2.259279037406532, 3.6493305772704288, 5.489737577018199, -2.311920263314753]
Epoch: 3363  loss: 66.54176328313754
Learned parameters: [2.2591515092496253, 3.6495104345196845, 5.48999462201305, -2.312270723768772]
Epoch: 3364  loss: 66.52965553448837
Learned parameters: [2.259024050805649, 3.649690191177883, 5.49025152571607, -2.3126209895605343]
Epoch: 3365  loss: 66.51756746695372
Learned parameters: [2.2588966620603395, 3.649869847269659, 5.49050828815741, -2.31297106073521]
Epoch: 3366  loss: 66.50549905272959
Learned parameters: [2.258769342999485, 3.650049402819615, 5.49076490936727, -2.313320937337947]
Epoch: 3367  loss: 66.49345026404316
Learned parameters: [2.2586420936089167, 3.6502288578523134, 5.491021389375871, -2.313670619413868]
Epoch: 3368  loss: 66.48142107316535
Learned parameters: [2.258514913874455, 3.650408212392263, 5.491277728213363, -2.3140201070080546]
Epoch: 3369  loss: 66.46941145241523
Learned parameters: [2.258387803781898, 3.6505874664639415, 5.491533925909819, -2.314369400165549]
Epoch: 3370  loss: 66.45742137413154
Learned parameters: [2.258260763317054, 3.6507666200918036, 5.491789982495298, -2.3147184989313634]
Epoch: 3371  loss: 66.4454508106952
Learned parameters: [2.258133792465781, 3.650945673300281, 5.492045897999907, -2.315067403350493]
Epoch: 3372  loss: 66.43349973452344
Learned parameters: [2.258006891213942, 3.6511246261137846, 5.49230167245373, -2.315416113467904]
Epoch: 3373  loss: 66.42156811806706
Learned parameters: [2.2578800595473716, 3.6513034785567156, 5.492557305886783, -2.3157646293285263]
Epoch: 3374  loss: 66.40965593381796
Learned parameters: [2.2577532974519103, 3.6514822306534556, 5.492812798329061, -2.3161129509772627]
Epoch: 3375  loss: 66.3977631543021
Learned parameters: [2.257626604913419, 3.6516608824283727, 5.493068149810567, -2.3164610784589885]
Epoch: 3376  loss: 66.38588975207618
Learned parameters: [2.2574999819177837, 3.65183943390582, 5.493323360361305, -2.3168090118185405]
Epoch: 3377  loss: 66.37403569974877
Learned parameters: [2.2573734284508746, 3.6520178851101135, 5.493578430011215, -2.3171567511007116]
Epoch: 3378  loss: 66.3622009699596
Learned parameters: [2.257246944498572, 3.6521962360655364, 5.49383335879021, -2.317504296350266]
Epoch: 3379  loss: 66.350385535384
Learned parameters: [2.2571205300467723, 3.6523744867963166, 5.494088146728178, -2.3178516476119357]
Epoch: 3380  loss: 66.33858936873861
Learned parameters: [2.2569941850814215, 3.65255263732671, 5.494342793855083, -2.3181988049304376]
Epoch: 3381  loss: 66.32681244273579
Learned parameters: [2.2568679095885127, 3.6527306876811454, 5.494597300201057, -2.3185457683504826]
Epoch: 3382  loss: 66.31505473013115
Learned parameters: [2.2567417035538693, 3.6529086378840736, 5.4948516657959665, -2.3188925379167364]
Epoch: 3383  loss: 66.30331620373865
Learned parameters: [2.2566155669632577, 3.6530864879599227, 5.495105890669558, -2.31923911367383]
Epoch: 3384  loss: 66.29159683640961
Learned parameters: [2.2564894998025853, 3.6532642379330142, 5.495359974851717, -2.319585495666385]
Epoch: 3385  loss: 66.27989660103324
Learned parameters: [2.2563635020579054, 3.653441887827567, 5.495613918372483, -2.3199316839390223]
Epoch: 3386  loss: 66.26821547056318
Learned parameters: [2.256237573715144, 3.6536194376675533, 5.4958677212615195, -2.3202776785362946]
Epoch: 3387  loss: 66.25655341815715
Learned parameters: [2.256111714760202, 3.6537968874777027, 5.49612138354821, -2.3206234795007483]
Epoch: 3388  loss: 66.24491041673404
Learned parameters: [2.2559859251791385, 3.6539742372818758, 5.4963749052624085, -2.3209690868771498]
Epoch: 3389  loss: 66.23328643925119
Learned parameters: [2.255860204958261, 3.6541514871038694, 5.4966282864342935, -2.321314500710276]
Epoch: 3390  loss: 66.2216814587684
Learned parameters: [2.2557345540836122, 3.6543286369675676, 5.496881527093653, -2.321659721044822]
Epoch: 3391  loss: 66.2100954483854
Learned parameters: [2.2556089725409105, 3.654505686896995, 5.497134627269817, -2.32200474792539]
Epoch: 3392  loss: 66.19852838122739
Learned parameters: [2.2554834603158986, 3.6546826369161742, 5.4973875869921285, -2.3223495813965465]
Epoch: 3393  loss: 66.18698023047149
Learned parameters: [2.2553580173946615, 3.654859487049018, 5.497640406290381, -2.322694221502879]
Epoch: 3394  loss: 66.17545096932265
Learned parameters: [2.2552326437634473, 3.6550362373193916, 5.497893085194581, -2.323038668288969]
Epoch: 3395  loss: 66.16394057101647
Learned parameters: [2.255107339408321, 3.655212887751217, 5.498145623734457, -2.3233829217993294]
Epoch: 3396  loss: 66.15244900882942
Learned parameters: [2.254982104315093, 3.6553894383685424, 5.498398021939396, -2.3237269820783943]
Epoch: 3397  loss: 66.14097625605433
Learned parameters: [2.2548569384696164, 3.655565889195472, 5.498650279838871, -2.3240708491705737]
Epoch: 3398  loss: 66.12952228602896
Learned parameters: [2.254731841857956, 3.655742240256025, 5.49890239746262, -2.3244145231202715]
Epoch: 3399  loss: 66.11808707213987
Learned parameters: [2.2546068144662814, 3.6559184915741656, 5.4991543748405, -2.3247580039718696]
Epoch: 3400  loss: 66.10667058779876
Learned parameters: [2.2544818562806594, 3.656094643173871, 5.499406212002192, -2.3251012917696916]
Epoch: 3401  loss: 66.0952728064592
Learned parameters: [2.2543569672870043, 3.6562706950791557, 5.4996579089771505, -2.3254443865580017]
Epoch: 3402  loss: 66.08389370160796
Learned parameters: [2.254232147471233, 3.6564466473139903, 5.499909465794788, -2.3257872883810218]
Epoch: 3403  loss: 66.07253324679584
Learned parameters: [2.2541073968192826, 3.656622499901917, 5.500160882484286, -2.3261299972829494]
Epoch: 3404  loss: 66.06119141564645
Learned parameters: [2.253982715317402, 3.656798252866298, 5.500412159075195, -2.3264725133080018]
Epoch: 3405  loss: 66.04986818176218
Learned parameters: [2.2538581029519364, 3.6569739062305024, 5.500663295597207, -2.326814836500373]
Epoch: 3406  loss: 66.0385635187809
Learned parameters: [2.253733559708971, 3.657149460018015, 5.500914292079652, -2.3271569669041727]
Epoch: 3407  loss: 66.02727740036482
Learned parameters: [2.253609085574375, 3.657324914252421, 5.501165148551563, -2.327498904563435]
Epoch: 3408  loss: 66.01600980021684
Learned parameters: [2.253484680534148, 3.6575002689573384, 5.501415865042178, -2.3278406495221753]
Epoch: 3409  loss: 66.00476069205769
Learned parameters: [2.25336034457454, 3.657675524156399, 5.501666441581116, -2.328182201824412]
Epoch: 3410  loss: 65.99353004965725
Learned parameters: [2.2532360776818003, 3.6578506798732464, 5.501916878197981, -2.3285235615141238]
Epoch: 3411  loss: 65.9823178468165
Learned parameters: [2.253111879841978, 3.6580257361315938, 5.50216717492208, -2.3288647286352155]
Epoch: 3412  loss: 65.97112405737204
Learned parameters: [2.2529877510410308, 3.6582006929551776, 5.502417331782565, -2.3292057032315294]
Epoch: 3413  loss: 65.95994865520885
Learned parameters: [2.2528636912650493, 3.6583755503676594, 5.50266734880872, -2.329546485346876]
Epoch: 3414  loss: 65.94879161422784
Learned parameters: [2.252739700500376, 3.6585503083928232, 5.502917226030283, -2.3298870750250806]
Epoch: 3415  loss: 65.93765290834476
Learned parameters: [2.2526157787332237, 3.6587249670544875, 5.503166963476784, -2.3302274723099115]
Epoch: 3416  loss: 65.92653251154027
Learned parameters: [2.252491925949574, 3.658899526376527, 5.503416561177401, -2.3305676772450665]
Epoch: 3417  loss: 65.91543039781573
Learned parameters: [2.2523681421354214, 3.659073986382801, 5.503666019161306, -2.3309076898742185]
Epoch: 3418  loss: 65.90434654121559
Learned parameters: [2.2522444272769784, 3.6592483470970936, 5.503915337457952, -2.331247510241054]
Epoch: 3419  loss: 65.89328091581619
Learned parameters: [2.2521207813605444, 3.6594226085430375, 5.504164516096815, -2.3315871383892426]
Epoch: 3420  loss: 65.88223349577078
Learned parameters: [2.251997204372307, 3.659596770744154, 5.504413555107105, -2.331926574362397]
Epoch: 3421  loss: 65.87120425523105
Learned parameters: [2.2518736962984063, 3.659770833723991, 5.504662454517952, -2.332265818204098]
Epoch: 3422  loss: 65.86019316838016
Learned parameters: [2.251750257125025, 3.6599447975060957, 5.504911214358535, -2.33260486995791]
Epoch: 3423  loss: 65.84920020943379
Learned parameters: [2.251626886838412, 3.6601186621140025, 5.505159834658111, -2.332943729667385]
Epoch: 3424  loss: 65.8382253526405
Learned parameters: [2.2515035854248127, 3.660292427571258, 5.505408315445922, -2.3332823973760526]
Epoch: 3425  loss: 65.82726857227487
Learned parameters: [2.2513803528704694, 3.6604660939015217, 5.505656656751259, -2.3336208731274386]
Epoch: 3426  loss: 65.81632984263035
Learned parameters: [2.2512571891615356, 3.660639661128495, 5.505904858603282, -2.3339591569650286]
Epoch: 3427  loss: 65.8054091380564
Learned parameters: [2.251134094284166, 3.6608131292758666, 5.506152921031126, -2.334297248932284]
Epoch: 3428  loss: 65.79450643293457
Learned parameters: [2.2510110682245976, 3.66098649836729, 5.506400844064016, -2.3346351490726556]
Epoch: 3429  loss: 65.78362170167905
Learned parameters: [2.2508881109691354, 3.6611597684263844, 5.5066486277312485, -2.334972857429583]
Epoch: 3430  loss: 65.77275491873422
Learned parameters: [2.2507652225040413, 3.661332939476777, 5.506896272062037, -2.3353103740464767]
Epoch: 3431  loss: 65.76190605857357
Learned parameters: [2.2506424028155454, 3.6615060115422287, 5.507143777085625, -2.3356476989667434]
Epoch: 3432  loss: 65.7510750956877
Learned parameters: [2.2505196518898005, 3.661678984646499, 5.50739114283112, -2.3359848322337604]
Epoch: 3433  loss: 65.7402620046229
Learned parameters: [2.2503969697130106, 3.661851858813304, 5.507638369327671, -2.3363217738908895]
Epoch: 3434  loss: 65.7294667599623
Learned parameters: [2.250274356271471, 3.6620246340662996, 5.507885456604518, -2.3366585239814848]
Epoch: 3435  loss: 65.71868933631464
Learned parameters: [2.2501518115514987, 3.662197310429107, 5.508132404690904, -2.3369950825488828]
Epoch: 3436  loss: 65.70792970834013
Learned parameters: [2.2500293355392613, 3.6623698879251423, 5.508379213615705, -2.3373314496363755]
Epoch: 3437  loss: 65.69718785077096
Learned parameters: [2.2499069282209354, 3.662542366577601, 5.508625883407672, -2.337667625287244]
Epoch: 3438  loss: 65.68646373833911
Learned parameters: [2.2497845895829442, 3.662714746409622, 5.5088724140958965, -2.3380036095447885]
Epoch: 3439  loss: 65.67575734579665
Learned parameters: [2.2496623196117698, 3.6628870274443424, 5.509118805709552, -2.338339402452295]
Epoch: 3440  loss: 65.66506864792699
Learned parameters: [2.2495401182937016, 3.663059209704971, 5.5093650582775355, -2.33867500405299]
Epoch: 3441  loss: 65.65439761954758
Learned parameters: [2.249417985614887, 3.6632312932147695, 5.509611171828537, -2.3390104143900485]
Epoch: 3442  loss: 65.64374423550935
Learned parameters: [2.249295921561574, 3.6634032779970176, 5.509857146391402, -2.3393456335066363]
Epoch: 3443  loss: 65.63310847068936
Learned parameters: [2.2491739261201755, 3.6635751640749543, 5.510102981995197, -2.3396806614459216]
Epoch: 3444  loss: 65.62249030000277
Learned parameters: [2.249051999277121, 3.6637469514718193, 5.510348678669002, -2.340015498251051]
Epoch: 3445  loss: 65.6118896983994
Learned parameters: [2.2489301410187044, 3.663918640210895, 5.510594236441696, -2.3403501439651206]
Epoch: 3446  loss: 65.60130664085449
Learned parameters: [2.2488083513311388, 3.6640902303154887, 5.510839655342028, -2.340684598631187]
Epoch: 3447  loss: 65.59074110238706
Learned parameters: [2.248686630200734, 3.6642617218088853, 5.5110849353988725, -2.3410188622922963]
Epoch: 3448  loss: 65.58019305802335
Learned parameters: [2.248564977613965, 3.6644331147144555, 5.511330076641405, -2.3413529349915017]
Epoch: 3449  loss: 65.5696624828423
Learned parameters: [2.2484433935571895, 3.664604409055535, 5.511575079098572, -2.341686816771791]
Epoch: 3450  loss: 65.55914935195639
Learned parameters: [2.2483218780166414, 3.664775604855468, 5.511819942799109, -2.3420205076760974]
Epoch: 3451  loss: 65.54865364051298
Learned parameters: [2.2482004309786126, 3.6649467021375717, 5.512064667771818, -2.342354007747345]
Epoch: 3452  loss: 65.53817532368907
Learned parameters: [2.2480790524295315, 3.6651177009251126, 5.512309254045674, -2.3426873170284606]
Epoch: 3453  loss: 65.52771437669072
Learned parameters: [2.2479577423558452, 3.6652886012413, 5.512553701649636, -2.3430204355623525]
Epoch: 3454  loss: 65.5172707747858
Learned parameters: [2.247836500743846, 3.6654594031091667, 5.512798010612292, -2.343353363391871]
Epoch: 3455  loss: 65.50684449327113
Learned parameters: [2.2477153275798973, 3.6656301065517387, 5.51304218096233, -2.343686100559858]
Epoch: 3456  loss: 65.49643550766606
Learned parameters: [2.2475942228505024, 3.6658007115923685, 5.513286212727645, -2.344018647107606]
Epoch: 3457  loss: 65.48604379318068
Learned parameters: [2.247473186541822, 3.6659712182541573, 5.513530105936794, -2.3443510030780974]
Epoch: 3458  loss: 65.47566932511012
Learned parameters: [2.24735221864078, 3.66614162655999, 5.513773860619378, -2.3446831685144116]
Epoch: 3459  loss: 65.46531207885383
Learned parameters: [2.2472313191342, 3.666311936532797, 5.514017476804838, -2.3450151434595723]
Epoch: 3460  loss: 65.45497202983196
Learned parameters: [2.2471104880081985, 3.666482148195829, 5.5142609545216645, -2.345346927956449]
Epoch: 3461  loss: 65.44464915349421
Learned parameters: [2.2469897252485596, 3.6666522615724295, 5.514504293797854, -2.3456785220478173]
Epoch: 3462  loss: 65.43434342534337
Learned parameters: [2.246869030841585, 3.6668222766857848, 5.514747494662103, -2.3460099257765115]
Epoch: 3463  loss: 65.42405482089728
Learned parameters: [2.246748404774153, 3.6669921935589094, 5.5149905571438955, -2.3463411391854385]
Epoch: 3464  loss: 65.41378331571366
Learned parameters: [2.2466278470329666, 3.6671620122148605, 5.515233481272443, -2.346672162317441]
Epoch: 3465  loss: 65.40352888538922
Learned parameters: [2.246507357604144, 3.6673317326768564, 5.515476267076108, -2.3470029952152287]
Epoch: 3466  loss: 65.39329150553611
Learned parameters: [2.2463869364736944, 3.6675013549682465, 5.5157189145831484, -2.347333637921471]
Epoch: 3467  loss: 65.38307115179109
Learned parameters: [2.246266583628056, 3.667670879112263, 5.515961423822413, -2.3476640904788892]
Epoch: 3468  loss: 65.37286779983529
Learned parameters: [2.246146299053988, 3.667840305132038, 5.516203794823182, -2.347994352930238]
Epoch: 3469  loss: 65.36268142538535
Learned parameters: [2.246026082738043, 3.6680096330507355, 5.516446027614419, -2.348324425318206]
Epoch: 3470  loss: 65.352512004189
Learned parameters: [2.2459059346663737, 3.6681788628915784, 5.516688122224476, -2.3486543076853916]
Epoch: 3471  loss: 65.34235951205318
Learned parameters: [2.2457858548250433, 3.6683479946774873, 5.516930078681385, -2.3489840000743714]
Epoch: 3472  loss: 65.33222392482209
Learned parameters: [2.245665843200686, 3.6685170284312267, 5.517171897013971, -2.349313502527791]
Epoch: 3473  loss: 65.32210521834104
Learned parameters: [2.245545899780192, 3.668685964175496, 5.51741357725141, -2.349642815088313]
Epoch: 3474  loss: 65.31200336848836
Learned parameters: [2.24542602455007, 3.6688548019331186, 5.517655119422334, -2.3499719377985056]
Epoch: 3475  loss: 65.3019183511752
Learned parameters: [2.2453062174964247, 3.6690235417270456, 5.5178965235548025, -2.350300870700838]
Epoch: 3476  loss: 65.2918501423475
Learned parameters: [2.2451864786054965, 3.669192183580195, 5.518137789677053, -2.350629613837774]
Epoch: 3477  loss: 65.28179871797785
Learned parameters: [2.245066807863966, 3.669360727515338, 5.518378917817914, -2.3509581672518265]
Epoch: 3478  loss: 65.27176405407374
Learned parameters: [2.2449472052586206, 3.6695291735552162, 5.518619908006354, -2.351286530985499]
Epoch: 3479  loss: 65.26174612667637
Learned parameters: [2.244827670775901, 3.6696975217226577, 5.518860760270825, -2.3516147050812033]
Epoch: 3480  loss: 65.25174491185356
Learned parameters: [2.2447082044020137, 3.66986577204057, 5.519101474639446, -2.351942689581285]
Epoch: 3481  loss: 65.24176038570407
Learned parameters: [2.244588806123359, 3.67003392453182, 5.519342051140605, -2.3522704845281037]
Epoch: 3482  loss: 65.23179252435403
Learned parameters: [2.2444694759266417, 3.670201979219191, 5.5195824898031045, -2.3525980899640446]
Epoch: 3483  loss: 65.22184130396319
Learned parameters: [2.244350213798576, 3.6703699361255584, 5.519822790655804, -2.3529255059314704]
Epoch: 3484  loss: 65.21190670069956
Learned parameters: [2.244231019725571, 3.670537795273938, 5.520062953727151, -2.3532527324726655]
Epoch: 3485  loss: 65.2019886907872
Learned parameters: [2.244111893693838, 3.6707055566873517, 5.520302979045262, -2.3535797696298477]
Epoch: 3486  loss: 65.19208725048648
Learned parameters: [2.243992835689843, 3.670873220388709, 5.5205428666385785, -2.3539066174452516]
Epoch: 3487  loss: 65.18220235608445
Learned parameters: [2.2438738457003478, 3.6710407864008126, 5.520782616535926, -2.3542332759611337]
Epoch: 3488  loss: 65.17233398390157
Learned parameters: [2.243754923712052, 3.6712082547464617, 5.521022228766016, -2.354559745219713]
Epoch: 3489  loss: 65.1624821102849
Learned parameters: [2.243636069711332, 3.671375625448499, 5.521261703357061, -2.354886025263133]
Epoch: 3490  loss: 65.15264671163267
Learned parameters: [2.2435172836844806, 3.6715428985296463, 5.521501040337059, -2.355212116133499]
Epoch: 3491  loss: 65.14282776436525
Learned parameters: [2.2433985656181172, 3.6717100740125423, 5.521740239734461, -2.355538017872958]
Epoch: 3492  loss: 65.13302524492514
Learned parameters: [2.243279915499079, 3.6718771519197713, 5.5219793015780185, -2.3558637305236747]
Epoch: 3493  loss: 65.1232391297788
Learned parameters: [2.243161333314, 3.6720441322739883, 5.522218225896192, -2.3561892541277634]
Epoch: 3494  loss: 65.1134693954309
Learned parameters: [2.2430428190492253, 3.6722110150979446, 5.522457012717032, -2.356514588727274]
Epoch: 3495  loss: 65.10371601841038
Learned parameters: [2.242924372691162, 3.6723778004143814, 5.52269566206867, -2.356839734364249]
Epoch: 3496  loss: 65.09397897527141
Learned parameters: [2.242805994226516, 3.672544488246034, 5.522934173979696, -2.35716469108077]
Epoch: 3497  loss: 65.08425824259841
Learned parameters: [2.2426876836420533, 3.6727110786156376, 5.5231725484787795, -2.3574894589189106]
Epoch: 3498  loss: 65.07455379700777
Learned parameters: [2.2425694409242896, 3.6728775715459925, 5.5234107855942245, -2.3578140379206833]
Epoch: 3499  loss: 65.06486561515396
Learned parameters: [2.242451266059604, 3.6730439670599306, 5.5236488853541275, -2.3581384281280577]
Epoch: 3500  loss: 65.05519367371495
Learned parameters: [2.2423331590345277, 3.6732102651802303, 5.5238868477867795, -2.3584626295830122]
Epoch: 3501  loss: 65.04553794940396
Learned parameters: [2.242215119835807, 3.6733764659296035, 5.524124672920766, -2.358786642327552]
Epoch: 3502  loss: 65.03589841896336
Learned parameters: [2.2420971484501426, 3.67354256933079, 5.52436236078461, -2.35911046640366]
Epoch: 3503  loss: 65.02627505914992
Learned parameters: [2.2419792448640514, 3.673708575406642, 5.524599911406604, -2.359434101853279]
Epoch: 3504  loss: 65.01666784675947
Learned parameters: [2.2418614090639495, 3.673874484180018, 5.524837324814877, -2.359757548718316]
Epoch: 3505  loss: 65.00707675862245
Learned parameters: [2.2417436410364138, 3.6740402956737346, 5.525074601037785, -2.3600808070407]
Epoch: 3506  loss: 64.99750177159468
Learned parameters: [2.241625940768132, 3.6742060099104843, 5.525311740103786, -2.360403876862377]
Epoch: 3507  loss: 64.98794286259492
Learned parameters: [2.2415083082457126, 3.674371626912765, 5.525548742041091, -2.36072675822527]
Epoch: 3508  loss: 64.97840000855878
Learned parameters: [2.241390743455764, 3.6745371467030776, 5.525785606877909, -2.3610494511712803]
Epoch: 3509  loss: 64.96887318644407
Learned parameters: [2.241273246384906, 3.674702569303923, 5.526022334642454, -2.3613719557422943]
Epoch: 3510  loss: 64.95936237322839
Learned parameters: [2.24115581701975, 3.674867894737812, 5.526258925362935, -2.3616942719801837]
Epoch: 3511  loss: 64.94986754592712
Learned parameters: [2.241038455346925, 3.675033123027253, 5.526495379067571, -2.3620163999268016]
Epoch: 3512  loss: 64.9403886815855
Learned parameters: [2.240921161353059, 3.6751982541947594, 5.526731695784578, -2.3623383396239834]
Epoch: 3513  loss: 64.93092575727707
Learned parameters: [2.2408039350247484, 3.6753632882628104, 5.526967875542095, -2.3626600911135403]
Epoch: 3514  loss: 64.9214787501106
Learned parameters: [2.2406867763486162, 3.6755282252538675, 5.527203918368281, -2.3629816544372666]
Epoch: 3515  loss: 64.9120476372203
Learned parameters: [2.2405696853113284, 3.675693065190384, 5.527439824291351, -2.3633030296369437]
Epoch: 3516  loss: 64.90263239576791
Learned parameters: [2.2404526618995444, 3.6758578080948183, 5.527675593339501, -2.363624216754331]
Epoch: 3517  loss: 64.89323300294593
Learned parameters: [2.240335706099897, 3.67602245398964, 5.527911225540884, -2.3639452158311625]
Epoch: 3518  loss: 64.88384943597728
Learned parameters: [2.2402188178989957, 3.676187002897325, 5.52814672092361, -2.364266026909147]
Epoch: 3519  loss: 64.87448167211161
Learned parameters: [2.2401019972834972, 3.676351454840369, 5.5283820795158665, -2.364586650029987]
Epoch: 3520  loss: 64.86512968861635
Learned parameters: [2.2399852442400947, 3.6765158098413355, 5.528617301345932, -2.3649070852353713]
Epoch: 3521  loss: 64.85579346279556
Learned parameters: [2.239868558755412, 3.6766800679227964, 5.5288523864419705, -2.3652273325669593]
Epoch: 3522  loss: 64.84647297198637
Learned parameters: [2.2397519408160367, 3.6768442291073153, 5.529087334832075, -2.3655473920663823]
Epoch: 3523  loss: 64.83716819356586
Learned parameters: [2.2396353904085973, 3.677008293417363, 5.52932214654433, -2.365867263775246]
Epoch: 3524  loss: 64.82787910493812
Learned parameters: [2.2395189075198307, 3.6771722608753747, 5.529556821606963, -2.366186947735157]
Epoch: 3525  loss: 64.81860568352914
Learned parameters: [2.2394024921364677, 3.6773361315037807, 5.529791360048181, -2.3665064439877064]
Epoch: 3526  loss: 64.80934790680416
Learned parameters: [2.239286144245106, 3.6774999053249164, 5.530025761895907, -2.3668257525744285]
Epoch: 3527  loss: 64.80010575227995
Learned parameters: [2.2391698638323483, 3.677663582361022, 5.530260027178008, -2.3671448735368363]
Epoch: 3528  loss: 64.79087919747619
Learned parameters: [2.239053650884974, 3.677827162634304, 5.530494155922594, -2.3674638069164593]
Epoch: 3529  loss: 64.78166821994327
Learned parameters: [2.238937505389809, 3.677990646166976, 5.530728148157849, -2.3677825527548206]
Epoch: 3530  loss: 64.77247279725214
Learned parameters: [2.2388214273335327, 3.6781540329813263, 5.530962003911764, -2.368101111093409]
Epoch: 3531  loss: 64.76329290700698
Learned parameters: [2.238705416702725, 3.6783173230996846, 5.531195723212184, -2.368419481973678]
Epoch: 3532  loss: 64.75412852683716
Learned parameters: [2.238589473484053, 3.6784805165443646, 5.531429306087073, -2.3687376654370818]
Epoch: 3533  loss: 64.74497963440479
Learned parameters: [2.23847359766433, 3.67864361333773, 5.53166275256465, -2.3690556615250897]
Epoch: 3534  loss: 64.73584620738065
Learned parameters: [2.238357789230327, 3.678806613502183, 5.531896062673078, -2.3693734702791516]
Epoch: 3535  loss: 64.72672822348471
Learned parameters: [2.238242048168657, 3.678969517060165, 5.532129236440289, -2.369691091740673]
Epoch: 3536  loss: 64.7176256604636
Learned parameters: [2.2381263744659208, 3.6791323240341156, 5.532362273894182, -2.3700085259510404]
Epoch: 3537  loss: 64.70853849608837
Learned parameters: [2.2380107681088637, 3.679295034446435, 5.532595175062854, -2.370325772951654]
Epoch: 3538  loss: 64.69946670816091
Learned parameters: [2.237895229084307, 3.679457648319494, 5.5328279399744975, -2.3706428327839153]
Epoch: 3539  loss: 64.69041027451749
Learned parameters: [2.2377797573789744, 3.679620165675682, 5.533060568657155, -2.3709597054891924]
Epoch: 3540  loss: 64.68136917301108
Learned parameters: [2.2376643529795217, 3.6797825865374767, 5.533293061138812, -2.3712763911088373]
Epoch: 3541  loss: 64.67234338151934
Learned parameters: [2.237549015872586, 3.6799449109273605, 5.533525417447424, -2.3715928896841936]
Epoch: 3542  loss: 64.66333287795676
Learned parameters: [2.2374337460448923, 3.68010713886777, 5.533757637611055, -2.371909201256605]
Epoch: 3543  loss: 64.65433764028114
Learned parameters: [2.2373185434831644, 3.680269270380941, 5.533989721657643, -2.37222532586741]
Epoch: 3544  loss: 64.64535764648502
Learned parameters: [2.237203408174175, 3.680431305489084, 5.534221669615195, -2.372541263557958]
Epoch: 3545  loss: 64.63639287456895
Learned parameters: [2.2370883401046897, 3.680593244214409, 5.5344534815117, -2.3728570143695804]
Epoch: 3546  loss: 64.62744330256642
Learned parameters: [2.2369733392614157, 3.6807550865791434, 5.5346851573750575, -2.3731725783435813]
Epoch: 3547  loss: 64.61850890853944
Learned parameters: [2.2368584056310477, 3.6809168326055226, 5.5349166972331485, -2.3734879555212465]
Epoch: 3548  loss: 64.60958967057833
Learned parameters: [2.2367435392003343, 3.681078482315765, 5.535148101113921, -2.373803145943854]
Epoch: 3549  loss: 64.6006855667979
Learned parameters: [2.2366287399560423, 3.6812400357320803, 5.535379369045342, -2.374118149652669]
Epoch: 3550  loss: 64.59179657534702
Learned parameters: [2.2365140078849217, 3.681401492876679, 5.535610501055348, -2.3744329666889445]
Epoch: 3551  loss: 64.58292267439586
Learned parameters: [2.2363993429736837, 3.6815628537717764, 5.5358414971718135, -2.3747475970939087]
Epoch: 3552  loss: 64.57406384215112
Learned parameters: [2.236284745209059, 3.681724118439576, 5.53607235742263, -2.375062040908776]
Epoch: 3553  loss: 64.56522005684292
Learned parameters: [2.2361702145778075, 3.6818852869022667, 5.536303081835721, -2.3753762981747504]
Epoch: 3554  loss: 64.55639129672997
Learned parameters: [2.236055751066712, 3.682046359182032, 5.536533670439034, -2.3756903689330233]
Epoch: 3555  loss: 64.54757754009734
Learned parameters: [2.2359413546625255, 3.682207335301057, 5.536764123260472, -2.376004253224766]
Epoch: 3556  loss: 64.5387787652627
Learned parameters: [2.2358270253519708, 3.6823682152815334, 5.536994440327879, -2.3763179510911274]
Epoch: 3557  loss: 64.5299949505646
Learned parameters: [2.2357127631217995, 3.6825289991456645, 5.537224621669153, -2.3766314625732456]
Epoch: 3558  loss: 64.52122607437389
Learned parameters: [2.235598567958788, 3.682689686915643, 5.537454667312216, -2.3769447877122523]
Epoch: 3559  loss: 64.5124721150866
Learned parameters: [2.2354844398496994, 3.6828502786136594, 5.537684577284966, -2.377257926549265]
Epoch: 3560  loss: 64.50373305112811
Learned parameters: [2.235370378781279, 3.6830107742619, 5.537914351615266, -2.3775708791253862]
Epoch: 3561  loss: 64.49500886095453
Learned parameters: [2.235256384740273, 3.6831711738824864, 5.538143990330928, -2.3778836454816914]
Epoch: 3562  loss: 64.4862995230626
Learned parameters: [2.2351424577134735, 3.683331477497506, 5.538373493459812, -2.378196225659246]
Epoch: 3563  loss: 64.47760501596113
Learned parameters: [2.2350285976876836, 3.6834916851290216, 5.538602861029771, -2.3785086196991045]
Epoch: 3564  loss: 64.46892531820771
Learned parameters: [2.234914804649623, 3.683651796798927, 5.538832093068421, -2.3788208276422864]
Epoch: 3565  loss: 64.46026040838527
Learned parameters: [2.2348010785861154, 3.683811812529103, 5.539061189603523, -2.3791328495298147]
Epoch: 3566  loss: 64.45161026509585
Learned parameters: [2.2346874194840414, 3.6839717323414143, 5.539290150662909, -2.3794446854026967]
Epoch: 3567  loss: 64.442974866963
Learned parameters: [2.2345738273302174, 3.6841315562577632, 5.539518976274322, -2.3797563353019155]
Epoch: 3568  loss: 64.43435419264134
Learned parameters: [2.2344603021113922, 3.6842912843000994, 5.53974766646542, -2.380067799268433]
Epoch: 3569  loss: 64.4257482208051
Learned parameters: [2.2343468438143326, 3.684450916490391, 5.5399762212638946, -2.3803790773432034]
Epoch: 3570  loss: 64.41715693015949
Learned parameters: [2.234233452425876, 3.6846104528505994, 5.540204640697535, -2.380690169567177]
Epoch: 3571  loss: 64.40858029943347
Learned parameters: [2.234120127932892, 3.6847698934027404, 5.540432924794209, -2.381001075981301]
Epoch: 3572  loss: 64.40001830738538
Learned parameters: [2.2340068703221654, 3.684929238168861, 5.540661073581657, -2.3813117966264925]
Epoch: 3573  loss: 64.3914709328005
Learned parameters: [2.233893679580431, 3.685088487171025, 5.540889087087545, -2.3816223315436464]
Epoch: 3574  loss: 64.38293815448773
Learned parameters: [2.233780555694484, 3.685247640431282, 5.541116965339617, -2.3819326807736543]
Epoch: 3575  loss: 64.37441995129527
Learned parameters: [2.2336674986512026, 3.685406697971657, 5.541344708365727, -2.382242844357408]
Epoch: 3576  loss: 64.36591630208932
Learned parameters: [2.233554508437437, 3.685565659814181, 5.541572316193679, -2.3825528223357817]
Epoch: 3577  loss: 64.35742718576722
Learned parameters: [2.233441585039961, 3.6857245259809064, 5.541799788851165, -2.382862614749622]
Epoch: 3578  loss: 64.34895258124637
Learned parameters: [2.2333287284455587, 3.6858832964939316, 5.542027126365916, -2.3831722216397715]
Epoch: 3579  loss: 64.3404924674719
Learned parameters: [2.2332159386410537, 3.6860419713753494, 5.5422543287657176, -2.383481643047068]
Epoch: 3580  loss: 64.33204682342077
Learned parameters: [2.233103215613251, 3.686200550647146, 5.54248139607826, -2.383790879012339]
Epoch: 3581  loss: 64.32361562811982
Learned parameters: [2.2329905593489583, 3.6863590343312325, 5.542708328331196, -2.3840999295764123]
Epoch: 3582  loss: 64.31519886059803
Learned parameters: [2.2328779698350574, 3.6865174224495108, 5.542935125552288, -2.38440879478012]
Epoch: 3583  loss: 64.30679649991234
Learned parameters: [2.23276544705842, 3.6866757150239184, 5.543161787769303, -2.384717474664292]
Epoch: 3584  loss: 64.29840852514094
Learned parameters: [2.232652991005835, 3.6868339120764353, 5.543388315009905, -2.38502596926974]
Epoch: 3585  loss: 64.29003491539657
Learned parameters: [2.232540601664071, 3.6869920136290406, 5.54361470730172, -2.3853342786372567]
Epoch: 3586  loss: 64.28167564982076
Learned parameters: [2.2324282790199574, 3.6871500197036897, 5.54384096467245, -2.3856424028076284]
Epoch: 3587  loss: 64.27333070757734
Learned parameters: [2.2323160230603785, 3.6873079303222895, 5.54406708714985, -2.3859503418216366]
Epoch: 3588  loss: 64.26500006786728
Learned parameters: [2.232203833772172, 3.687465745506719, 5.544293074761583, -2.3862580957200406]
Epoch: 3589  loss: 64.25668370991598
Learned parameters: [2.232091711142147, 3.68762346527887, 5.54451892753527, -2.386565664543581]
Epoch: 3590  loss: 64.24838161296856
Learned parameters: [2.2319796551571414, 3.6877810896606285, 5.544744645498568, -2.3868730483329896]
Epoch: 3591  loss: 64.24009375629856
Learned parameters: [2.231867665804013, 3.687938618673877, 5.544970228679164, -2.387180247128989]
Epoch: 3592  loss: 64.23182011920923
Learned parameters: [2.2317557430696175, 3.6880960523405037, 5.54519567710474, -2.3874872609722924]
Epoch: 3593  loss: 64.22356068102232
Learned parameters: [2.2316438869407897, 3.6882533906824047, 5.545420990802947, -2.387794089903595]
Epoch: 3594  loss: 64.21531542109302
Learned parameters: [2.23153209740435, 3.688410633721475, 5.545646169801411, -2.388100733963577]
Epoch: 3595  loss: 64.20708431880502
Learned parameters: [2.2314203744471377, 3.6885677814795885, 5.545871214127768, -2.3884071931929074]
Epoch: 3596  loss: 64.19886735356442
Learned parameters: [2.2313087180560207, 3.68872483397861, 5.546096123809692, -2.388713467632248]
Epoch: 3597  loss: 64.19066450480372
Learned parameters: [2.2311971282178686, 3.688881791240405, 5.546320898874856, -2.389019557322249]
Epoch: 3598  loss: 64.18247575198531
Learned parameters: [2.231085604919524, 3.689038653286853, 5.546545539350898, -2.389325462303547]
Epoch: 3599  loss: 64.17430107458995
Learned parameters: [2.2309741481478067, 3.6891954201398502, 5.546770045265429, -2.3896311826167707]
Epoch: 3600  loss: 64.16614045213218
Learned parameters: [2.2308627578895615, 3.689352091821238, 5.546994416646059, -2.3899367183025295]
Epoch: 3601  loss: 64.1579938641595
Learned parameters: [2.2307514341316557, 3.6895086683528184, 5.5472186535204004, -2.3902420694014177]
Epoch: 3602  loss: 64.14986129024925
Learned parameters: [2.2306401768609443, 3.6896651497562574, 5.547442755915961, -2.3905472359540103]
Epoch: 3603  loss: 64.14174271001298
Learned parameters: [2.23052898606433, 3.689821536053196, 5.547666723860305, -2.3908522180008793]
Epoch: 3604  loss: 64.13363810307041
Learned parameters: [2.2304178617287294, 3.689977827265292, 5.547890557381022, -2.3911570155825888]
Epoch: 3605  loss: 64.12554744906741
Learned parameters: [2.230306803841016, 3.6901340234142355, 5.5481142565056505, -2.3914616287396844]
Epoch: 3606  loss: 64.11747072767666
Learned parameters: [2.2301958123880214, 3.690290124521734, 5.548337821261662, -2.3917660575126862]
Epoch: 3607  loss: 64.10940791860214
Learned parameters: [2.2300848873566195, 3.69044613060949, 5.5485612516765865, -2.3920703019421037]
Epoch: 3608  loss: 64.1013590015655
Learned parameters: [2.2299740287337375, 3.6906020416992225, 5.548784547778041, -2.3923743620684506]
Epoch: 3609  loss: 64.09332395631606
Learned parameters: [2.2298632365062843, 3.690757857812705, 5.549007709593645, -2.3926782379322296]
Epoch: 3610  loss: 64.08530276261683
Learned parameters: [2.229752510661113, 3.690913578971792, 5.549230737150974, -2.392981929573928]
Epoch: 3611  loss: 64.07729540026526
Learned parameters: [2.229641851185025, 3.6910692051983522, 5.549453630477528, -2.393285437034014]
Epoch: 3612  loss: 64.06930184908981
Learned parameters: [2.2295312580649016, 3.6912247365142306, 5.5496763896009105, -2.39358876035296]
Epoch: 3613  loss: 64.06132208893908
Learned parameters: [2.229420731287672, 3.691380172941255, 5.549899014548791, -2.3938918995712384]
Epoch: 3614  loss: 64.05335609969444
Learned parameters: [2.229310270840232, 3.691535514501261, 5.550121505348787, -2.3941948547293075]
Epoch: 3615  loss: 64.04540386125655
Learned parameters: [2.229199876709427, 3.6916907612160945, 5.550343862028439, -2.394497625867609]
Epoch: 3616  loss: 64.03746535355691
Learned parameters: [2.2290895488820985, 3.6918459131075987, 5.550566084615281, -2.3948002130265786]
Epoch: 3617  loss: 64.02954055654789
Learned parameters: [2.2289792873451537, 3.692000970197627, 5.550788173136956, -2.3951026162466587]
Epoch: 3618  loss: 64.02162945020697
Learned parameters: [2.228869092085472, 3.6921559325079585, 5.55101012762102, -2.3954048355682835]
Epoch: 3619  loss: 64.01373201455624
Learned parameters: [2.2287589630899083, 3.6923108000603095, 5.551231948094955, -2.3957068710318787]
Epoch: 3620  loss: 64.00584822963495
Learned parameters: [2.2286489003453607, 3.6924655728763853, 5.551453634586303, -2.3960087226778697]
Epoch: 3621  loss: 63.997978075496604
Learned parameters: [2.228538903838755, 3.6926202509778845, 5.551675187122647, -2.3963103905466783]
Epoch: 3622  loss: 63.9901215322287
Learned parameters: [2.228428973556987, 3.692774834386515, 5.551896605731526, -2.3966118746787144]
Epoch: 3623  loss: 63.98227857994036
Learned parameters: [2.228319109486914, 3.692929323124024, 5.552117890440454, -2.396913175114393]
Epoch: 3624  loss: 63.97444919875636
Learned parameters: [2.2282093116153976, 3.6930837172121764, 5.552339041276965, -2.397214291894131]
Epoch: 3625  loss: 63.966633368838885
Learned parameters: [2.2280995799293164, 3.693238016672702, 5.552560058268598, -2.397515225058336]
Epoch: 3626  loss: 63.95883107038229
Learned parameters: [2.2279899144155424, 3.6933922215272372, 5.552780941442824, -2.3978159746474037]
Epoch: 3627  loss: 63.9510422836049
Learned parameters: [2.2278803150609945, 3.6935463317974104, 5.553001690827186, -2.398116540701729]
Epoch: 3628  loss: 63.94326698874332
Learned parameters: [2.2277707818525987, 3.693700347504852, 5.553222306449235, -2.3984169232616983]
Epoch: 3629  loss: 63.9355051660621
Learned parameters: [2.2276613147772197, 3.6938542686712146, 5.553442788336439, -2.398717122367677]
Epoch: 3630  loss: 63.92775679584972
Learned parameters: [2.2275519138217184, 3.6940080953181527, 5.553663136516263, -2.3990171380600196]
Epoch: 3631  loss: 63.92002185841913
Learned parameters: [2.227442578972991, 3.6941618274673145, 5.553883351016221, -2.399316970379079]
Epoch: 3632  loss: 63.91230033411027
Learned parameters: [2.227333310217955, 3.6943154651403316, 5.554103431863851, -2.3996166193652004]
Epoch: 3633  loss: 63.90459220329036
Learned parameters: [2.2272241075434973, 3.6944690083588334, 5.554323379086636, -2.3999160850587122]
Epoch: 3634  loss: 63.896897446349726
Learned parameters: [2.2271149709365026, 3.694622457144458, 5.5545431927120665, -2.4002153674999396]
Epoch: 3635  loss: 63.889216043699534
Learned parameters: [2.2270059003838494, 3.694775811518849, 5.554762872767625, -2.4005144667291964]
Epoch: 3636  loss: 63.88154797578129
Learned parameters: [2.2268968958724424, 3.694929071503642, 5.554982419280829, -2.400813382786793]
Epoch: 3637  loss: 63.8738932230595
Learned parameters: [2.226787957389183, 3.695082237120475, 5.55520183227919, -2.4011121157130284]
Epoch: 3638  loss: 63.86625176602226
Learned parameters: [2.226679084920961, 3.69523530839099, 5.555421111790205, -2.401410665548193]
Epoch: 3639  loss: 63.858623585185754
Learned parameters: [2.2265702784546595, 3.695388285336833, 5.555640257841361, -2.401709032332568]
Epoch: 3640  loss: 63.85100866109041
Learned parameters: [2.2264615379771584, 3.695541167979618, 5.555859270460119, -2.4020072161064228]
Epoch: 3641  loss: 63.84340697431868
Learned parameters: [2.2263528634753107, 3.6956939563407705, 5.556078149673774, -2.4023052169099937]
Epoch: 3642  loss: 63.835818505483516
Learned parameters: [2.226244254936079, 3.695846650441657, 5.556296895509758, -2.4026030347835277]
Epoch: 3643  loss: 63.828243235205925
Learned parameters: [2.2261357123464856, 3.695999250303655, 5.5565155079956, -2.402900669767275]
Epoch: 3644  loss: 63.820681144124364
Learned parameters: [2.226027235693438, 3.6961517559482004, 5.556733987158682, -2.403198121901456]
Epoch: 3645  loss: 63.81313221290977
Learned parameters: [2.2259188249637663, 3.696304167396773, 5.556952333026287, -2.403495391226273]
Epoch: 3646  loss: 63.80559642225299
Learned parameters: [2.2258104801443532, 3.6964564846708594, 5.557170545625781, -2.403792477781926]
Epoch: 3647  loss: 63.79807375286771
Learned parameters: [2.225702201222178, 3.696608707791938, 5.557388624984673, -2.4040893816086237]
Epoch: 3648  loss: 63.790564185497345
Learned parameters: [2.2255939881842113, 3.6967608367815017, 5.55760657113046, -2.4043861027465563]
Epoch: 3649  loss: 63.78306770090138
Learned parameters: [2.2254858410173455, 3.696912871661147, 5.557824384090578, -2.4046826412359006]
Epoch: 3650  loss: 63.77558427986265
Learned parameters: [2.2253777597084183, 3.6970648124524983, 5.55804206389239, -2.4049789971168165]
Epoch: 3651  loss: 63.76811390319429
Learned parameters: [2.225269744244319, 3.697216659177171, 5.558259610563335, -2.405275170429465]
Epoch: 3652  loss: 63.76065655173657
Learned parameters: [2.225161794612009, 3.6973684118567647, 5.558477024130949, -2.405571161214011]
Epoch: 3653  loss: 63.75321220634526
Learned parameters: [2.225053910798445, 3.697520070512882, 5.558694304622765, -2.4058669695106136]
Epoch: 3654  loss: 63.745780847912734
Learned parameters: [2.224946092790501, 3.6976716351671524, 5.5589114520662, -2.406162595359409]
Epoch: 3655  loss: 63.738362457348565
Learned parameters: [2.224838340575033, 3.69782310584121, 5.559128466488643, -2.406458038800526]
Epoch: 3656  loss: 63.73095701558296
Learned parameters: [2.224730654138964, 3.697974482556668, 5.559345347917577, -2.406753299874099]
Epoch: 3657  loss: 63.72356450358627
Learned parameters: [2.2246230334692254, 3.698125765335071, 5.5595620963804615, -2.4070483786202623]
Epoch: 3658  loss: 63.71618490234758
Learned parameters: [2.2245154785527292, 3.6982769541979392, 5.559778711904713, -2.4073432750791435]
Epoch: 3659  loss: 63.708818192874574
Learned parameters: [2.224407989376396, 3.698428049166795, 5.559995194517762, -2.407637989290864]
Epoch: 3660  loss: 63.7014643562098
Learned parameters: [2.2243005659271473, 3.6985790502631657, 5.560211544247045, -2.4079325212955416]
Epoch: 3661  loss: 63.69412337340365
Learned parameters: [2.224193208191887, 3.6987299575085872, 5.560427761119978, -2.4082268711332855]
Epoch: 3662  loss: 63.68679522554359
Learned parameters: [2.2240859161575215, 3.6988807709245988, 5.560643845163987, -2.408521038844202]
Epoch: 3663  loss: 63.679479893731084
Learned parameters: [2.223978689810968, 3.699031490532738, 5.560859796406512, -2.408815024468394]
Epoch: 3664  loss: 63.67217735910019
Learned parameters: [2.2238715291391515, 3.6991821163545433, 5.561075614875012, -2.4091088280459627]
Epoch: 3665  loss: 63.66488760279783
Learned parameters: [2.223764434128996, 3.6993326484116325, 5.561291300597006, -2.4094024496170294]
Epoch: 3666  loss: 63.65761060598839
Learned parameters: [2.2236574047673523, 3.699483086725649, 5.561506853599918, -2.4096958892217057]
Epoch: 3667  loss: 63.65034634987644
Learned parameters: [2.2235504410410836, 3.699633431318222, 5.561722273911188, -2.4099891469000982]
Epoch: 3668  loss: 63.643094815683796
Learned parameters: [2.2234435429371104, 3.6997836822109518, 5.561937561558329, -2.410282222692318]
Epoch: 3669  loss: 63.63585598466339
Learned parameters: [2.2233367104423696, 3.699933839425423, 5.562152716568876, -2.4105751166384732]
Epoch: 3670  loss: 63.62862983808891
Learned parameters: [2.2232299435437497, 3.7000839029832227, 5.562367738970295, -2.4108678287786605]
Epoch: 3671  loss: 63.621416357253615
Learned parameters: [2.2231232422281066, 3.7002338729059345, 5.5625826287899995, -2.411160359152966]
Epoch: 3672  loss: 63.61421552348254
Learned parameters: [2.2230166064823282, 3.7003837492151233, 5.562797386055449, -2.411452707801478]
Epoch: 3673  loss: 63.60702731812228
Learned parameters: [2.2229100362933463, 3.700533531932336, 5.563012010794163, -2.4117448747642847]
Epoch: 3674  loss: 63.59985172254266
Learned parameters: [2.222803531648056, 3.7006832210791165, 5.563226503033609, -2.412036860081465]
Epoch: 3675  loss: 63.592688718134184
Learned parameters: [2.2226970925333362, 3.7008328166770026, 5.563440862801225, -2.4123286637930916]
Epoch: 3676  loss: 63.58553828631817
Learned parameters: [2.222590718936064, 3.700982318747521, 5.563655090124451, -2.4126202859392363]
Epoch: 3677  loss: 63.5784004085305
Learned parameters: [2.222484410843133, 3.7011317273121884, 5.563869185030751, -2.412911726559976]
Epoch: 3678  loss: 63.571275066240354
Learned parameters: [2.222378168241455, 3.701281042392507, 5.564083147547615, -2.41320298569539]
Epoch: 3679  loss: 63.56416224093597
Learned parameters: [2.222271991117927, 3.701430264009974, 5.564296977702514, -2.413494063385553]
Epoch: 3680  loss: 63.557061914125114
Learned parameters: [2.2221658794594146, 3.7015793921860873, 5.5645106755228735, -2.4137849596705356]
Epoch: 3681  loss: 63.54997406735937
Learned parameters: [2.22205983325273, 3.7017284269421573, 5.564724241035922, -2.414075674590382]
Epoch: 3682  loss: 63.542898682221946
Learned parameters: [2.2219538524848135, 3.7018773682993937, 5.564937674269029, -2.414366208185151]
Epoch: 3683  loss: 63.535835740304236
Learned parameters: [2.2218479371427033, 3.7020262162789983, 5.5651509752497175, -2.4146565604949144]
Epoch: 3684  loss: 63.52878522321671
Learned parameters: [2.221742087213322, 3.702174970902225, 5.565364144005361, -2.4149467315597204]
Epoch: 3685  loss: 63.52174711258992
Learned parameters: [2.221636302683461, 3.702323632190384, 5.565577180563163, -2.41523672141959]
Epoch: 3686  loss: 63.51472139008451
Learned parameters: [2.2215305835399723, 3.702472200164785, 5.565790084950417, -2.4155265301145494]
Epoch: 3687  loss: 63.50770803737524
Learned parameters: [2.221424929769849, 3.7026206748467154, 5.566002857194629, -2.415816157684642]
Epoch: 3688  loss: 63.50070703617075
Learned parameters: [2.2213193413600556, 3.702769056257485, 5.566215497323271, -2.4161056041699003]
Epoch: 3689  loss: 63.4937183681931
Learned parameters: [2.221213818297449, 3.702917344418471, 5.5664280053636865, -2.4163948696103343]
Epoch: 3690  loss: 63.48674201518803
Learned parameters: [2.221108360568846, 3.703065539351102, 5.566640381343187, -2.416683954045944]
Epoch: 3691  loss: 63.47977795892969
Learned parameters: [2.2210029681611436, 3.703213641076785, 5.566852625289192, -2.416972857516731]
Epoch: 3692  loss: 63.4728261806159
Learned parameters: [2.2208976410592633, 3.703361649616443, 5.567064737229305, -2.417261580066739]
Epoch: 3693  loss: 63.4658866625778
Learned parameters: [2.220792379251422, 3.703509564991257, 5.567276717192544, -2.417550121735744]
Epoch: 3694  loss: 63.458959386679936
Learned parameters: [2.2206871827252166, 3.703657387222589, 5.567488565207086, -2.417838482563441]
Epoch: 3695  loss: 63.4520443347936
Learned parameters: [2.2205820514667347, 3.703805116332234, 5.567700281299022, -2.418126662589294]
Epoch: 3696  loss: 63.44514148881525
Learned parameters: [2.2204769854621, 3.703952752341978, 5.56791186549452, -2.4184146618527955]
Epoch: 3697  loss: 63.438250830664
Learned parameters: [2.2203719846987617, 3.704100295273163, 5.568123317821595, -2.418702480393685]
Epoch: 3698  loss: 63.431372342281335
Learned parameters: [2.2202670491646277, 3.7042477451470077, 5.56833463830893, -2.4189901182518017]
Epoch: 3699  loss: 63.42450600563036
Learned parameters: [2.220162178846528, 3.7043951019850323, 5.568545826983717, -2.419277575466823]
Epoch: 3700  loss: 63.41765180269543
Learned parameters: [2.2200573737305183, 3.704542365808979, 5.56875688387208, -2.4195648520783193]
Epoch: 3701  loss: 63.41080971548228
Learned parameters: [2.219952633803346, 3.7046895366403914, 5.568967809001132, -2.419851948125993]
Epoch: 3702  loss: 63.40397972602253
Learned parameters: [2.219847959052684, 3.7048366145005454, 5.569178602399297, -2.42013886364972]
Epoch: 3703  loss: 63.39716181637176
Learned parameters: [2.219743349465887, 3.7049835994108036, 5.569389264094565, -2.4204255986893397]
Epoch: 3704  loss: 63.390355968598655
Learned parameters: [2.2196388050293434, 3.7051304913927945, 5.569599794113585, -2.4207121532845455]
Epoch: 3705  loss: 63.383562164806015
Learned parameters: [2.219534325729431, 3.7052772904681666, 5.56981019248301, -2.420998527475044]
Epoch: 3706  loss: 63.376780387106834
Learned parameters: [2.219429911553359, 3.7054239966583618, 5.570020459230696, -2.421284721300695]
Epoch: 3707  loss: 63.370010617644034
Learned parameters: [2.2193255624886095, 3.7055706099847607, 5.570230594384907, -2.4215707348014326]
Epoch: 3708  loss: 63.36325283857068
Learned parameters: [2.219221278521993, 3.7057171304689356, 5.570440597972986, -2.4218565680170996]
Epoch: 3709  loss: 63.3565070320755
Learned parameters: [2.2191170596398515, 3.7058635581325796, 5.570650470021629, -2.422142220987482]
Epoch: 3710  loss: 63.349773180365055
Learned parameters: [2.2190129058289596, 3.7060098929972467, 5.570860210558145, -2.422427693752454]
Epoch: 3711  loss: 63.343051265675385
Learned parameters: [2.21890881707667, 3.706156135084305, 5.571069819610653, -2.422712986351995]
Epoch: 3712  loss: 63.336341270255915
Learned parameters: [2.218804793370111, 3.706302284415166, 5.571279297206956, -2.4229980988260555]
Epoch: 3713  loss: 63.32964317639206
Learned parameters: [2.218700834695819, 3.7064483410113866, 5.571488643374028, -2.423283031214496]
Epoch: 3714  loss: 63.32295696637972
Learned parameters: [2.218596941040331, 3.7065943048944714, 5.571697858138826, -2.4235677835571834]
Epoch: 3715  loss: 63.3162826225532
Learned parameters: [2.2184931123907243, 3.706740176085732, 5.571906941529051, -2.423852355894079]
Epoch: 3716  loss: 63.30962012725985
Learned parameters: [2.2183893487342528, 3.7068859546064123, 5.572115893572651, -2.424136748265179]
Epoch: 3717  loss: 63.30296946286957
Learned parameters: [2.2182856500577457, 3.707031640477865, 5.572324714296983, -2.424420960710414]
Epoch: 3718  loss: 63.296330611775886
Learned parameters: [2.218182016347711, 3.707177233721526, 5.572533403728963, -2.4247049932696667]
Epoch: 3719  loss: 63.28970355639342
Learned parameters: [2.2180784475909507, 3.7073227343587387, 5.572741961895923, -2.424988845982874]
Epoch: 3720  loss: 63.28308827915909
Learned parameters: [2.217974943774637, 3.707468142410737, 5.572950388825719, -2.425272518890038]
Epoch: 3721  loss: 63.27648476253391
Learned parameters: [2.2178715048857924, 3.707613457898789, 5.573158684546006, -2.42555601203114]
Epoch: 3722  loss: 63.269892988996325
Learned parameters: [2.217768130911038, 3.7077586808442344, 5.573366849083862, -2.4258393254461006]
Epoch: 3723  loss: 63.263312941072805
Learned parameters: [2.2176648218369754, 3.707903811268262, 5.57357488246625, -2.426122459174835]
Epoch: 3724  loss: 63.25674460129882
Learned parameters: [2.2175615776506583, 3.7080488491918957, 5.573782784720748, -2.42640541325732]
Epoch: 3725  loss: 63.25018795223202
Learned parameters: [2.2174583983392915, 3.708193794636149, 5.573990555875172, -2.426688187733563]
Epoch: 3726  loss: 63.24364297644492
Learned parameters: [2.217355283889677, 3.7083386476221727, 5.574198195956796, -2.426970782643506]
Epoch: 3727  loss: 63.23710965653095
Learned parameters: [2.2172522342883636, 3.70848340817121, 5.574405704992553, -2.4272531980270466]
Epoch: 3728  loss: 63.230587975107824
Learned parameters: [2.217149249522178, 3.7086280763044437, 5.5746130830097815, -2.4275354339241244]
Epoch: 3729  loss: 63.224077914815695
Learned parameters: [2.2170463295782445, 3.7087726520429913, 5.574820330036251, -2.4278174903747245]
Epoch: 3730  loss: 63.217579458320316
Learned parameters: [2.2169434744435392, 3.708917135408029, 5.575027446099534, -2.428099367418803]
Epoch: 3731  loss: 63.21109258829807
Learned parameters: [2.216840684104729, 3.709061526420858, 5.575234431226798, -2.4283810650962634]
Epoch: 3732  loss: 63.20461728745232
Learned parameters: [2.2167379585484883, 3.7092058251028193, 5.575441285445248, -2.428662583447008]
Epoch: 3733  loss: 63.19815353850946
Learned parameters: [2.2166352977617754, 3.709350031475201, 5.575648008782509, -2.428943922510989]
Epoch: 3734  loss: 63.19170132421307
Learned parameters: [2.2165327017316185, 3.709494145559274, 5.575854601266305, -2.4292250823281583]
Epoch: 3735  loss: 63.18526062733555
Learned parameters: [2.216430170444818, 3.709638167376376, 5.576061062924044, -2.4295060629384264]
Epoch: 3736  loss: 63.17883143067506
Learned parameters: [2.2163277038880294, 3.709782096947891, 5.576267393782936, -2.429786864381675]
Epoch: 3737  loss: 63.17241371704094
Learned parameters: [2.2162253020480827, 3.7099259342951587, 5.576473593870443, -2.430067486697812]
Epoch: 3738  loss: 63.166007469271754
Learned parameters: [2.2161229649119836, 3.7100696794394654, 5.576679663214275, -2.4303479299267705]
Epoch: 3739  loss: 63.1596126702343
Learned parameters: [2.2160206924665924, 3.7102133324020867, 5.576885601841914, -2.4306281941084613]
Epoch: 3740  loss: 63.153229302807645
Learned parameters: [2.2159184846986304, 3.710356893204338, 5.57709140978065, -2.430908279282769]
Epoch: 3741  loss: 63.14685734989915
Learned parameters: [2.2158163415948877, 3.710500361867518, 5.577297087057875, -2.4311881854895874]
Epoch: 3742  loss: 63.140496794434256
Learned parameters: [2.21571426314229, 3.7106437384128923, 5.577502633701182, -2.431467912768832]
Epoch: 3743  loss: 63.13414761936049
Learned parameters: [2.2156122493277453, 3.710787022861742, 5.577708049738148, -2.431747461160416]
Epoch: 3744  loss: 63.12780980764328
Learned parameters: [2.215510300138028, 3.7109302152353982, 5.577913335196178, -2.4320268307042343]
Epoch: 3745  loss: 63.1214833422714
Learned parameters: [2.2154084155598825, 3.7110733155552045, 5.578118490102642, -2.4323060214401737]
Epoch: 3746  loss: 63.115168206263746
Learned parameters: [2.2153065955801603, 3.7112163238424793, 5.578323514485067, -2.432585033408138]
Epoch: 3747  loss: 63.108864382644825
Learned parameters: [2.215204840185791, 3.7113592401185818, 5.578528408371132, -2.432863866648041]
Epoch: 3748  loss: 63.10257185445713
Learned parameters: [2.2151031493636264, 3.711502064405027, 5.578733171788486, -2.4331425211997795]
Epoch: 3749  loss: 63.09629060476922
Learned parameters: [2.21500152310032, 3.7116447967233506, 5.5789378047644895, -2.433420997103217]
Epoch: 3750  loss: 63.09002061668644
Learned parameters: [2.214899961382598, 3.7117874370950417, 5.579142307326593, -2.43369929439823]
Epoch: 3751  loss: 63.08376187331885
Learned parameters: [2.2147984641973935, 3.711929985541549, 5.5793466795025655, -2.43397741312475]
Epoch: 3752  loss: 63.07751435780423
Learned parameters: [2.214697031531613, 3.712072442084314, 5.579550921320142, -2.4342553533227074]
Epoch: 3753  loss: 63.07127805330397
Learned parameters: [2.2145956633719552, 3.7122148067448184, 5.579755032806762, -2.434533115032002]
Epoch: 3754  loss: 63.06505294300148
Learned parameters: [2.2144943597051077, 3.7123570795445375, 5.579959013989859, -2.4348106982925466]
Epoch: 3755  loss: 63.058839010096825
Learned parameters: [2.2143931205179097, 3.7124992605048885, 5.580162864897081, -2.4350881031442837]
Epoch: 3756  loss: 63.05263623782159
Learned parameters: [2.2142919457972448, 3.7126413496472006, 5.580366585556104, -2.435365329627168]
Epoch: 3757  loss: 63.04644460943328
Learned parameters: [2.214190835529872, 3.7127833469927354, 5.580570175994378, -2.435642377781135]
Epoch: 3758  loss: 63.040264108210856
Learned parameters: [2.2140897897025447, 3.7129252525627474, 5.580773636239348, -2.435919247646121]
Epoch: 3759  loss: 63.034094717446564
Learned parameters: [2.213988808302067, 3.713067066378469, 5.580976966318535, -2.4361959392620727]
Epoch: 3760  loss: 63.027936420455475
Learned parameters: [2.213887891315295, 3.713208788461119, 5.581180166259538, -2.4364724526689447]
Epoch: 3761  loss: 63.021789200570765
Learned parameters: [2.2137870387290253, 3.713350418831933, 5.581383236089883, -2.436748787906684]
Epoch: 3762  loss: 63.01565304115206
Learned parameters: [2.213686250529996, 3.7134919575121654, 5.581586175837022, -2.437024945015229]
Epoch: 3763  loss: 63.00952792557739
Learned parameters: [2.213585526704966, 3.713633404523069, 5.581788985528444, -2.437300924034523]
Epoch: 3764  loss: 63.003413837247564
Learned parameters: [2.2134848672407723, 3.7137747598858764, 5.581991665191758, -2.437576725004524]
Epoch: 3765  loss: 62.99731075958232
Learned parameters: [2.213384272124205, 3.7139160236217807, 5.58219421485448, -2.4378523479651797]
Epoch: 3766  loss: 62.99121867603811
Learned parameters: [2.213283741341993, 3.714057195751898, 5.58239663454399, -2.438127792956426]
Epoch: 3767  loss: 62.98513757008072
Learned parameters: [2.213183274880947, 3.7141982762973256, 5.582598924287788, -2.4384030600182083]
Epoch: 3768  loss: 62.97906742520566
Learned parameters: [2.2130828727279086, 3.7143392652791385, 5.582801084113412, -2.4386781491904737]
Epoch: 3769  loss: 62.97300822491856
Learned parameters: [2.212982534869685, 3.71448016271845, 5.583003114048375, -2.4389530605131644]
Epoch: 3770  loss: 62.96695995274655
Learned parameters: [2.212882261293018, 3.7146209686364244, 5.583205014120122, -2.4392277940262166]
Epoch: 3771  loss: 62.96092259223667
Learned parameters: [2.2127820519846546, 3.7147616830542454, 5.583406784356123, -2.4395023497695654]
Epoch: 3772  loss: 62.95489612695924
Learned parameters: [2.212681906931401, 3.7149023059930997, 5.583608424783944, -2.4397767277831526]
Epoch: 3773  loss: 62.94888054050135
Learned parameters: [2.212581826120076, 3.715042837474189, 5.583809935431182, -2.44005092810692]
Epoch: 3774  loss: 62.942875816479784
Learned parameters: [2.2124818095374326, 3.7151832775187588, 5.584011316325359, -2.4403249507807976]
Epoch: 3775  loss: 62.93688193851922
Learned parameters: [2.2123818571702074, 3.715323626148105, 5.584212567494008, -2.440598795844712]
Epoch: 3776  loss: 62.93089889026645
Learned parameters: [2.212281969005156, 3.7154638833835296, 5.584413688964697, -2.440872463338593]
Epoch: 3777  loss: 62.92492665539857
Learned parameters: [2.212182145029077, 3.7156040492463602, 5.584614680765086, -2.4411459533023843]
Epoch: 3778  loss: 62.91896521760616
Learned parameters: [2.2120823852287357, 3.7157441237579403, 5.584815542922796, -2.4414192657760228]
Epoch: 3779  loss: 62.91301456060018
Learned parameters: [2.2119826895908457, 3.715884106939627, 5.585016275465379, -2.441692400799434]
Epoch: 3780  loss: 62.907074668119655
Learned parameters: [2.2118830581021394, 3.7160239988127732, 5.585216878420418, -2.4419653584125434]
Epoch: 3781  loss: 62.901145523921
Learned parameters: [2.2117834907494043, 3.7161637993987062, 5.585417351815575, -2.4422381386552883]
Epoch: 3782  loss: 62.895227111782425
Learned parameters: [2.211683987519405, 3.7163035087187293, 5.5856176956784696, -2.4425107415676046]
Epoch: 3783  loss: 62.88931941550619
Learned parameters: [2.211584548398869, 3.7164431267941618, 5.5858179100366785, -2.4427831671894253]
Epoch: 3784  loss: 62.883422418911806
Learned parameters: [2.211485173374521, 3.7165826536463134, 5.586017994917782, -2.443055415560686]
Epoch: 3785  loss: 62.8775361058353
Learned parameters: [2.211385862433118, 3.7167220892964896, 5.586217950349412, -2.443327486721331]
Epoch: 3786  loss: 62.87166046013944
Learned parameters: [2.211286615561435, 3.716861433765995, 5.586417776359239, -2.4435993807113086]
Epoch: 3787  loss: 62.865795465704686
Learned parameters: [2.2111874327461973, 3.717000687076151, 5.586617472974873, -2.443871097570563]
Epoch: 3788  loss: 62.85994110643578
Learned parameters: [2.211088313974113, 3.717139849248289, 5.586817040223912, -2.4441426373390374]
Epoch: 3789  loss: 62.85409736625046
Learned parameters: [2.21098925923192, 3.71727892030374, 5.587016478134012, -2.444414000056691]
Epoch: 3790  loss: 62.84826422909126
Learned parameters: [2.2108902685063647, 3.7174179002638605, 5.587215786732868, -2.4446851857634906]
Epoch: 3791  loss: 62.842441678902134
Learned parameters: [2.210791341784243, 3.7175567891502035, 5.587414966048376, -2.444956194499409]
Epoch: 3792  loss: 62.83662969965723
Learned parameters: [2.210692479052152, 3.7176955869843513, 5.587614016108149, -2.445227026304392]
Epoch: 3793  loss: 62.830828275358144
Learned parameters: [2.2105936802966886, 3.717834293787857, 5.587812936939792, -2.445497681218391]
Epoch: 3794  loss: 62.82503739002824
Learned parameters: [2.2104949455046183, 3.7179729095821967, 5.588011728571144, -2.4457681592813927]
Epoch: 3795  loss: 62.81925702770924
Learned parameters: [2.210396274662752, 3.718111434388812, 5.588210391030106, -2.4460384605333987]
Epoch: 3796  loss: 62.81348717246281
Learned parameters: [2.2102976677577613, 3.7182498682291985, 5.588408924344419, -2.446308585014414]
Epoch: 3797  loss: 62.807727808366835
Learned parameters: [2.210199124776204, 3.718388211124864, 5.588607328541663, -2.446578532764434]
Epoch: 3798  loss: 62.80197891952741
Learned parameters: [2.210100645704759, 3.7185264630972577, 5.588805603649591, -2.4468483038234825]
Epoch: 3799  loss: 62.7962404900679
Learned parameters: [2.2100022305302027, 3.71866462416778, 5.589003749696089, -2.4471178982316073]
Epoch: 3800  loss: 62.7905125041428
Learned parameters: [2.2099038792392065, 3.7188026943576986, 5.589201766708825, -2.4473873160288533]
Epoch: 3801  loss: 62.784794945927686
Learned parameters: [2.2098055918183874, 3.7189406736882544, 5.589399654715377, -2.4476565572552698]
Epoch: 3802  loss: 62.7790877996088
Learned parameters: [2.209707368254453, 3.719078562180663, 5.589597413743464, -2.447925621950926]
Epoch: 3803  loss: 62.773391049402925
Learned parameters: [2.209609208534137, 3.7192163598561137, 5.589795043820839, -2.4481945101558966]
Epoch: 3804  loss: 62.767704679532464
Learned parameters: [2.2095111126441176, 3.719354066735815, 5.589992544975192, -2.4484632219102527]
Epoch: 3805  loss: 62.76202867424882
Learned parameters: [2.209413080571022, 3.7194916828409963, 5.590189917234154, -2.4487317572540603]
Epoch: 3806  loss: 62.756363017819844
Learned parameters: [2.209315112301503, 3.7196292081928846, 5.590387160625406, -2.4490001162273947]
Epoch: 3807  loss: 62.75070769453477
Learned parameters: [2.209217207822262, 3.7197666428127003, 5.59058427517671, -2.449268298870342]
Epoch: 3808  loss: 62.745062688701566
Learned parameters: [2.2091193671199822, 3.7199039867216745, 5.590781260915813, -2.449536305222988]
Epoch: 3809  loss: 62.739427984649794
Learned parameters: [2.2090215901812855, 3.7200412399410188, 5.590978117870364, -2.44980413532541]
Epoch: 3810  loss: 62.733803566738445
Learned parameters: [2.208923876992792, 3.7201784024918667, 5.591174846067968, -2.450071789217684]
Epoch: 3811  loss: 62.728189419342726
Learned parameters: [2.208826227541213, 3.7203154743953473, 5.591371445536379, -2.4503392669399036]
Epoch: 3812  loss: 62.722585526851006
Learned parameters: [2.208728641813272, 3.7204524556725875, 5.5915679163033705, -2.4506065685321596]
Epoch: 3813  loss: 62.71699187368058
Learned parameters: [2.2086311197955877, 3.720589346344732, 5.591764258396565, -2.45087369403452]
Epoch: 3814  loss: 62.711408444263924
Learned parameters: [2.2085336614747737, 3.72072614643295, 5.591960471843599, -2.4511406434870535]
Epoch: 3815  loss: 62.705835223045575
Learned parameters: [2.208436266837505, 3.720862855958426, 5.5921565566722204, -2.4514074169298454]
Epoch: 3816  loss: 62.7002721944971
Learned parameters: [2.208338935870483, 3.7209994749423707, 5.592352512910245, -2.4516740144029967]
Epoch: 3817  loss: 62.694719343106854
Learned parameters: [2.2082416685603365, 3.7211360034060355, 5.5925483405854015, -2.451940435946596]
Epoch: 3818  loss: 62.68917665337775
Learned parameters: [2.208144464893648, 3.7212724413707003, 5.59274403972537, -2.452206681600724]
Epoch: 3819  loss: 62.683644109843364
Learned parameters: [2.208047324857067, 3.7214087888576586, 5.592939610357949, -2.4524727514054736]
Epoch: 3820  loss: 62.678121697047835
Learned parameters: [2.2079502484372737, 3.721545045888212, 5.593135052510993, -2.4527386454009426]
Epoch: 3821  loss: 62.67260939955766
Learned parameters: [2.2078532356208913, 3.7216812124836918, 5.59333036621229, -2.4530043636272203]
Epoch: 3822  loss: 62.667107201961244
Learned parameters: [2.207756286394515, 3.721817288665465, 5.593525551489616, -2.453269906124399]
Epoch: 3823  loss: 62.66161508886195
Learned parameters: [2.2076594007447525, 3.721953274454918, 5.593720608370786, -2.4535352729325783]
Epoch: 3824  loss: 62.656133044885856
Learned parameters: [2.2075625786582367, 3.7220891698734344, 5.593915536883661, -2.453800464091863]
Epoch: 3825  loss: 62.65066105467486
Learned parameters: [2.2074658201216026, 3.722224974942391, 5.594110337056108, -2.454065479642361]
Epoch: 3826  loss: 62.64519910290448
Learned parameters: [2.207369125121428, 3.722360689683159, 5.594305008915908, -2.454330319624174]
Epoch: 3827  loss: 62.63974717425651
Learned parameters: [2.2072724936443167, 3.7224963141171092, 5.594499552490898, -2.454594984077415]
Epoch: 3828  loss: 62.634305253436764
Learned parameters: [2.2071759256768972, 3.722631848265609, 5.594693967808958, -2.454859473042204]
Epoch: 3829  loss: 62.628873325173906
Learned parameters: [2.207079421205779, 3.7227672921500194, 5.594888254897943, -2.45512378655866]
Epoch: 3830  loss: 62.623451374211555
Learned parameters: [2.2069829802175462, 3.722902645791713, 5.595082413785686, -2.455387924666903]
Epoch: 3831  loss: 62.61803938531067
Learned parameters: [2.2068866026987903, 3.723037909212066, 5.595276444500046, -2.45565188740706]
Epoch: 3832  loss: 62.61263734325964
Learned parameters: [2.2067902886361233, 3.7231730824324485, 5.595470347068919, -2.455915674819265]
Epoch: 3833  loss: 62.60724523285981
Learned parameters: [2.2066940380161317, 3.7233081654742404, 5.595664121520179, -2.4561792869436547]
Epoch: 3834  loss: 62.601863038936116
Learned parameters: [2.206597850825389, 3.7234431583588288, 5.595857767881695, -2.456442723820369]
Epoch: 3835  loss: 62.59649074632115
Learned parameters: [2.2065017270505476, 3.7235780611078058, 5.596051286181588, -2.4567059854895636]
Epoch: 3836  loss: 62.591128339849284
Learned parameters: [2.206405666678145, 3.723712873742881, 5.596244676447886, -2.4569690719913857]
Epoch: 3837  loss: 62.58577580439618
Learned parameters: [2.206309669694589, 3.723847596285767, 5.596437938708428, -2.457231983365973]
Epoch: 3838  loss: 62.58043312485744
Learned parameters: [2.2062137360864087, 3.7239822287581132, 5.596631072991225, -2.4574947196534964]
Epoch: 3839  loss: 62.57510028615002
Learned parameters: [2.206117865840273, 3.724116771181508, 5.596824079324491, -2.4577572808941697]
Epoch: 3840  loss: 62.56977727321168
Learned parameters: [2.206022058942751, 3.7242512235775367, 5.597016957736298, -2.458019667128202]
Epoch: 3841  loss: 62.56446407099325
Learned parameters: [2.205926315380279, 3.724385585967791, 5.597209708254535, -2.4582818783957965]
Epoch: 3842  loss: 62.55916066447084
Learned parameters: [2.2058306351393298, 3.7245198583738484, 5.597402330907161, -2.4585439147371853]
Epoch: 3843  loss: 62.55386703863584
Learned parameters: [2.20573501820651, 3.724654040817235, 5.597594825722338, -2.4588057761926434]
Epoch: 3844  loss: 62.548583178501374
Learned parameters: [2.205639464568383, 3.7247881333194606, 5.597787192728167, -2.459067462802452]
Epoch: 3845  loss: 62.54330906910633
Learned parameters: [2.205543974211325, 3.724922135901846, 5.597979431952366, -2.4593289746068727]
Epoch: 3846  loss: 62.53804469552699
Learned parameters: [2.2054485471218723, 3.7250560485856496, 5.59817154342288, -2.459590311646205]
Epoch: 3847  loss: 62.53279004283119
Learned parameters: [2.205353183286688, 3.7251898713920966, 5.598363527167851, -2.459851473960779]
Epoch: 3848  loss: 62.52754509611087
Learned parameters: [2.2052578826923135, 3.725323604342444, 5.598555383215266, -2.4601124615909207]
Epoch: 3849  loss: 62.52230984048478
Learned parameters: [2.2051626453251276, 3.7254572474579692, 5.598747111592882, -2.460373274576932]
Epoch: 3850  loss: 62.51708426108647
Learned parameters: [2.2050674711716, 3.725590800759932, 5.598938712328601, -2.460633912959138]
Epoch: 3851  loss: 62.51186834305932
Learned parameters: [2.2049723602183513, 3.7257242642695596, 5.599130185450554, -2.4608943767778957]
Epoch: 3852  loss: 62.50666207157754
Learned parameters: [2.2048773124519396, 3.725857638008104, 5.599321530986799, -2.4611546660735564]
Epoch: 3853  loss: 62.50146543183054
Learned parameters: [2.2047823278587657, 3.7259909219968685, 5.599512748965189, -2.46141478088645]
Epoch: 3854  loss: 62.496278409022466
Learned parameters: [2.204687406425261, 3.7261241162571546, 5.599703839413633, -2.4616747212569177]
Epoch: 3855  loss: 62.49110098838648
Learned parameters: [2.2045925481379385, 3.7262572208101465, 5.599894802360106, -2.461934487225313]
Epoch: 3856  loss: 62.48593315517802
Learned parameters: [2.2044977529834, 3.726390235677028, 5.600085637832734, -2.4621940788320082]
Epoch: 3857  loss: 62.48077489465661
Learned parameters: [2.2044030209481416, 3.726523160879034, 5.600276345859512, -2.462453496117363]
Epoch: 3858  loss: 62.475626192108535
Learned parameters: [2.2043083520185545, 3.7266559964374446, 5.600466926468306, -2.462712739121722]
Epoch: 3859  loss: 62.47048703283966
Learned parameters: [2.2042137461810825, 3.7267887423735058, 5.6006573796870445, -2.4629718078854284]
Epoch: 3860  loss: 62.46535740217559
Learned parameters: [2.204119203422295, 3.7269213987084537, 5.600847705543858, -2.4632307024488522]
Epoch: 3861  loss: 62.46023728545248
Learned parameters: [2.2040247237287267, 3.7270539654635586, 5.601037904066846, -2.4634894228523594]
Epoch: 3862  loss: 62.455126668035824
Learned parameters: [2.203930307086785, 3.72718644266015, 5.601227975283952, -2.4637479691362993]
Epoch: 3863  loss: 62.45002553529495
Learned parameters: [2.2038359534828786, 3.7273188303195854, 5.601417919223147, -2.4640063413410287]
Epoch: 3864  loss: 62.44493387263019
Learned parameters: [2.2037416629035027, 3.7274511284632217, 5.601607735912545, -2.4642645395069236]
Epoch: 3865  loss: 62.43985166545476
Learned parameters: [2.2036474353351845, 3.7275833371124176, 5.601797425380319, -2.4645225636743717]
Epoch: 3866  loss: 62.43477889920047
Learned parameters: [2.2035532707643566, 3.727715456288577, 5.601986987654529, -2.4647804138837475]
Epoch: 3867  loss: 62.429715559322474
Learned parameters: [2.203459169177409, 3.727847486013133, 5.6021764227631925, -2.465038090175423]
Epoch: 3868  loss: 62.42466163128675
Learned parameters: [2.2033651305607957, 3.727979426307516, 5.602365730734434, -2.4652955925897846]
Epoch: 3869  loss: 62.419617100585015
Learned parameters: [2.203271154901017, 3.7281112771931793, 5.602554911596475, -2.465552921167238]
Epoch: 3870  loss: 62.41458195272232
Learned parameters: [2.2031772421845153, 3.728243038691606, 5.602743965377476, -2.465810075948183]
Epoch: 3871  loss: 62.409556173220665
Learned parameters: [2.203083392397639, 3.728374710824287, 5.602932892105464, -2.4660670569730128]
Epoch: 3872  loss: 62.40453974763314
Learned parameters: [2.202989605526806, 3.7285062936127034, 5.60312169180858, -2.4663238642821352]
Epoch: 3873  loss: 62.39953266151661
Learned parameters: [2.202895881558518, 3.7286377870783216, 5.603310364515099, -2.46658049791598]
Epoch: 3874  loss: 62.39453490045467
Learned parameters: [2.2028022204792213, 3.7287691912426313, 5.603498910253235, -2.466836957914973]
Epoch: 3875  loss: 62.389546450051995
Learned parameters: [2.2027086222752588, 3.728900506127147, 5.603687329051066, -2.4670932443195293]
Epoch: 3876  loss: 62.3845672959228
Learned parameters: [2.202615086933011, 3.7290317317533805, 5.603875620936741, -2.4673493571700784]
Epoch: 3877  loss: 62.37959742370708
Learned parameters: [2.2025216144389375, 3.7291628681428257, 5.604063785938533, -2.467605296507071]
Epoch: 3878  loss: 62.37463681905838
Learned parameters: [2.202428204779488, 3.729293915316986, 5.604251824084723, -2.467861062370965]
Epoch: 3879  loss: 62.36968546765253
Learned parameters: [2.202334857941013, 3.729424873297391, 5.604439735403462, -2.4681166548022087]
Epoch: 3880  loss: 62.36474335518355
Learned parameters: [2.202241573909853, 3.729555742105574, 5.604627519922903, -2.4683720738412602]
Epoch: 3881  loss: 62.35981046734285
Learned parameters: [2.2021483526725603, 3.7296865217633703, 5.60481517767172, -2.468627319528615]
Epoch: 3882  loss: 62.354886789835874
Learned parameters: [2.2020551942154034, 3.729817212292663, 5.605002708678188, -2.4688823919047342]
Epoch: 3883  loss: 62.34997230841481
Learned parameters: [2.2019620985245503, 3.7299478137153272, 5.605190112970438, -2.469137291010079]
Epoch: 3884  loss: 62.34506700883239
Learned parameters: [2.2018690655863966, 3.7300783260531416, 5.6053773905769235, -2.4693920168851653]
Epoch: 3885  loss: 62.34017087687805
Learned parameters: [2.2017760953874497, 3.730208749327818, 5.605564541526254, -2.469646569570545]
Epoch: 3886  loss: 62.33528389835128
Learned parameters: [2.2016831879140475, 3.7303390835610792, 5.605751565846802, -2.4699009491067603]
Epoch: 3887  loss: 62.3304060590651
Learned parameters: [2.201590343152366, 3.730469328774663, 5.605938463566715, -2.470155155534345]
Epoch: 3888  loss: 62.325537344861196
Learned parameters: [2.201497561088715, 3.730599484990242, 5.606125234714337, -2.4704091888938735]
Epoch: 3889  loss: 62.3206777415951
Learned parameters: [2.201404841709562, 3.7307295522294197, 5.606311879318241, -2.4706630492259647]
Epoch: 3890  loss: 62.31582723513728
Learned parameters: [2.20131218500127, 3.730859530513841, 5.606498397406886, -2.470916736571254]
Epoch: 3891  loss: 62.31098581138134
Learned parameters: [2.2012195909499486, 3.7309894198649625, 5.60668478900825, -2.471170250970353]
Epoch: 3892  loss: 62.30615345626704
Learned parameters: [2.201127059541895, 3.7311192203041177, 5.606871054150551, -2.4714235924639176]
Epoch: 3893  loss: 62.30133015572051
Learned parameters: [2.2010345907636615, 3.7312489318525808, 5.607057192862385, -2.4716767610926604]
Epoch: 3894  loss: 62.29651589569031
Learned parameters: [2.2009421846016255, 3.7313785545316858, 5.607243205172133, -2.4719297568972767]
Epoch: 3895  loss: 62.29171066214565
Learned parameters: [2.200849841041904, 3.7315080883628515, 5.60742909110783, -2.472182579918433]
Epoch: 3896  loss: 62.28691444107117
Learned parameters: [2.2007575600707048, 3.7316375333674463, 5.607614850697639, -2.472435230196814]
Epoch: 3897  loss: 62.28212721847317
Learned parameters: [2.2006653416744855, 3.731766889566791, 5.6078004839701, -2.472687707773157]
Epoch: 3898  loss: 62.27734898036843
Learned parameters: [2.2005731858396684, 3.7318961569822378, 5.607985990953727, -2.472940012688206]
Epoch: 3899  loss: 62.27257971279553
Learned parameters: [2.2004810925524114, 3.7320253356352295, 5.6081713716766926, -2.4731921449826686]
Epoch: 3900  loss: 62.267819401814705
Learned parameters: [2.2003890617988624, 3.732154425547227, 5.60835662616717, -2.473444104697257]
Epoch: 3901  loss: 62.26306803349508
Learned parameters: [2.200297093565388, 3.7322834267396177, 5.608541754453642, -2.4736958918727185]
Epoch: 3902  loss: 62.25832559393919
Learned parameters: [2.2002051878384026, 3.732412339233759, 5.608726756564657, -2.4739475065498144]
Epoch: 3903  loss: 62.25359206925512
Learned parameters: [2.200113344604133, 3.732541163051084, 5.608911632528526, -2.4741989487692804]
Epoch: 3904  loss: 62.24886744557307
Learned parameters: [2.200021563848714, 3.7326698982130746, 5.609096382373455, -2.474450218571842]
Epoch: 3905  loss: 62.2441517090344
Learned parameters: [2.1999298455584464, 3.732798544741189, 5.609281006127904, -2.4747013159982587]
Epoch: 3906  loss: 62.2394448458092
Learned parameters: [2.199838189719694, 3.7329271026568653, 5.609465503820427, -2.4749522410892983]
Epoch: 3907  loss: 62.23474684208057
Learned parameters: [2.199746596318714, 3.7330555719815646, 5.609649875479431, -2.47520299388571]
Epoch: 3908  loss: 62.23005768404893
Learned parameters: [2.199655065341667, 3.7331839527367983, 5.609834121133211, -2.475453574428234]
Epoch: 3909  loss: 62.225377357930626
Learned parameters: [2.199563596774807, 3.7333122449440763, 5.610018240810216, -2.475703982757633]
Epoch: 3910  loss: 62.22070584996198
Learned parameters: [2.199472190604448, 3.7334404486249135, 5.610202234539006, -2.475954218914684]
Epoch: 3911  loss: 62.2160431463948
Learned parameters: [2.1993808468168456, 3.733568563800863, 5.6103861023480786, -2.4762042829401647]
Epoch: 3912  loss: 62.2113892334985
Learned parameters: [2.199289565398178, 3.7336965904935293, 5.610569844265853, -2.4764541748748483]
Epoch: 3913  loss: 62.20674409755747
Learned parameters: [2.199198346334642, 3.73382452872453, 5.610753460320797, -2.4767038947595195]
Epoch: 3914  loss: 62.20210772488061
Learned parameters: [2.1991071896125067, 3.733952378515479, 5.610936950541502, -2.4769534426349815]
Epoch: 3915  loss: 62.19748010178463
Learned parameters: [2.19901609521802, 3.734080139888011, 5.61112031495655, -2.477202818542047]
Epoch: 3916  loss: 62.1928612146113
Learned parameters: [2.1989250631373545, 3.7342078128637968, 5.611303553594441, -2.4774520225215273]
Epoch: 3917  loss: 62.18825104971768
Learned parameters: [2.198834093356692, 3.7343353974645193, 5.611486666483711, -2.4777010546142493]
Epoch: 3918  loss: 62.183649593475764
Learned parameters: [2.1987431858622357, 3.7344628937118602, 5.611669653652948, -2.477949914861057]
Epoch: 3919  loss: 62.179056832279436
Learned parameters: [2.198652340640206, 3.734590301627504, 5.611852515130779, -2.4781986033028063]
Epoch: 3920  loss: 62.174472752541156
Learned parameters: [2.198561557676799, 3.7347176212331488, 5.612035250945819, -2.4784471199803604]
Epoch: 3921  loss: 62.16989734068282
Learned parameters: [2.198470836958166, 3.73484485255051, 5.612217861126637, -2.4786954649345865]
Epoch: 3922  loss: 62.165330583151245
Learned parameters: [2.1983801784704644, 3.7349719956013003, 5.612400345701826, -2.478943638206363]
Epoch: 3923  loss: 62.160772466414286
Learned parameters: [2.1982895821998927, 3.7350990504071997, 5.612582704700042, -2.479191639836585]
Epoch: 3924  loss: 62.1562229769464
Learned parameters: [2.19819904813265, 3.735226016989896, 5.61276493814996, -2.479439469866161]
Epoch: 3925  loss: 62.15168210124955
Learned parameters: [2.1981085762548753, 3.7353528953710997, 5.612947046080192, -2.4796871283360002]
Epoch: 3926  loss: 62.14714982583499
Learned parameters: [2.1980181665526946, 3.73547968557253, 5.613129028519356, -2.4799346152870254]
Epoch: 3927  loss: 62.1426261372392
Learned parameters: [2.197927819012267, 3.7356063876159022, 5.613310885496132, -2.4801819307601765]
Epoch: 3928  loss: 62.13811102199172
Learned parameters: [2.197837533619898, 3.7357330015232644, 5.6134926170396415, -2.480429074796421]
Epoch: 3929  loss: 62.13360446663819
Learned parameters: [2.1977473103615606, 3.735859527316759, 5.6136742231785615, -2.4806760474366882]
Epoch: 3930  loss: 62.1291064577554
Learned parameters: [2.197657149223154, 3.735985965018509, 5.6138557039414625, -2.4809228487219146]
Epoch: 3931  loss: 62.12461698194009
Learned parameters: [2.1975670501908553, 3.7361123146505206, 5.614037059357306, -2.4811694786931024]
Epoch: 3932  loss: 62.120136025815754
Learned parameters: [2.1974770132509573, 3.7362385762347317, 5.61421828945522, -2.481415937391294]
Epoch: 3933  loss: 62.115663576007606
Learned parameters: [2.197387038389501, 3.7363647497931103, 5.61439939426398, -2.4816622248575144]
Epoch: 3934  loss: 62.11119961917047
Learned parameters: [2.1972971255923865, 3.7364908353476287, 5.6145803738121725, -2.481908341132789]
Epoch: 3935  loss: 62.10674414197243
Learned parameters: [2.1972072748456974, 3.7366168329201823, 5.6147612281286525, -2.4821542862582024]
Epoch: 3936  loss: 62.1022971310976
Learned parameters: [2.1971174861356713, 3.7367427425325945, 5.6149419572425, -2.4824000602748866]
Epoch: 3937  loss: 62.097858573248786
Learned parameters: [2.1970277594483845, 3.736868564206706, 5.615122561182581, -2.4826456632239697]
Epoch: 3938  loss: 62.09342845514645
Learned parameters: [2.1969380947697275, 3.7369942979643396, 5.615303039977483, -2.4828910951465724]
Epoch: 3939  loss: 62.08900676354402
Learned parameters: [2.1968484920856617, 3.737119943827085, 5.615483393655795, -2.4831363560838566]
Epoch: 3940  loss: 62.08459348520101
Learned parameters: [2.1967589513824684, 3.73724550181647, 5.615663622246602, -2.483381446077064]
Epoch: 3941  loss: 62.08018860689196
Learned parameters: [2.1966694726463296, 3.737370971954055, 5.615843725778869, -2.4836263651674346]
Epoch: 3942  loss: 62.0757921154036
Learned parameters: [2.196580055863096, 3.7374963542614976, 5.616023704281121, -2.483871113396171]
Epoch: 3943  loss: 62.07140399755076
Learned parameters: [2.196490701018655, 3.7376216487604546, 5.616203557781959, -2.484115690804496]
Epoch: 3944  loss: 62.06702424014734
Learned parameters: [2.196401408099195, 3.7377468554724995, 5.616383286310423, -2.4843600974336923]
Epoch: 3945  loss: 62.062652830046
Learned parameters: [2.196312177090887, 3.7378719744192024, 5.616562889895537, -2.4846043333250476]
Epoch: 3946  loss: 62.05828975409977
Learned parameters: [2.196223007979644, 3.7379970056222165, 5.616742368565986, -2.4848483985198184]
Epoch: 3947  loss: 62.053934999188584
Learned parameters: [2.196133900751326, 3.7381219491032245, 5.616921722350406, -2.4850922930592625]
Epoch: 3948  loss: 62.0495885522044
Learned parameters: [2.1960448553920293, 3.7382468048838624, 5.617100951277788, -2.485336016984688]
Epoch: 3949  loss: 62.04525040005488
Learned parameters: [2.19595587188789, 3.73837157298576, 5.6172800553772, -2.4855795703374226]
Epoch: 3950  loss: 62.0409205296651
Learned parameters: [2.195866950224835, 3.738496253430577, 5.61745903467741, -2.4858229531587646]
Epoch: 3951  loss: 62.036598927986795
Learned parameters: [2.1957780903887514, 3.738620846239995, 5.6176378892071455, -2.4860661654900076]
Epoch: 3952  loss: 62.032285581979835
Learned parameters: [2.1956892923656777, 3.7387453514356754, 5.617816618995373, -2.486309207372478]
Epoch: 3953  loss: 62.02798047852719
Learned parameters: [2.1956005561402843, 3.7388697690386667, 5.617995224071621, -2.486552078850827]
Epoch: 3954  loss: 62.02368360441145
Learned parameters: [2.1955118816993404, 3.7389940990705854, 5.618173704465682, -2.4867947799661407]
Epoch: 3955  loss: 62.01939494691756
Learned parameters: [2.195423269029061, 3.7391183415532194, 5.6183520602066155, -2.487037310759449]
Epoch: 3956  loss: 62.01511449307794
Learned parameters: [2.1953347181148706, 3.739242496508554, 5.618530291322389, -2.487279671271671]
Epoch: 3957  loss: 62.01084222994283
Learned parameters: [2.1952462289426125, 3.739366563958484, 5.618708397841606, -2.487521861543827]
Epoch: 3958  loss: 62.00657814457729
Learned parameters: [2.195157801498854, 3.7394905439247283, 5.6188863797939295, -2.4877638816170826]
Epoch: 3959  loss: 62.002322224061814
Learned parameters: [2.1950694357698675, 3.7396144364291053, 5.619064237208649, -2.4880057315325863]
Epoch: 3960  loss: 61.99807445548823
Learned parameters: [2.194981131741191, 3.739738241493653, 5.619241970114066, -2.4882474113313986]
Epoch: 3961  loss: 61.99383482597375
Learned parameters: [2.194892889398556, 3.7398619591403883, 5.619419578538799, -2.488488921054641]
Epoch: 3962  loss: 61.98960332264522
Learned parameters: [2.1948047087283045, 3.739985589391169, 5.619597062512356, -2.4887302607435613]
Epoch: 3963  loss: 61.98537993264539
Learned parameters: [2.1947165897167085, 3.740109132267879, 5.619774422064178, -2.488971430439425]
Epoch: 3964  loss: 61.981164643140964
Learned parameters: [2.1946285323494377, 3.740232587792574, 5.619951657222892, -2.4892124301834286]
Epoch: 3965  loss: 61.97695744130861
Learned parameters: [2.194540536612143, 3.7403559559873134, 5.620128768017126, -2.4894532600167962]
Epoch: 3966  loss: 61.97275831434066
Learned parameters: [2.1944526024909865, 3.7404792368740027, 5.6203057544762425, -2.4896939199808625]
Epoch: 3967  loss: 61.96856724945296
Learned parameters: [2.1943647299722175, 3.7406024304745404, 5.620482616629768, -2.4899344101170104]
Epoch: 3968  loss: 61.96438423387116
Learned parameters: [2.1942769190416014, 3.740725536810967, 5.620659354506585, -2.490174730466577]
Epoch: 3969  loss: 61.96020925483602
Learned parameters: [2.1941891696847473, 3.7408485559053664, 5.620835968135381, -2.490414881070902]
Epoch: 3970  loss: 61.95604229960803
Learned parameters: [2.19410148188767, 3.740971487779709, 5.621012457545442, -2.4906548619714157]
Epoch: 3971  loss: 61.951883355467594
Learned parameters: [2.194013855636565, 3.7410943324559165, 5.62118882276633, -2.4908946732096036]
Epoch: 3972  loss: 61.94773240970346
Learned parameters: [2.1939262909172412, 3.741217089955981, 5.62136506382707, -2.491134314826911]
Epoch: 3973  loss: 61.94358944963074
Learned parameters: [2.1938387877153254, 3.741339760301939, 5.621541180756456, -2.4913737868647785]
Epoch: 3974  loss: 61.93945446257702
Learned parameters: [2.193751346016734, 3.7414623435157544, 5.6217171735837175, -2.491613089364722]
Epoch: 3975  loss: 61.93532743588334
Learned parameters: [2.1936639658075796, 3.7415848396193385, 5.621893042338388, -2.4918522223683115]
Epoch: 3976  loss: 61.931208356904655
Learned parameters: [2.1935766470737064, 3.741707248634678, 5.622068787049651, -2.492091185917098]
Epoch: 3977  loss: 61.92709721300038
Learned parameters: [2.1934893898008943, 3.7418295705842137, 5.622244407746873, -2.492329980052631]
Epoch: 3978  loss: 61.92299399153768
Learned parameters: [2.193402193974777, 3.741951805490415, 5.622419904459238, -2.4925686048164617]
Epoch: 3979  loss: 61.91889867991937
Learned parameters: [2.1933150595811597, 3.742073953375655, 5.6225952772161705, -2.492807060250197]
Epoch: 3980  loss: 61.91481126556751
Learned parameters: [2.19322798660599, 3.7421960142622193, 5.622770526047299, -2.493045346395494]
Epoch: 3981  loss: 61.91073173591495
Learned parameters: [2.193140975035072, 3.7423179881723883, 5.622945650982056, -2.493283463294018]
Epoch: 3982  loss: 61.906660078417325
Learned parameters: [2.193054024854046, 3.742439875128444, 5.623120652049654, -2.493521410987437]
Epoch: 3983  loss: 61.90259628054735
Learned parameters: [2.1929671360486607, 3.742561675152601, 5.623295529279468, -2.493759189517465]
Epoch: 3984  loss: 61.898540329789824
Learned parameters: [2.192880308604803, 3.742683388267007, 5.6234702827010805, -2.493996798925871]
Epoch: 3985  loss: 61.894492213646735
Learned parameters: [2.192793542508267, 3.7428050144937988, 5.6236449123439565, -2.4942342392544354]
Epoch: 3986  loss: 61.890451919639005
Learned parameters: [2.1927068377446974, 3.742926553855125, 5.623819418237369, -2.4944715105449466]
Epoch: 3987  loss: 61.88641943530064
Learned parameters: [2.19262019429978, 3.743048006373097, 5.623993800410664, -2.4947086128392275]
Epoch: 3988  loss: 61.88239474818549
Learned parameters: [2.192533612159302, 3.743169372069651, 5.624168058893274, -2.4949455461791437]
Epoch: 3989  loss: 61.87837784587858
Learned parameters: [2.192447091309064, 3.7432906509665904, 5.624342193714602, -2.4951823106065856]
Epoch: 3990  loss: 61.87436871597468
Learned parameters: [2.1923606317348097, 3.743411843085757, 5.6245162049040145, -2.4954189061634646]
Epoch: 3991  loss: 61.87036734606551
Learned parameters: [2.1922742334222307, 3.7435329484490336, 5.624690092490851, -2.4956553328917126]
Epoch: 3992  loss: 61.86637372376673
Learned parameters: [2.192187896357005, 3.743653967078316, 5.62486385650446, -2.4958915908332777]
Epoch: 3993  loss: 61.86238783671689
Learned parameters: [2.1921016205248662, 3.7437748989954924, 5.625037496974293, -2.496127680030133]
Epoch: 3994  loss: 61.858409672566765
Learned parameters: [2.1920154059115524, 3.7438957442224585, 5.625211013929833, -2.4963636005242664]
Epoch: 3995  loss: 61.854439218977745
Learned parameters: [2.191929252502717, 3.7440165027811103, 5.625384407400444, -2.496599352357658]
Epoch: 3996  loss: 61.85047646364353
Learned parameters: [2.191843160284023, 3.7441371746933374, 5.625557677415519, -2.4968349355722967]
Epoch: 3997  loss: 61.84652139425588
Learned parameters: [2.1917571292411924, 3.744257759981032, 5.625730824004559, -2.4970703502101936]
Epoch: 3998  loss: 61.84257399853409
Learned parameters: [2.1916711593599425, 3.7443782586661087, 5.625903847197085, -2.4973055963133706]
Epoch: 3999  loss: 61.838634264205766
Learned parameters: [2.1915852506259013, 3.744498670770527, 5.626076747022524, -2.497540673923847]
Epoch: 4000  loss: 61.834702179021164
Learned parameters: [2.1914994030246784, 3.744618996316206, 5.626249523510262, -2.497775583083646]
Epoch: 4001  loss: 61.83077773074588
Learned parameters: [2.191413616541998, 3.7447392353250604, 5.626422176689876, -2.498010323834823]
Epoch: 4002  loss: 61.826860907155805
Learned parameters: [2.191327891163569, 3.744859387819032, 5.626594706590944, -2.4982448962194366]
Epoch: 4003  loss: 61.82295169605186
Learned parameters: [2.1912422268749947, 3.744979453820111, 5.626767113242923, -2.4984793002795342]
Epoch: 4004  loss: 61.819050085237265
Learned parameters: [2.1911566236618754, 3.7450994333503167, 5.62693939667529, -2.4987135360571706]
Epoch: 4005  loss: 61.81515606254182
Learned parameters: [2.191071081509888, 3.7452193264316733, 5.627111556917661, -2.4989476035944205]
Epoch: 4006  loss: 61.811269615805166
Learned parameters: [2.1909856004047126, 3.745339133086232, 5.627283593999676, -2.4991815029333675]
Epoch: 4007  loss: 61.80739073288787
Learned parameters: [2.1909001803319406, 3.7454588533360607, 5.627455507950865, -2.499415234116083]
Epoch: 4008  loss: 61.80351940166675
Learned parameters: [2.1908148212771668, 3.745578487203249, 5.627627298800778, -2.499648797184646]
Epoch: 4009  loss: 61.7996556100266
Learned parameters: [2.190729523226034, 3.745698034709899, 5.627798966579066, -2.4998821921811536]
Epoch: 4010  loss: 61.79579934587594
Learned parameters: [2.1906442861641993, 3.7458174958781343, 5.627970511315424, -2.5001154191477153]
Epoch: 4011  loss: 61.79195059713349
Learned parameters: [2.190559110077248, 3.7459368707301297, 5.628141933039482, -2.5003484781264413]
Epoch: 4012  loss: 61.788109351735415
Learned parameters: [2.1904739949507404, 3.7460561592881216, 5.628313231780879, -2.5005813691594514]
Epoch: 4013  loss: 61.78427559762655
Learned parameters: [2.190388940770279, 3.746175361574351, 5.628484407569339, -2.5008140922888837]
Epoch: 4014  loss: 61.780449322777855
Learned parameters: [2.190303947521475, 3.7462944776110683, 5.628655460434621, -2.50104664755689]
Epoch: 4015  loss: 61.77663051516922
Learned parameters: [2.190219015189887, 3.746413507420548, 5.628826390406428, -2.501279035005624]
Epoch: 4016  loss: 61.77281916280493
Learned parameters: [2.190134143761069, 3.746532451025063, 5.628997197514474, -2.501511254677255]
Epoch: 4017  loss: 61.76901525369424
Learned parameters: [2.1900493332205992, 3.7466513084468844, 5.629167881788531, -2.501743306613976]
Epoch: 4018  loss: 61.76521877587177
Learned parameters: [2.1899645835540418, 3.746770079708301, 5.6293384432583755, -2.5019751908579924]
Epoch: 4019  loss: 61.761429717377396
Learned parameters: [2.1898798947469573, 3.746888764831624, 5.629508881953815, -2.50220690745153]
Epoch: 4020  loss: 61.757648066271166
Learned parameters: [2.189795266784869, 3.747007363839187, 5.629679197904632, -2.502438456436825]
Epoch: 4021  loss: 61.75387381063463
Learned parameters: [2.1897106996533053, 3.7471258767533304, 5.629849391140638, -2.5026698378561316]
Epoch: 4022  loss: 61.75010693855092
Learned parameters: [2.1896261933378023, 3.7472443035964007, 5.630019461691687, -2.5029010517517247]
Epoch: 4023  loss: 61.74634743813171
Learned parameters: [2.189541747823884, 3.747362644390742, 5.630189409587632, -2.5031320981658944]
Epoch: 4024  loss: 61.74259529750349
Learned parameters: [2.1894573630970497, 3.7474808991586794, 5.630359234858294, -2.5033629771409407]
Epoch: 4025  loss: 61.73885050480469
Learned parameters: [2.189373039142812, 3.747599067922544, 5.630528937533542, -2.503593688719185]
Epoch: 4026  loss: 61.735113048185795
Learned parameters: [2.1892887759466877, 3.7477171507046765, 5.630698517643283, -2.50382423294297]
Epoch: 4027  loss: 61.73138291581997
Learned parameters: [2.189204573494163, 3.747835147527443, 5.630867975217412, -2.504054609854658]
Epoch: 4028  loss: 61.72766009587175
Learned parameters: [2.1891204317708444, 3.747953058413613, 5.6310373102862705, -2.5042848194966374]
Epoch: 4029  loss: 61.72394457651514
Learned parameters: [2.189036350762029, 3.74807088338609, 5.631206522879816, -2.5045148619112685]
Epoch: 4030  loss: 61.720236345958114
Learned parameters: [2.1889523304529623, 3.7481886224677403, 5.631375613027933, -2.504744737140929]
Epoch: 4031  loss: 61.71653539242817
Learned parameters: [2.188868370829169, 3.7483062756813084, 5.631544580760902, -2.50497444522807]
Epoch: 4032  loss: 61.71284170416925
Learned parameters: [2.188784471876235, 3.7484238430494754, 5.631713426109098, -2.505203986215182]
Epoch: 4033  loss: 61.70915526943786
Learned parameters: [2.1887006335794883, 3.748541324594947, 5.631882149102535, -2.505433360144745]
Epoch: 4034  loss: 61.7054760765064
Learned parameters: [2.1886168559241814, 3.748658720340407, 5.632050749771133, -2.505662567059259]
Epoch: 4035  loss: 61.70180411367268
Learned parameters: [2.1885331388957594, 3.748776030308455, 5.632219228145098, -2.5058916070012858]
Epoch: 4036  loss: 61.69813936923053
Learned parameters: [2.1884494824797516, 3.748893254521654, 5.632387584254781, -2.5061204800134362]
Epoch: 4037  loss: 61.694481831502216
Learned parameters: [2.188365886661493, 3.7490103930025818, 5.632555818130274, -2.506349186138321]
Epoch: 4038  loss: 61.69083148882865
Learned parameters: [2.1882823514261984, 3.7491274457738157, 5.632723929801512, -2.5065777254185617]
Epoch: 4039  loss: 61.68718832955351
Learned parameters: [2.188198876759267, 3.7492444128578515, 5.632891919298701, -2.5068060978968396]
Epoch: 4040  loss: 61.68355234205545
Learned parameters: [2.188115462646099, 3.749361294276929, 5.633059786651937, -2.5070343036158675]
Epoch: 4041  loss: 61.67992351473148
Learned parameters: [2.1880321090721035, 3.7494780900532447, 5.63322753189133, -2.507262342618387]
Epoch: 4042  loss: 61.6763018359821
Learned parameters: [2.187948816022628, 3.74959480020902, 5.633395155046937, -2.5074902149471536]
Epoch: 4043  loss: 61.672687294220594
Learned parameters: [2.1878655834829717, 3.749711424766512, 5.633562656148791, -2.5077179206449443]
Epoch: 4044  loss: 61.66907987787006
Learned parameters: [2.18778241143848, 3.749827963748, 5.633730035227036, -2.5079454597545725]
Epoch: 4045  loss: 61.66547957537715
Learned parameters: [2.1876992998744904, 3.7499444171757723, 5.633897292311834, -2.508172832318868]
Epoch: 4046  loss: 61.66188637519832
Learned parameters: [2.187616248776313, 3.750060785072139, 5.634064427433333, -2.5084000383806724]
Epoch: 4047  loss: 61.65830026580858
Learned parameters: [2.187533258129238, 3.7501770674594264, 5.634231440621682, -2.508627077982839]
Epoch: 4048  loss: 61.65472123570002
Learned parameters: [2.1874503279185613, 3.7502932643599234, 5.634398331907029, -2.508853951168226]
Epoch: 4049  loss: 61.65114927338318
Learned parameters: [2.1873674581296, 3.7504093757959325, 5.634565101319581, -2.50908065797971]
Epoch: 4050  loss: 61.647584367369355
Learned parameters: [2.1872846487476667, 3.7505254017897793, 5.63473174888957, -2.509307198460178]
Epoch: 4051  loss: 61.644026506200206
Learned parameters: [2.187201899758019, 3.7506413423638265, 5.634898274647179, -2.509533572652524]
Epoch: 4052  loss: 61.64047567842697
Learned parameters: [2.187119211145892, 3.7507571975404046, 5.635064678622554, -2.50975978059965]
Epoch: 4053  loss: 61.6369318726163
Learned parameters: [2.1870365828966025, 3.750872967341824, 5.635230960845971, -2.509985822344485]
Epoch: 4054  loss: 61.633395077348176
Learned parameters: [2.1869540149954694, 3.750988651790428, 5.635397121347744, -2.510211697929967]
Epoch: 4055  loss: 61.62986528122444
Learned parameters: [2.1868715074277185, 3.751104250908613, 5.635563160158087, -2.510437407399032]
Epoch: 4056  loss: 61.62634247284266
Learned parameters: [2.186789060178546, 3.75121976471881, 5.635729077307201, -2.5106629507946194]
Epoch: 4057  loss: 61.62282664084091
Learned parameters: [2.1867066732332447, 3.751335193243453, 5.635894872825457, -2.510888328159699]
Epoch: 4058  loss: 61.61931777384869
Learned parameters: [2.1866243465771005, 3.7514505365050095, 5.636060546743246, -2.5111135395372486]
Epoch: 4059  loss: 61.61581586052548
Learned parameters: [2.1865420801953057, 3.751565794525999, 5.636226099090858, -2.5113385849702428]
Epoch: 4060  loss: 61.61232088953933
Learned parameters: [2.186459874073043, 3.7516809673289395, 5.636391529898577, -2.511563464501658]
Epoch: 4061  loss: 61.60883284957751
Learned parameters: [2.186377728195561, 3.751796054936336, 5.636556839196797, -2.5117881781744864]
Epoch: 4062  loss: 61.60535172933789
Learned parameters: [2.186295642548142, 3.751911057370715, 5.636722027015991, -2.51201272603174]
Epoch: 4063  loss: 61.6018775175404
Learned parameters: [2.1862136171159703, 3.7520259746546576, 5.636887093386526, -2.5122371081164276]
Epoch: 4064  loss: 61.59841020290682
Learned parameters: [2.1861316518841947, 3.752140806810789, 5.637052038338758, -2.5124613244715683]
Epoch: 4065  loss: 61.59494977418268
Learned parameters: [2.186049746838027, 3.7522555538617595, 5.637216861903172, -2.5126853751402063]
Epoch: 4066  loss: 61.59149622012481
Learned parameters: [2.1859679019626896, 3.7523702158302346, 5.637381564110299, -2.512909260165403]
Epoch: 4067  loss: 61.58804952950187
Learned parameters: [2.185886117243345, 3.7524847927389158, 5.637546144990613, -2.513132979590226]
Epoch: 4068  loss: 61.58460969110156
Learned parameters: [2.18580439266513, 3.752599284610519, 5.637710604574577, -2.5133565334577552]
Epoch: 4069  loss: 61.58117669373314
Learned parameters: [2.1857227282131952, 3.752713691467741, 5.637874942892683, -2.513579921811087]
Epoch: 4070  loss: 61.57775052620922
Learned parameters: [2.185641123872743, 3.7528280133332808, 5.638039159975525, -2.5138031446933446]
Epoch: 4071  loss: 61.574331177360804
Learned parameters: [2.1855595796289355, 3.7529422502298657, 5.638203255853675, -2.514026202147665]
Epoch: 4072  loss: 61.570918636035515
Learned parameters: [2.185478095466866, 3.7530564021802557, 5.638367230557636, -2.514249094217194]
Epoch: 4073  loss: 61.567512891098076
Learned parameters: [2.1853966713716617, 3.7531704692072245, 5.638531084117998, -2.5144718209451056]
Epoch: 4074  loss: 61.56411393141419
Learned parameters: [2.1853153073284752, 3.7532844513335504, 5.638694816565419, -2.514694382374599]
Epoch: 4075  loss: 61.56072174587531
Learned parameters: [2.1852340033224107, 3.7533983485820346, 5.638858427930516, -2.5149167785488875]
Epoch: 4076  loss: 61.55733632338878
Learned parameters: [2.1851527593385582, 3.7535121609754913, 5.639021918243917, -2.5151390095112034]
Epoch: 4077  loss: 61.55395765287133
Learned parameters: [2.1850715753619965, 3.7536258885367118, 5.639185287536242, -2.5153610753047957]
Epoch: 4078  loss: 61.55058572326065
Learned parameters: [2.1849904513778395, 3.753739531288483, 5.639348535838189, -2.515582975972941]
Epoch: 4079  loss: 61.547220523502155
Learned parameters: [2.1849093873711816, 3.7538530892536097, 5.6395116631804605, -2.5158047115589377]
Epoch: 4080  loss: 61.54386204256171
Learned parameters: [2.1848283833270745, 3.7539665624549197, 5.639674669593736, -2.5160262821061035]
Epoch: 4081  loss: 61.54051026939854
Learned parameters: [2.1847474392307094, 3.7540799509156466, 5.639837555109169, -2.5162476876577893]
Epoch: 4082  loss: 61.53716519297565
Learned parameters: [2.1846665550669635, 3.7541932546591803, 5.64000031975755, -2.5164689282573334]
Epoch: 4083  loss: 61.533826802291074
Learned parameters: [2.1845857308206473, 3.7543064737088776, 5.640162963569576, -2.5166900039480935]
Epoch: 4084  loss: 61.53049508636293
Learned parameters: [2.184504966476857, 3.754419608087968, 5.640325486576352, -2.5169109147735034]
Epoch: 4085  loss: 61.52717003422211
Learned parameters: [2.184424262020749, 3.754532657819616, 5.640487888809073, -2.517131660777039]
Epoch: 4086  loss: 61.52385163491257
Learned parameters: [2.1843436174372246, 3.7546456229270104, 5.640650170298586, -2.51735224200217]
Epoch: 4087  loss: 61.520539877501875
Learned parameters: [2.184263032711084, 3.754758503433323, 5.640812331075609, -2.5175726584923863]
Epoch: 4088  loss: 61.517234751059576
Learned parameters: [2.1841825078273613, 3.7548712993616213, 5.640974371171201, -2.5177929102912477]
Epoch: 4089  loss: 61.51393624467947
Learned parameters: [2.1841020427711664, 3.7549840107349217, 5.641136290616548, -2.5180129974423635]
Epoch: 4090  loss: 61.51064434745721
Learned parameters: [2.184021637527378, 3.755096637576306, 5.641298089442553, -2.5182329199893463]
Epoch: 4091  loss: 61.50735904852023
Learned parameters: [2.183941292080764, 3.7552091799088476, 5.641459767679978, -2.5184526779758243]
Epoch: 4092  loss: 61.50408033699572
Learned parameters: [2.183861006416298, 3.7553216377555323, 5.64162132535989, -2.5186722714454923]
Epoch: 4093  loss: 61.50080820203122
Learned parameters: [2.183780780519015, 3.755434011139239, 5.641782762513425, -2.5188917004420857]
Epoch: 4094  loss: 61.49754263280648
Learned parameters: [2.183700614373719, 3.7555463000826688, 5.64194407917129, -2.519110965009335]
Epoch: 4095  loss: 61.49428361850369
Learned parameters: [2.1836205079653177, 3.7556585046085025, 5.6421052753643695, -2.5193300651910144]
Epoch: 4096  loss: 61.491031148323096
Learned parameters: [2.1835404612788163, 3.7557706247394114, 5.6422663511237285, -2.519549001030945]
Epoch: 4097  loss: 61.48778521146453
Learned parameters: [2.1834604742991193, 3.7558826604981075, 5.642427306480326, -2.519767772572958]
Epoch: 4098  loss: 61.48454579715042
Learned parameters: [2.18338054701101, 3.7559946119073553, 5.64258814146499, -2.5199863798608884]
Epoch: 4099  loss: 61.48131289461585
Learned parameters: [2.1833006793993577, 3.7561064789899343, 5.64274885610872, -2.520204822938617]
Epoch: 4100  loss: 61.47808649310685
Learned parameters: [2.1832208714491044, 3.7562182617686197, 5.642909450442648, -2.5204231018500525]
Epoch: 4101  loss: 61.47486658188377
Learned parameters: [2.1831411231450972, 3.7563299602662266, 5.643069924497802, -2.5206412166391057]
Epoch: 4102  loss: 61.47165315023294
Learned parameters: [2.1830614344721124, 3.756441574505592, 5.643230278305131, -2.5208591673496885]
Epoch: 4103  loss: 61.46844618743822
Learned parameters: [2.182981805414982, 3.75655310450952, 5.643390511895666, -2.52107695402573]
Epoch: 4104  loss: 61.465245682818626
Learned parameters: [2.1829022359586228, 3.756664550300816, 5.64355062530059, -2.521294576711187]
Epoch: 4105  loss: 61.46205162568741
Learned parameters: [2.182822726087869, 3.7567759119023316, 5.643710618551004, -2.5215120354500193]
Epoch: 4106  loss: 61.45886400538142
Learned parameters: [2.182743275787451, 3.7568871893369256, 5.643870491677864, -2.521729330286182]
Epoch: 4107  loss: 61.455682811256004
Learned parameters: [2.1826638850421762, 3.756998382627402, 5.644030244712234, -2.5219464612636546]
Epoch: 4108  loss: 61.45250803267603
Learned parameters: [2.182584553836967, 3.7571094917965713, 5.644189877685374, -2.522163428426447]
Epoch: 4109  loss: 61.44933965902074
Learned parameters: [2.182505282156637, 3.757220516867308, 5.64434939062843, -2.5223802318185666]
Epoch: 4110  loss: 61.446177679680105
Learned parameters: [2.1824260699858873, 3.7573314578625525, 5.644508783572425, -2.522596871484015]
Epoch: 4111  loss: 61.44302208405297
Learned parameters: [2.1823469173094936, 3.7574423148052585, 5.644668056548522, -2.5228133474668177]
Epoch: 4112  loss: 61.43987286156779
Learned parameters: [2.1822678241123223, 3.757553087718377, 5.644827209588037, -2.523029659811023]
Epoch: 4113  loss: 61.436730001653785
Learned parameters: [2.182188790379168, 3.7576637766249132, 5.644986242722222, -2.5232458085606826]
Epoch: 4114  loss: 61.433593493758316
Learned parameters: [2.182109816094712, 3.7577743815479394, 5.6451451559822114, -2.5234617937598522]
Epoch: 4115  loss: 61.43046332733744
Learned parameters: [2.1820309012436927, 3.7578849025105336, 5.64530394939925, -2.523677615452611]
Epoch: 4116  loss: 61.42733949187573
Learned parameters: [2.1819520458109225, 3.7579953395357375, 5.645462623004687, -2.5238932736830546]
Epoch: 4117  loss: 61.424221976858576
Learned parameters: [2.181873249781174, 3.7581056926466347, 5.645621176829854, -2.5241087684952888]
Epoch: 4118  loss: 61.42111077178905
Learned parameters: [2.1817945131391405, 3.7582159618663593, 5.645779610906006, -2.524324099933423]
Epoch: 4119  loss: 61.41800586618763
Learned parameters: [2.181715835869521, 3.7583261472180634, 5.645937925264436, -2.524539268041583]
Epoch: 4120  loss: 61.41490724957952
Learned parameters: [2.181637217957065, 3.758436248724902, 5.646096119936538, -2.5247542728639214]
Epoch: 4121  loss: 61.41181491151087
Learned parameters: [2.1815586593865213, 3.758546266410057, 5.64625419495374, -2.5249691144446076]
Epoch: 4122  loss: 61.4087288415417
Learned parameters: [2.1814801601425673, 3.7586562002967514, 5.646412150347405, -2.5251837928278187]
Epoch: 4123  loss: 61.40564902924384
Learned parameters: [2.1814017202098506, 3.758766050408209, 5.646569986148873, -2.525398308057749]
Epoch: 4124  loss: 61.40257546420219
Learned parameters: [2.181323339573081, 3.7588758167676515, 5.646727702389603, -2.5256126601786235]
Epoch: 4125  loss: 61.39950813602448
Learned parameters: [2.181245018216987, 3.758985499398305, 5.646885299101104, -2.5258268492346843]
Epoch: 4126  loss: 61.3964470343136
Learned parameters: [2.1811667561262222, 3.759095098323432, 5.647042776314814, -2.526040875270181]
Epoch: 4127  loss: 61.39339214870483
Learned parameters: [2.181088553285392, 3.7592046135663257, 5.64720013406214, -2.5262547383293783]
Epoch: 4128  loss: 61.39034346883427
Learned parameters: [2.1810104096791787, 3.7593140451502776, 5.647357372374631, -2.5264684384565768]
Epoch: 4129  loss: 61.387300984359825
Learned parameters: [2.1809323252922646, 3.759423393098591, 5.64751449128387, -2.5266819756960994]
Epoch: 4130  loss: 61.384264684947084
Learned parameters: [2.1808543001092486, 3.759532657434606, 5.647671490821358, -2.5268953500922815]
Epoch: 4131  loss: 61.38123456028298
Learned parameters: [2.180776334114725, 3.7596418381816776, 5.647828371018624, -2.5271085616894817]
Epoch: 4132  loss: 61.37821060005692
Learned parameters: [2.1806984272933216, 3.7597509353631486, 5.64798513190727, -2.5273216105320877]
Epoch: 4133  loss: 61.375192793981356
Learned parameters: [2.1806205796296676, 3.7598599490023283, 5.648141773518904, -2.527534496664509]
Epoch: 4134  loss: 61.37218113178854
Learned parameters: [2.180542791108357, 3.759968879122552, 5.648298295885125, -2.5277472201311744]
Epoch: 4135  loss: 61.369175603203175
Learned parameters: [2.1804650617139556, 3.7600777257471787, 5.648454699037528, -2.527959780976537]
Epoch: 4136  loss: 61.366176197976124
Learned parameters: [2.1803873914311747, 3.7601864888999152, 5.648610983008165, -2.5281721792450886]
Epoch: 4137  loss: 61.363182905837135
Learned parameters: [2.180309780244451, 3.76029516860469, 5.648767147828818, -2.5283844149813057]
Epoch: 4138  loss: 61.360195716558415
Learned parameters: [2.1802322281380766, 3.7604037648854227, 5.648923193531073, -2.5285964882296748]
Epoch: 4139  loss: 61.35721461992552
Learned parameters: [2.180154735096655, 3.760512277765916, 5.649079120146975, -2.5288083990347783]
Epoch: 4140  loss: 61.35423960573928
Learned parameters: [2.180077301104862, 3.760620707269909, 5.649234927708686, -2.5290201474412477]
Epoch: 4141  loss: 61.35127066381453
Learned parameters: [2.1799999261470946, 3.7607290534211715, 5.649390616247986, -2.529231733493709]
Epoch: 4142  loss: 61.348307783982776
Learned parameters: [2.179922610207657, 3.7608373162434514, 5.649546185796544, -2.5294431572368112]
Epoch: 4143  loss: 61.345350956082356
Learned parameters: [2.1798453532711095, 3.760945495760386, 5.649701636386396, -2.52965441871528]
Epoch: 4144  loss: 61.34240016997455
Learned parameters: [2.1797681553220616, 3.761053591995562, 5.64985696804967, -2.5298655179738887]
Epoch: 4145  loss: 61.33945541552731
Learned parameters: [2.17969101634487, 3.7611616049725995, 5.65001218081816, -2.530076455057409]
Epoch: 4146  loss: 61.33651668262213
Learned parameters: [2.1796139363238445, 3.7612695347151446, 5.650167274723643, -2.5302872300106496]
Epoch: 4147  loss: 61.33358396115396
Learned parameters: [2.1795369152434794, 3.761377381246767, 5.65032224979818, -2.530497842878487]
Epoch: 4148  loss: 61.330657241035055
Learned parameters: [2.1794599530882905, 3.7614851445910014, 5.650477106073886, -2.5307082937058363]
Epoch: 4149  loss: 61.327736512190995
Learned parameters: [2.1793830498425564, 3.761592824771298, 5.65063184358249, -2.53091858253761]
Epoch: 4150  loss: 61.324821764573244
Learned parameters: [2.179306205490588, 3.7617004218109034, 5.650786462355688, -2.531128709418757]
Epoch: 4151  loss: 61.321912988140625
Learned parameters: [2.1792294200169855, 3.761807935733001, 5.650940962425627, -2.5313386743943047]
Epoch: 4152  loss: 61.31901017286446
Learned parameters: [2.179152693406231, 3.761915366560823, 5.651095343824327, -2.531548477509291]
Epoch: 4153  loss: 61.316113308717846
Learned parameters: [2.1790760256425092, 3.7620227143176987, 5.651249606583433, -2.5317581188087335]
Epoch: 4154  loss: 61.313222385698516
Learned parameters: [2.178999416710143, 3.7621299790269433, 5.651403750734822, -2.531967598337696]
Epoch: 4155  loss: 61.31033739380831
Learned parameters: [2.1789228665936524, 3.7622371607118428, 5.65155777631069, -2.532176916141299]
Epoch: 4156  loss: 61.30745832307081
Learned parameters: [2.178846375277437, 3.7623442593957583, 5.651711683343115, -2.5323860722646727]
Epoch: 4157  loss: 61.30458516350885
Learned parameters: [2.178769942745671, 3.762451275102141, 5.651865471863903, -2.532595066752935]
Epoch: 4158  loss: 61.30171790517694
Learned parameters: [2.1786935689826405, 3.7625582078544326, 5.652019141905051, -2.532803899651238]
Epoch: 4159  loss: 61.298856538129264
Learned parameters: [2.178617253972818, 3.762665057676026, 5.652172693498833, -2.5330125710047757]
Epoch: 4160  loss: 61.296001052442264
Learned parameters: [2.1785409977005203, 3.7627718245903186, 5.652326126677299, -2.5332210808587217]
Epoch: 4161  loss: 61.29315143820793
Learned parameters: [2.1784648001499574, 3.7628785086207683, 5.652479441472388, -2.53342942925825]
Epoch: 4162  loss: 61.29030768552152
Learned parameters: [2.178388661305426, 3.762985109790841, 5.652632637916198, -2.5336376162485656]
Epoch: 4163  loss: 61.287469784502875
Learned parameters: [2.1783125811512947, 3.763091628123941, 5.65278571604092, -2.533845641874897]
Epoch: 4164  loss: 61.28463772527872
Learned parameters: [2.178236559671883, 3.763198063643517, 5.652938675878714, -2.534053506182482]
Epoch: 4165  loss: 61.28181149798822
Learned parameters: [2.1781605968513986, 3.7633044163730855, 5.653091517461623, -2.534261209216556]
Epoch: 4166  loss: 61.278991092784274
Learned parameters: [2.178084692674102, 3.7634106863361856, 5.653244240821803, -2.534468751022379]
Epoch: 4167  loss: 61.2761764998302
Learned parameters: [2.178008847124322, 3.7635168735563735, 5.653396845991547, -2.5346761316452375]
Epoch: 4168  loss: 61.273367709308495
Learned parameters: [2.1779330601863154, 3.7636229780572594, 5.653549333003083, -2.5348833511304227]
Epoch: 4169  loss: 61.27056471140799
Learned parameters: [2.177857331844267, 3.763728999862505, 5.653701701888576, -2.535090409523231]
Epoch: 4170  loss: 61.26776749633483
Learned parameters: [2.177781662082417, 3.7638349389957786, 5.653853952680298, -2.5352973068689795]
Epoch: 4171  loss: 61.264976054310495
Learned parameters: [2.1777060508850514, 3.7639407954807615, 5.65400608541062, -2.535504043213008]
Epoch: 4172  loss: 61.26219037555765
Learned parameters: [2.1776304982363843, 3.7640465693411835, 5.654158100111847, -2.5357106186006626]
Epoch: 4173  loss: 61.25941045032963
Learned parameters: [2.1775550041205642, 3.7641522606008, 5.654309996816218, -2.5359170330772973]
Epoch: 4174  loss: 61.256636268882254
Learned parameters: [2.1774795685218162, 3.7642578692833526, 5.654461775556103, -2.5361232866882966]
Epoch: 4175  loss: 61.25386782148749
Learned parameters: [2.177404191424394, 3.764363395412602, 5.654613436363953, -2.5363293794790707]
Epoch: 4176  loss: 61.251105098421405
Learned parameters: [2.177328872812459, 3.7644688390123586, 5.654764979272127, -2.5365353114950384]
Epoch: 4177  loss: 61.24834808998857
Learned parameters: [2.177253612670148, 3.764574200106458, 5.654916404312982, -2.5367410827816363]
Epoch: 4178  loss: 61.24559678649717
Learned parameters: [2.1771784109816346, 3.764679478718749, 5.655067711518968, -2.5369466933843294]
Epoch: 4179  loss: 61.24285117826439
Learned parameters: [2.1771032677311237, 3.764784674873092, 5.6552189009226135, -2.5371521433486115]
Epoch: 4180  loss: 61.240111255630445
Learned parameters: [2.1770281829027205, 3.764889788593349, 5.655369972556321, -2.5373574327199884]
Epoch: 4181  loss: 61.237377008943156
Learned parameters: [2.176953156480548, 3.7649948199034, 5.655520926452562, -2.537562561543998]
Epoch: 4182  loss: 61.2346484285639
Learned parameters: [2.17687818844877, 3.7650997688271355, 5.655671762643903, -2.5377675298662106]
Epoch: 4183  loss: 61.231925504865856
Learned parameters: [2.1768032787915055, 3.7652046353884754, 5.655822481162889, -2.537972337732216]
Epoch: 4184  loss: 61.22920822823585
Learned parameters: [2.1767284274928325, 3.765309419611357, 5.655973082042033, -2.538176985187616]
Epoch: 4185  loss: 61.226496589074756
Learned parameters: [2.176653634536845, 3.7654141215197217, 5.656123565313905, -2.538381472278038]
Epoch: 4186  loss: 61.22379057779362
Learned parameters: [2.1765788999076516, 3.765518741137522, 5.6562739310111345, -2.5385857990491396]
Epoch: 4187  loss: 61.22109018482194
Learned parameters: [2.1765042235893333, 3.7656232784887287, 5.656424179166345, -2.538789965546602]
Epoch: 4188  loss: 61.21839540059665
Learned parameters: [2.1764296055659376, 3.7657277335973283, 5.656574309812152, -2.5389939718161276]
Epoch: 4189  loss: 61.215706215563905
Learned parameters: [2.176355045821511, 3.7658321064873213, 5.656724322981204, -2.539197817903448]
Epoch: 4190  loss: 61.21302262019804
Learned parameters: [2.176280544340102, 3.765936397182703, 5.656874218706184, -2.539401503854322]
Epoch: 4191  loss: 61.21034460497181
Learned parameters: [2.1762061011057496, 3.766040605707436, 5.657023997019767, -2.539605029714533]
Epoch: 4192  loss: 61.20767216037384
Learned parameters: [2.1761317161024936, 3.7661447320855, 5.657173657954672, -2.5398083955298927]
Epoch: 4193  loss: 61.2050052769152
Learned parameters: [2.17605738931438, 3.766248776340986, 5.657323201543726, -2.5400116013462433]
Epoch: 4194  loss: 61.202343945076265
Learned parameters: [2.1759831207254883, 3.7663527384984365, 5.657472627820093, -2.5402146472094524]
Epoch: 4195  loss: 61.19968815537733
Learned parameters: [2.1759089103195297, 3.7664566185824433, 5.657621936816437, -2.5404175331653662]
Epoch: 4196  loss: 61.19703789835192
Learned parameters: [2.1758347580803576, 3.7665604166175157, 5.657771128565627, -2.54062025925989]
Epoch: 4197  loss: 61.19439316455179
Learned parameters: [2.175760663992123, 3.766664132628038, 5.657920203100966, -2.540822825539016]
Epoch: 4198  loss: 61.191753944538185
Learned parameters: [2.175686628038806, 3.7667677666383974, 5.658069160455534, -2.5410252320487507]
Epoch: 4199  loss: 61.18912022889117
Learned parameters: [2.175612650204117, 3.7668713186730245, 5.658218000662062, -2.54122747883511]
Epoch: 4200  loss: 61.18649200819428
Learned parameters: [2.175538730471903, 3.7669747887562766, 5.658366723753497, -2.541429565944175]
Epoch: 4201  loss: 61.183869273052466
Learned parameters: [2.1754648688262406, 3.767078176912416, 5.658515329763132, -2.5416314934221096]
Epoch: 4202  loss: 61.181252014077096
Learned parameters: [2.1753910652510324, 3.7671814831657082, 5.6586638187240315, -2.5418332613150865]
Epoch: 4203  loss: 61.178640221903365
Learned parameters: [2.1753173197299525, 3.767284707540447, 5.6588121906689635, -2.5420348696692847]
Epoch: 4204  loss: 61.17603388716229
Learned parameters: [2.175243632246866, 3.7673878500608526, 5.658960445630991, -2.542236318530952]
Epoch: 4205  loss: 61.17343300050961
Learned parameters: [2.1751700027857845, 3.7674909107511336, 5.659108583643445, -2.542437607946407]
Epoch: 4206  loss: 61.17083755260556
Learned parameters: [2.1750964313304895, 3.7675938896355325, 5.659256604739357, -2.5426387379619686]
Epoch: 4207  loss: 61.16824753413745
Learned parameters: [2.175022917864624, 3.767696786738266, 5.659404508951567, -2.542839708623971]
Epoch: 4208  loss: 61.16566293579576
Learned parameters: [2.174949462371982, 3.7677996020832274, 5.659552296312995, -2.543040519978803]
Epoch: 4209  loss: 61.16308374830424
Learned parameters: [2.174876064836645, 3.767902335694249, 5.65969996685701, -2.543241172072932]
Epoch: 4210  loss: 61.16050996237918
Learned parameters: [2.1748027252424253, 3.768004987595255, 5.659847520616647, -2.543441664952812]
Epoch: 4211  loss: 61.157941568746566
Learned parameters: [2.174729443572881, 3.7681075578102563, 5.659994957624625, -2.543641998664885]
Epoch: 4212  loss: 61.15537855815398
Learned parameters: [2.17465621981182, 3.7682100463632215, 5.660142277914059, -2.5438421732556575]
Epoch: 4213  loss: 61.152820921357666
Learned parameters: [2.17458305394321, 3.7683124532781016, 5.660289481518325, -2.544042188771684]
Epoch: 4214  loss: 61.15026864911975
Learned parameters: [2.1745099459507675, 3.768414778578939, 5.660436568470489, -2.544242045259503]
Epoch: 4215  loss: 61.14772173222549
Learned parameters: [2.174436895818092, 3.768517022289836, 5.660583538803493, -2.5444417427656556]
Epoch: 4216  loss: 61.14518016146297
Learned parameters: [2.1743639035289566, 3.7686191844348933, 5.660730392550576, -2.54464128133674]
Epoch: 4217  loss: 61.142643927638076
Learned parameters: [2.1742909690672403, 3.768721265038222, 5.660877129745174, -2.544840661019395]
Epoch: 4218  loss: 61.14011302156461
Learned parameters: [2.1742180924165884, 3.7688232641240185, 5.661023750420428, -2.5450398818602404]
Epoch: 4219  loss: 61.13758743407722
Learned parameters: [2.1741452735605833, 3.768925181716464, 5.661170254609388, -2.545238943905891]
Epoch: 4220  loss: 61.135067156022785
Learned parameters: [2.17407251248301, 3.7690270178396847, 5.661316642345403, -2.5454378472030053]
Epoch: 4221  loss: 61.13255217825739
Learned parameters: [2.1739998091676913, 3.769128772517832, 5.661462913661919, -2.5456365917982655]
Epoch: 4222  loss: 61.13004249164661
Learned parameters: [2.1739271635982336, 3.7692304457751056, 5.661609068592091, -2.545835177738338]
Epoch: 4223  loss: 61.127538087076914
Learned parameters: [2.1738545757582313, 3.769332037635737, 5.661755107169095, -2.546033605069905]
Epoch: 4224  loss: 61.12503895543715
Learned parameters: [2.1737820456314454, 3.7694335481239527, 5.661901029426385, -2.546231873839693]
Epoch: 4225  loss: 61.122545087633476
Learned parameters: [2.173709573201616, 3.769534977264022, 5.662046835397427, -2.546429984094448]
Epoch: 4226  loss: 61.12005647458329
Learned parameters: [2.173637158452311, 3.769636325080294, 5.662192525115487, -2.5466279358809047]
Epoch: 4227  loss: 61.117573107213204
Learned parameters: [2.1735648013671147, 3.7697375915971474, 5.662338098613895, -2.546825729245821]
Epoch: 4228  loss: 61.115094976465635
Learned parameters: [2.17349250192976, 3.7698387768389527, 5.662483555926228, -2.547023364235997]
Epoch: 4229  loss: 61.11262207329477
Learned parameters: [2.1734202601239003, 3.769939880830131, 5.66262889708599, -2.547220840898241]
Epoch: 4230  loss: 61.110154388665535
Learned parameters: [2.173348075933067, 3.770040903595164, 5.662774122126557, -2.547418159279363]
Epoch: 4231  loss: 61.107691913558874
Learned parameters: [2.1732759493408524, 3.770141845158532, 5.662919231081415, -2.5476153194261983]
Epoch: 4232  loss: 61.10523463896037
Learned parameters: [2.173203880330927, 3.770242705544717, 5.6630642239842, -2.5478123213856163]
Epoch: 4233  loss: 61.10278255587804
Learned parameters: [2.1731318688868924, 3.7703434847782433, 5.663209100868491, -2.5480091652045]
Epoch: 4234  loss: 61.10033565532374
Learned parameters: [2.1730599149922347, 3.77044418288365, 5.663353861767713, -2.5482058509297283]
Epoch: 4235  loss: 61.097893928331125
Learned parameters: [2.1729880186305506, 3.770544799885471, 5.6634985067154915, -2.5484023786082246]
Epoch: 4236  loss: 61.09545736593563
Learned parameters: [2.1729161797854837, 3.7706453358082515, 5.66364303574556, -2.548598748286949]
Epoch: 4237  loss: 61.09302595918893
Learned parameters: [2.172844398440524, 3.7707457906765973, 5.663787448891478, -2.5487949600128688]
Epoch: 4238  loss: 61.090599699159796
Learned parameters: [2.1727726745791625, 3.7708461645151337, 5.6639317461868455, -2.5489910138329788]
Epoch: 4239  loss: 61.08817857691611
Learned parameters: [2.172701008184958, 3.77094645734845, 5.664075927665381, -2.5491869097943143]
Epoch: 4240  loss: 61.085762583552466
Learned parameters: [2.1726293992414654, 3.77104666920114, 5.664219993360828, -2.5493826479439394]
Epoch: 4241  loss: 61.08335171016787
Learned parameters: [2.1725578477321643, 3.7711468000978363, 5.664363943306867, -2.5495782283289357]
Epoch: 4242  loss: 61.08094594787434
Learned parameters: [2.1724863536405126, 3.771246850063197, 5.664507777537189, -2.5497736509964097]
Epoch: 4243  loss: 61.07854528779745
Learned parameters: [2.1724149169500273, 3.771346819121881, 5.664651496085611, -2.549968915993508]
Epoch: 4244  loss: 61.07614972107558
Learned parameters: [2.1723435376442084, 3.771446707298568, 5.664795098985967, -2.5501640233674028]
Epoch: 4245  loss: 61.073759238851366
Learned parameters: [2.172272215706461, 3.771546514617977, 5.664938586271997, -2.550358973165283]
Epoch: 4246  loss: 61.0713738322891
Learned parameters: [2.1722009511202205, 3.7716462411048184, 5.665081957977513, -2.5505537654343615]
Epoch: 4247  loss: 61.06899349256074
Learned parameters: [2.1721297438689886, 3.7717458867837923, 5.665225214136454, -2.5507484002218894]
Epoch: 4248  loss: 61.06661821085462
Learned parameters: [2.172058593936176, 3.7718454516796367, 5.665368354782672, -2.550942877575136]
Epoch: 4249  loss: 61.064247978363795
Learned parameters: [2.1719875013051477, 3.771944935817105, 5.665511379949991, -2.551137197541394]
Epoch: 4250  loss: 61.06188278630104
Learned parameters: [2.171916465959337, 3.772044339220947, 5.665654289672372, -2.5513313601679988]
Epoch: 4251  loss: 61.05952262588376
Learned parameters: [2.1718454878821305, 3.772143661915917, 5.66579708398367, -2.5515253655022296]
Epoch: 4252  loss: 61.05716748835918
Learned parameters: [2.1717745670568283, 3.7722429039267356, 5.665939762917691, -2.5517192135914657]
Epoch: 4253  loss: 61.05481736496451
Learned parameters: [2.1717037034669664, 3.7723420652780812, 5.666082326508616, -2.5519129044831548]
Epoch: 4254  loss: 61.052472246940766
Learned parameters: [2.1716328970961407, 3.772441145995184, 5.666224774791069, -2.552106438224769]
Epoch: 4255  loss: 61.050132125537964
Learned parameters: [2.1715621479272467, 3.772540146103425, 5.666367107798708, -2.5522998148637113]
Epoch: 4256  loss: 61.04779699203113
Learned parameters: [2.1714914559433773, 3.7726390656280904, 5.666509325565481, -2.552493034447454]
Epoch: 4257  loss: 61.04546683771015
Learned parameters: [2.1714208211282227, 3.7727379045942673, 5.666651428126193, -2.552686097023604]
Epoch: 4258  loss: 61.04314165388327
Learned parameters: [2.171350243465179, 3.7728366630270815, 5.666793415515256, -2.552879002639766]
Epoch: 4259  loss: 61.04082143185587
Learned parameters: [2.1712797229371366, 3.772935340951755, 5.666935287766393, -2.553071751343511]
Epoch: 4260  loss: 61.03850616295742
Learned parameters: [2.171209259527283, 3.773033938393395, 5.66707704491377, -2.5532643431825]
Epoch: 4261  loss: 61.036195838529075
Learned parameters: [2.1711388532192237, 3.773132455376965, 5.667218686992164, -2.5534567782045032]
Epoch: 4262  loss: 61.03389044991645
Learned parameters: [2.171068503996187, 3.7732308919275117, 5.667360214035858, -2.5536490564572856]
Epoch: 4263  loss: 61.03158998848075
Learned parameters: [2.170998211841046, 3.773329248070148, 5.667501626078671, -2.5538411779886028]
Epoch: 4264  loss: 61.02929444559622
Learned parameters: [2.1709279767370675, 3.773427523829854, 5.667642923154996, -2.5540331428463108]
Epoch: 4265  loss: 61.02700381265116
Learned parameters: [2.1708577986677366, 3.7735257192315284, 5.667784105299561, -2.55422495107834]
Epoch: 4266  loss: 61.02471808104347
Learned parameters: [2.170787677616137, 3.7736238343001767, 5.6679251725465765, -2.5544166027326036]
Epoch: 4267  loss: 61.02243724217524
Learned parameters: [2.1707176135651784, 3.7737218690608674, 5.668066124930063, -2.5546080978570354]
Epoch: 4268  loss: 61.0201612874682
Learned parameters: [2.170647606498133, 3.7738198235385543, 5.668206962484577, -2.554799436499661]
Epoch: 4269  loss: 61.01789020836745
Learned parameters: [2.1705776563982386, 3.773917697757905, 5.668347685244495, -2.554990618708536]
Epoch: 4270  loss: 61.01562399632619
Learned parameters: [2.170507763248649, 3.7740154917436124, 5.668488293244107, -2.555181644531735]
Epoch: 4271  loss: 61.01336264280299
Learned parameters: [2.1704379270324305, 3.774113205520414, 5.668628786517632, -2.5553725140173484]
Epoch: 4272  loss: 61.011106139266516
Learned parameters: [2.1703681477327206, 3.7742108391130538, 5.668769165099433, -2.5555632272135065]
Epoch: 4273  loss: 61.008854477201126
Learned parameters: [2.170298425332697, 3.774308392546293, 5.668909429023972, -2.555753784168371]
Epoch: 4274  loss: 61.00660764809976
Learned parameters: [2.1702287598154535, 3.7744058658449426, 5.66904957832564, -2.5559441849301163]
Epoch: 4275  loss: 61.00436564346667
Learned parameters: [2.1701591511640097, 3.7745032590338634, 5.669189613038767, -2.556134429546928]
Epoch: 4276  loss: 61.002128454814645
Learned parameters: [2.170089599361485, 3.774600572137919, 5.669329533197865, -2.556324518067029]
Epoch: 4277  loss: 60.99989607367769
Learned parameters: [2.1700201043909977, 3.7746978051820053, 5.669469338837486, -2.556514450538662]
Epoch: 4278  loss: 60.99766849159124
Learned parameters: [2.1699506662355628, 3.7747949581910745, 5.66960902999208, -2.5567042270100755]
Epoch: 4279  loss: 60.995445700109286
Learned parameters: [2.1698812848782043, 3.774892031190119, 5.669748606696158, -2.556893847529544]
Epoch: 4280  loss: 60.993227690791315
Learned parameters: [2.1698119603020034, 3.774989024204167, 5.669888068984372, -2.5570833121453815]
Epoch: 4281  loss: 60.99101445520951
Learned parameters: [2.169742692489987, 3.7750859372582886, 5.670027416891333, -2.5572726209059136]
Epoch: 4282  loss: 60.98880598495313
Learned parameters: [2.1696734814251126, 3.7751827703775214, 5.670166650451541, -2.5574617738594574]
Epoch: 4283  loss: 60.98660227162495
Learned parameters: [2.169604327090424, 3.775279523586913, 5.6703057696996595, -2.5576507710543637]
Epoch: 4284  loss: 60.98440330683506
Learned parameters: [2.16953522946899, 3.775376196911533, 5.670444774670424, -2.557839612539008]
Epoch: 4285  loss: 60.98220908219881
Learned parameters: [2.169466188543757, 3.77547279037651, 5.670583665398441, -2.5580282983617675]
Epoch: 4286  loss: 60.98001958935596
Learned parameters: [2.169397204297667, 3.775569304007008, 5.67072244191835, -2.558216828571039]
Epoch: 4287  loss: 60.97783481994601
Learned parameters: [2.1693282767137303, 3.7756657378282017, 5.670861104264932, -2.558405203215254]
Epoch: 4288  loss: 60.9756547656279
Learned parameters: [2.169259405774958, 3.7757620918652957, 5.670999652473006, -2.5585934223428644]
Epoch: 4289  loss: 60.97347941806456
Learned parameters: [2.1691905914642513, 3.7758583661435514, 5.671138086577281, -2.5587814860023297]
Epoch: 4290  loss: 60.9713087689374
Learned parameters: [2.1691218337645113, 3.775954560688256, 5.671276406612506, -2.5589693942421334]
Epoch: 4291  loss: 60.96914280993529
Learned parameters: [2.16905313265873, 3.7760506755246968, 5.671414612613597, -2.5591571471107977]
Epoch: 4292  loss: 60.966981532762375
Learned parameters: [2.1689844881298486, 3.7761467106781983, 5.671552704615438, -2.5593447446568622]
Epoch: 4293  loss: 60.964824929125896
Learned parameters: [2.168915900160712, 3.7762426661741304, 5.671690682652823, -2.5595321869288794]
Epoch: 4294  loss: 60.96267299075318
Learned parameters: [2.1688473687342227, 3.7763385420378692, 5.671828546760663, -2.5597194739754365]
Epoch: 4295  loss: 60.96052570938421
Learned parameters: [2.1687788938333066, 3.7764343382947905, 5.671966296973933, -2.559906605845147]
Epoch: 4296  loss: 60.958383076760114
Learned parameters: [2.1687104754408337, 3.776530054970297, 5.672103933327565, -2.560093582586642]
Epoch: 4297  loss: 60.95624508464529
Learned parameters: [2.1686421135396445, 3.776625692089803, 5.672241455856482, -2.5602804042485743]
Epoch: 4298  loss: 60.954111724808484
Learned parameters: [2.1685738081126025, 3.7767212496787086, 5.672378864595661, -2.5604670708796244]
Epoch: 4299  loss: 60.95198298903518
Learned parameters: [2.1685055591425924, 3.77681672776243, 5.672516159580155, -2.5606535825285093]
Epoch: 4300  loss: 60.949858869114024
Learned parameters: [2.168437366612428, 3.776912126366441, 5.672653340844975, -2.560839939243969]
Epoch: 4301  loss: 60.94773935685233
Learned parameters: [2.1683692305049096, 3.777007445516234, 5.6727904084251515, -2.5610261410747737]
Epoch: 4302  loss: 60.94562444406105
Learned parameters: [2.16830115080283, 3.7771026852372653, 5.672927362355723, -2.5612121880697325]
Epoch: 4303  loss: 60.94351412257293
Learned parameters: [2.168233127489027, 3.777197845554998, 5.673064202671839, -2.5613980802777028]
Epoch: 4304  loss: 60.941408384226584
Learned parameters: [2.1681651605463035, 3.7772929264949213, 5.673200929408642, -2.561583817747568]
Epoch: 4305  loss: 60.93930722086847
Learned parameters: [2.1680972499573805, 3.7773879280825606, 5.673337542601204, -2.561769400528232]
Epoch: 4306  loss: 60.93721062436167
Learned parameters: [2.1680293957050214, 3.7774828503434454, 5.673474042284699, -2.561954828668637]
Epoch: 4307  loss: 60.93511858657814
Learned parameters: [2.167961597772006, 3.777577693303115, 5.673610428494366, -2.56214010221776]
Epoch: 4308  loss: 60.9330310993975
Learned parameters: [2.167893856141064, 3.7776724569871343, 5.673746701265417, -2.5623252212246035]
Epoch: 4309  loss: 60.9309481547201
Learned parameters: [2.1678261707948923, 3.7777671414210903, 5.673882860633059, -2.5625101857381978]
Epoch: 4310  loss: 60.928869744447915
Learned parameters: [2.1677585417162093, 3.777861746630576, 5.674018906632574, -2.562694995807609]
Epoch: 4311  loss: 60.9267958604954
Learned parameters: [2.1676909688877215, 3.777956272641186, 5.674154839299255, -2.5628796514819263]
Epoch: 4312  loss: 60.92472649479944
Learned parameters: [2.1676234522921254, 3.77805071947852, 5.674290658668415, -2.563064152810265]
Epoch: 4313  loss: 60.9226616392973
Learned parameters: [2.1675559919120713, 3.7781450871682005, 5.6744263647753455, -2.563248499841768]
Epoch: 4314  loss: 60.92060128593768
Learned parameters: [2.1674885877302374, 3.778239375735855, 5.674561957655418, -2.563432692625616]
Epoch: 4315  loss: 60.91854542668563
Learned parameters: [2.16742123972928, 3.7783335852071, 5.674697437343999, -2.5636167312110176]
Epoch: 4316  loss: 60.91649405351774
Learned parameters: [2.1673539478918133, 3.7784277156075063, 5.674832803876395, -2.5638006156472017]
Epoch: 4317  loss: 60.914447158420394
Learned parameters: [2.167286712200548, 3.778521766962738, 5.674968057288148, -2.5639843459834437]
Epoch: 4318  loss: 60.91240473336851
Learned parameters: [2.1672195326382204, 3.7786157392989517, 5.67510319761516, -2.5641679222690454]
Epoch: 4319  loss: 60.91036677035373
Learned parameters: [2.167152409187078, 3.77870963264239, 5.6752382248926585, -2.5643513445532737]
Epoch: 4320  loss: 60.908333261394226
Learned parameters: [2.1670853418296065, 3.778803447019192, 5.675373139156224, -2.564534612885474]
Epoch: 4321  loss: 60.906304198514384
Learned parameters: [2.1670183305486446, 3.7788971824553608, 5.675507940441951, -2.564717727315091]
Epoch: 4322  loss: 60.9042795737512
Learned parameters: [2.1669513753267213, 3.7789908389769433, 5.675642628785521, -2.5649006878915666]
Epoch: 4323  loss: 60.90225937915805
Learned parameters: [2.166884476146096, 3.7790844166100186, 5.675777204222263, -2.5650834946643477]
Epoch: 4324  loss: 60.90024360679182
Learned parameters: [2.1668176329893365, 3.779177915380551, 5.675911666787963, -2.565266147682975]
Epoch: 4325  loss: 60.89823224872518
Learned parameters: [2.1667508458391542, 3.779271335314435, 5.676046016518635, -2.565448646997059]
Epoch: 4326  loss: 60.89622529704094
Learned parameters: [2.1666841146779445, 3.77936467643762, 5.67618025344988, -2.5656309926562084]
Epoch: 4327  loss: 60.89422274383391
Learned parameters: [2.166617439487998, 3.7794579387760563, 5.676314377617184, -2.5658131847100623]
Epoch: 4328  loss: 60.89222458121271
Learned parameters: [2.1665508202518895, 3.779551122355605, 5.67644838905647, -2.565995223208353]
Epoch: 4329  loss: 60.89023080128439
Learned parameters: [2.166484256952199, 3.7796442272021102, 5.676582287803706, -2.5661771082008618]
Epoch: 4330  loss: 60.888241396182956
Learned parameters: [2.166417749571219, 3.7797372533414713, 5.6767160738944815, -2.5663588397373647]
Epoch: 4331  loss: 60.8862563580422
Learned parameters: [2.166351298091283, 3.7798302007995694, 5.676849747364487, -2.566540417867686]
Epoch: 4332  loss: 60.88427567901557
Learned parameters: [2.166284902494943, 3.7799230696022543, 5.676983308249777, -2.566721842641727]
Epoch: 4333  loss: 60.88229935125835
Learned parameters: [2.166218562764598, 3.780015859775357, 5.677116756586192, -2.566903114109402]
Epoch: 4334  loss: 60.880327366951796
Learned parameters: [2.1661522788824388, 3.7801085713445306, 5.677250092409186, -2.567084232320629]
Epoch: 4335  loss: 60.87835971828613
Learned parameters: [2.1660860508309976, 3.780201204335364, 5.677383315754741, -2.5672651973254097]
Epoch: 4336  loss: 60.87639639745747
Learned parameters: [2.1660198785927967, 3.780293758773479, 5.677516426658878, -2.567446009173781]
Epoch: 4337  loss: 60.874437396671134
Learned parameters: [2.1659537621500426, 3.7803862346846073, 5.677649425157221, -2.567626667915759]
Epoch: 4338  loss: 60.8724827081413
Learned parameters: [2.1658877014849773, 3.7804786320945003, 5.67778231128549, -2.56780717360139]
Epoch: 4339  loss: 60.8705323240989
Learned parameters: [2.165821696580113, 3.780570951028869, 5.677915085079831, -2.567987526280786]
Epoch: 4340  loss: 60.86858623677744
Learned parameters: [2.1657557474178337, 3.780663191513489, 5.678047746576253, -2.568167726004064]
Epoch: 4341  loss: 60.86664443842831
Learned parameters: [2.16568985398027, 3.780755353574235, 5.678180295810452, -2.568347772821322]
Epoch: 4342  loss: 60.86470692131195
Learned parameters: [2.165624016249737, 3.7808474372369636, 5.678312732818427, -2.5685276667827095]
Epoch: 4343  loss: 60.86277367770046
Learned parameters: [2.165558234208688, 3.7809394425275284, 5.6784450576364165, -2.5687074079384162]
Epoch: 4344  loss: 60.86084469987061
Learned parameters: [2.165492507839353, 3.7810313694718736, 5.6785772703003845, -2.5688869963386205]
Epoch: 4345  loss: 60.85891998011978
Learned parameters: [2.1654268371238823, 3.7811232180959964, 5.678709370846227, -2.569066432033509]
Epoch: 4346  loss: 60.85699951074788
Learned parameters: [2.165361222044616, 3.7812149884258917, 5.678841359310163, -2.569245715073327]
Epoch: 4347  loss: 60.855083284067696
Learned parameters: [2.1652956625838837, 3.7813066804875914, 5.678973235728444, -2.569424845508344]
Epoch: 4348  loss: 60.85317129240903
Learned parameters: [2.165230158723825, 3.7813982943071376, 5.679105000137046, -2.5696038233888077]
Epoch: 4349  loss: 60.85126352810581
Learned parameters: [2.1651647104466303, 3.781489829910574, 5.679236652572051, -2.569782648764995]
Epoch: 4350  loss: 60.84935998350919
Learned parameters: [2.165099317734654, 3.781581287323926, 5.679368193069808, -2.5699613216872303]
Epoch: 4351  loss: 60.84746065097512
Learned parameters: [2.1650339805701, 3.78167266657329, 5.679499621666502, -2.570139842205839]
Epoch: 4352  loss: 60.8455655228737
Learned parameters: [2.1649686989350854, 3.781763967684819, 5.679630938398239, -2.5703182103711577]
Epoch: 4353  loss: 60.843674591580175
Learned parameters: [2.1649034728118224, 3.7818551906846745, 5.679762143301304, -2.570496426233563]
Epoch: 4354  loss: 60.84178784948651
Learned parameters: [2.164838302182564, 3.7819463355990357, 5.679893236412086, -2.570674489843463]
Epoch: 4355  loss: 60.83990528899557
Learned parameters: [2.1647731870294464, 3.7820374024541414, 5.680024217766852, -2.5708524012512743]
Epoch: 4356  loss: 60.83802690251074
Learned parameters: [2.164708127334576, 3.782128391276265, 5.68015508740187, -2.571030160507437]
Epoch: 4357  loss: 60.836152682462185
Learned parameters: [2.164643123080134, 3.7822193020916846, 5.680285845353559, -2.57120776766243]
Epoch: 4358  loss: 60.83428262127687
Learned parameters: [2.1645781742482955, 3.782310134926704, 5.680416491658373, -2.57138522276676]
Epoch: 4359  loss: 60.83241671139891
Learned parameters: [2.164513280821136, 3.782400889807674, 5.6805470263526665, -2.571562525870949]
Epoch: 4360  loss: 60.83055494527954
Learned parameters: [2.1644484427807433, 3.7824915667609624, 5.680677449472857, -2.5717396770255516]
Epoch: 4361  loss: 60.828697315389235
Learned parameters: [2.164383660109267, 3.782582165812938, 5.680807761055492, -2.571916676281162]
Epoch: 4362  loss: 60.8268438141984
Learned parameters: [2.1643189327887935, 3.7826726869900047, 5.6809379611370705, -2.5720935236883977]
Epoch: 4363  loss: 60.82499443419084
Learned parameters: [2.164254260801351, 3.782763130318583, 5.681068049754045, -2.5722702192978932]
Epoch: 4364  loss: 60.82314916786601
Learned parameters: [2.164189644129014, 3.7828534958250937, 5.6811980269429725, -2.572446763160323]
Epoch: 4365  loss: 60.821308007733315
Learned parameters: [2.1641250827538707, 3.7829437835359405, 5.681327892740454, -2.5726231553263914]
Epoch: 4366  loss: 60.819470946304065
Learned parameters: [2.1640605766579486, 3.7830339934775803, 5.681457647183062, -2.5727993958468307]
Epoch: 4367  loss: 60.8176379761142
Learned parameters: [2.163996125823262, 3.7831241256765256, 5.681587290307421, -2.57297548477241]
Epoch: 4368  loss: 60.815809089691946
Learned parameters: [2.163931730231791, 3.7832141801592694, 5.681716822150128, -2.5731514221539307]
Epoch: 4369  loss: 60.81398427959675
Learned parameters: [2.163867389865549, 3.7833041569522754, 5.681846242747854, -2.5733272080422394]
Epoch: 4370  loss: 60.81216353838291
Learned parameters: [2.1638031047065645, 3.7833940560820185, 5.681975552137335, -2.57350284248822]
Epoch: 4371  loss: 60.81034685862275
Learned parameters: [2.1637388747367905, 3.783483877575006, 5.68210475035525, -2.573678325542782]
Epoch: 4372  loss: 60.808534232895475
Learned parameters: [2.1636746999381473, 3.783573621457768, 5.682233837438276, -2.573853657256868]
Epoch: 4373  loss: 60.80672565379273
Learned parameters: [2.1636105802926195, 3.7836632877568355, 5.682362813423231, -2.5740288376814715]
Epoch: 4374  loss: 60.80492111391622
Learned parameters: [2.1635465157821594, 3.7837528764987587, 5.682491678346933, -2.574203866867616]
Epoch: 4375  loss: 60.80312060587774
Learned parameters: [2.163482506388636, 3.7838423877101204, 5.682620432246125, -2.5743787448663507]
Epoch: 4376  loss: 60.801324122299405
Learned parameters: [2.1634185520939577, 3.783931821417504, 5.682749075157654, -2.5745534717287653]
Epoch: 4377  loss: 60.799531655812345
Learned parameters: [2.1633546528800536, 3.784021177647498, 5.682877607118434, -2.57472804750599]
Epoch: 4378  loss: 60.7977431990629
Learned parameters: [2.1632908087287954, 3.7841104564267156, 5.683006028165346, -2.5749024722491813]
Epoch: 4379  loss: 60.79595874470438
Learned parameters: [2.1632270196220107, 3.784199657781791, 5.683134338335253, -2.575076746009525]
Epoch: 4380  loss: 60.794178285398225
Learned parameters: [2.1631632855415703, 3.7842887817393387, 5.683262537665103, -2.5752508688382374]
Epoch: 4381  loss: 60.79240181382661
Learned parameters: [2.1630996064693395, 3.7843778283259786, 5.683390626191874, -2.575424840786566]
Epoch: 4382  loss: 60.790629322669346
Learned parameters: [2.1630359823871435, 3.78446679756835, 5.683518603952532, -2.5755986619057887]
Epoch: 4383  loss: 60.78886080462736
Learned parameters: [2.162972413276771, 3.7845556894930716, 5.683646470984009, -2.5757723322472086]
Epoch: 4384  loss: 60.78709625240865
Learned parameters: [2.162908899120036, 3.784644504126719, 5.683774227323284, -2.5759458518621643]
Epoch: 4385  loss: 60.78533565872333
Learned parameters: [2.1628454398989154, 3.7847332414962254, 5.683901873007831, -2.576119220802047]
Epoch: 4386  loss: 60.78357901628643
Learned parameters: [2.1627820355949914, 3.7848219016287117, 5.684029408074657, -2.576292439118226]
Epoch: 4387  loss: 60.78182631782285
Learned parameters: [2.1627186861898124, 3.7849104845512787, 5.684156832560748, -2.5764655068621063]
Epoch: 4388  loss: 60.78007755608514
Learned parameters: [2.1626553916653033, 3.7849989902909003, 5.684284146503641, -2.5766384240851963]
Epoch: 4389  loss: 60.77833272382754
Learned parameters: [2.1625921520032914, 3.7850874188745474, 5.684411349940766, -2.576811190839033]
Epoch: 4390  loss: 60.776591813817326
Learned parameters: [2.1625289671852754, 3.785175770329251, 5.684538442909119, -2.5769838071751487]
Epoch: 4391  loss: 60.77485481883177
Learned parameters: [2.1624658371928938, 3.7852640446819796, 5.684665425445923, -2.5771562731451403]
Epoch: 4392  loss: 60.77312173165919
Learned parameters: [2.16240276200802, 3.7853522419596195, 5.684792297588761, -2.5773285888006865]
Epoch: 4393  loss: 60.771392545094514
Learned parameters: [2.162339741612314, 3.785440362189092, 5.684919059374949, -2.577500754193479]
Epoch: 4394  loss: 60.76966725195201
Learned parameters: [2.1622767759872383, 3.785528405397353, 5.685045710841563, -2.5776727693752237]
Epoch: 4395  loss: 60.76794584504545
Learned parameters: [2.1622138651145035, 3.785616371611278, 5.685172252026058, -2.5778446343977084]
Epoch: 4396  loss: 60.766228317206725
Learned parameters: [2.16215100897588, 3.7857042608577154, 5.685298682966013, -2.5780163493127732]
Epoch: 4397  loss: 60.76451466127476
Learned parameters: [2.162088207552869, 3.785792073163574, 5.685425003698661, -2.5781879141722586]
Epoch: 4398  loss: 60.76280487010081
Learned parameters: [2.162025460826963, 3.785879808555763, 5.685551214261271, -2.57835932902805]
Epoch: 4399  loss: 60.76109893654201
Learned parameters: [2.161962768779895, 3.7859674670611367, 5.685677314691494, -2.5785305939321175]
Epoch: 4400  loss: 60.75939685346593
Learned parameters: [2.1619001313932684, 3.7860550487065914, 5.685803305026848, -2.578701708936451]
Epoch: 4401  loss: 60.75769861375272
Learned parameters: [2.161837548648503, 3.786142553519101, 5.68592918530465, -2.5788726740930534]
Epoch: 4402  loss: 60.75600421029589
Learned parameters: [2.1617750205270907, 3.7862299815254885, 5.686054955562277, -2.579043489453974]
Epoch: 4403  loss: 60.75431363600295
Learned parameters: [2.1617125470107514, 3.7863173327524757, 5.686180615837439, -2.579214155071329]
Epoch: 4404  loss: 60.75262688378453
Learned parameters: [2.161650128081031, 3.7864046072268516, 5.686306166167649, -2.5793846709972392]
Epoch: 4405  loss: 60.75094394656204
Learned parameters: [2.161587763719279, 3.786491804975479, 5.68643160659019, -2.5795550372838285]
Epoch: 4406  loss: 60.74926481727262
Learned parameters: [2.1615254539070516, 3.7865789260251916, 5.686556937142685, -2.579725253983281]
Epoch: 4407  loss: 60.74758948885299
Learned parameters: [2.1614631986259654, 3.786665970402833, 5.686682157862882, -2.5798953211478173]
Epoch: 4408  loss: 60.74591795425603
Learned parameters: [2.16140099785742, 3.786752938135329, 5.686807268788273, -2.5800652388296528]
Epoch: 4409  loss: 60.74425020644459
Learned parameters: [2.1613388515828027, 3.7868398292496366, 5.6869322699563805, -2.5802350070810287]
Epoch: 4410  loss: 60.74258623839239
Learned parameters: [2.1612767597836693, 3.786926643772699, 5.687057161405005, -2.5804046259542397]
Epoch: 4411  loss: 60.74092604308103
Learned parameters: [2.16121472244149, 3.787013381731508, 5.687181943171877, -2.580574095501593]
Epoch: 4412  loss: 60.73926961350057
Learned parameters: [2.161152739537627, 3.787100043153111, 5.687306615294617, -2.580743415775404]
Epoch: 4413  loss: 60.73761694265645
Learned parameters: [2.161090811053477, 3.7871866280645725, 5.687431177810933, -2.580912586828019]
Epoch: 4414  loss: 60.735968023560446
Learned parameters: [2.1610289369705282, 3.7872731364929604, 5.687555630758713, -2.5810816087118247]
Epoch: 4415  loss: 60.73432284923617
Learned parameters: [2.1609671172701863, 3.78735956846539, 5.687679974175766, -2.581250481479219]
Epoch: 4416  loss: 60.732681412713085
Learned parameters: [2.160905351933756, 3.787445924009031, 5.6878042080998075, -2.581419205182613]
Epoch: 4417  loss: 60.731043707037074
Learned parameters: [2.1608436409426406, 3.7875322031510694, 5.687928332568749, -2.581587779874467]
Epoch: 4418  loss: 60.729409725260446
Learned parameters: [2.1607819842782345, 3.7876184059186544, 5.688052347620486, -2.581756205607254]
Epoch: 4419  loss: 60.72777946044923
Learned parameters: [2.1607203819218923, 3.7877045323389655, 5.688176253292901, -2.581924482433464]
Epoch: 4420  loss: 60.726152905670716
Learned parameters: [2.160658833854933, 3.787790582439263, 5.688300049623896, -2.582092610405617]
Epoch: 4421  loss: 60.72453005401512
Learned parameters: [2.160597340058697, 3.7878765562468217, 5.68842373665145, -2.5822605895762636]
Epoch: 4422  loss: 60.72291089856945
Learned parameters: [2.160535900514505, 3.787962453788945, 5.688547314413555, -2.582428419997982]
Epoch: 4423  loss: 60.7212954324371
Learned parameters: [2.1604745152036555, 3.788048275092961, 5.688670782948217, -2.582596101723376]
Epoch: 4424  loss: 60.719683648730864
Learned parameters: [2.1604131841074383, 3.7881340201862197, 5.688794142293468, -2.582763634805081]
Epoch: 4425  loss: 60.718075540575164
Learned parameters: [2.1603519072071458, 3.788219689096088, 5.688917392487394, -2.582931019295763]
Epoch: 4426  loss: 60.71647110109872
Learned parameters: [2.1602906844840315, 3.7883052818499596, 5.689040533568064, -2.583098255248116]
Epoch: 4427  loss: 60.714870323448125
Learned parameters: [2.160229515919366, 3.7883907984752407, 5.689163565573616, -2.5832653427148684]
Epoch: 4428  loss: 60.71327320077484
Learned parameters: [2.16016840149438, 3.7884762389993627, 5.689286488542176, -2.5834322817487765]
Epoch: 4429  loss: 60.71167972623782
Learned parameters: [2.160107341190306, 3.7885616034497716, 5.689409302511913, -2.5835990724026314]
Epoch: 4430  loss: 60.710089893014604
Learned parameters: [2.1600463349883676, 3.788646891853928, 5.689532007521031, -2.583765714729258]
Epoch: 4431  loss: 60.708503694282435
Learned parameters: [2.159985382869773, 3.788732104239311, 5.689654603607752, -2.5839322087815138]
Epoch: 4432  loss: 60.70692112323672
Learned parameters: [2.159924484815696, 3.78881724063342, 5.689777090810297, -2.5840985546122863]
Epoch: 4433  loss: 60.70534217307734
Learned parameters: [2.159863640807323, 3.7889023010637635, 5.689899469166946, -2.5842647522745015]
Epoch: 4434  loss: 60.703766837015856
Learned parameters: [2.1598028508258347, 3.788987285557861, 5.6900217387160135, -2.5844308018211204]
Epoch: 4435  loss: 60.70219510827286
Learned parameters: [2.159742114852363, 3.789072194143249, 5.6901438994957845, -2.5845967033051287]
Epoch: 4436  loss: 60.70062698008688
Learned parameters: [2.1596814328680463, 3.7891570268474517, 5.690265951544582, -2.5847624567795453]
Epoch: 4437  loss: 60.69906244569247
Learned parameters: [2.1596208048540433, 3.789241783698021, 5.690387894900814, -2.58492806229743]
Epoch: 4438  loss: 60.697501498341765
Learned parameters: [2.1595602307914517, 3.789326464722535, 5.690509729602849, -2.5850935199118728]
Epoch: 4439  loss: 60.69594413129977
Learned parameters: [2.159499710661336, 3.789411069948537, 5.6906314556890205, -2.585258829675999]
Epoch: 4440  loss: 60.69439033783749
Learned parameters: [2.15943924444483, 3.7894955994035673, 5.69075307319781, -2.5854239916429824]
Epoch: 4441  loss: 60.692840111231945
Learned parameters: [2.1593788321230294, 3.789580053115193, 5.690874582167692, -2.5855890058660274]
Epoch: 4442  loss: 60.69129344477804
Learned parameters: [2.159318473676959, 3.7896644311110164, 5.690995982637087, -2.585753872398364]
Epoch: 4443  loss: 60.6897503317707
Learned parameters: [2.1592581690876678, 3.7897487334186493, 5.691117274644499, -2.5859185912932636]
Epoch: 4444  loss: 60.68821076552623
Learned parameters: [2.1591979183362167, 3.789832960065717, 5.691238458228493, -2.586083162604035]
Epoch: 4445  loss: 60.68667473936153
Learned parameters: [2.1591377214036185, 3.7899171110798715, 5.691359533427613, -2.5862475863840158]
Epoch: 4446  loss: 60.685142246600314
Learned parameters: [2.1590775782708764, 3.7900011864887846, 5.691480500280437, -2.5864118626865786]
Epoch: 4447  loss: 60.68361328058999
Learned parameters: [2.1590174889189857, 3.7900851863201495, 5.691601358825583, -2.5865759915651356]
Epoch: 4448  loss: 60.68208783467273
Learned parameters: [2.1589574533289313, 3.790169110601679, 5.691722109101702, -2.5867399730731355]
Epoch: 4449  loss: 60.68056590220639
Learned parameters: [2.1588974714816818, 3.790252959361105, 5.69184275114747, -2.5869038072640604]
Epoch: 4450  loss: 60.67904747656547
Learned parameters: [2.158837543358183, 3.7903367326261788, 5.691963285001571, -2.5870674941914236]
Epoch: 4451  loss: 60.67753255111813
Learned parameters: [2.1587776689393663, 3.790420430424669, 5.692083710702719, -2.587231033908771]
Epoch: 4452  loss: 60.676021119258245
Learned parameters: [2.158717848206179, 3.790504052784354, 5.692204028289692, -2.587394426469687]
Epoch: 4453  loss: 60.67451317437927
Learned parameters: [2.1586580811395346, 3.7905875997330205, 5.692324237801253, -2.587557671927777]
Epoch: 4454  loss: 60.67300870988969
Learned parameters: [2.1585983677203098, 3.7906710712984615, 5.692444339276144, -2.5877207703366674]
Epoch: 4455  loss: 60.67150771920874
Learned parameters: [2.1585387079294063, 3.790754467508422, 5.692564332753154, -2.5878837217500177]
Epoch: 4456  loss: 60.670010195770196
Learned parameters: [2.1584791017477736, 3.7908377883907005, 5.6926842182712045, -2.5880465262215204]
Epoch: 4457  loss: 60.66851613299127
Learned parameters: [2.1584195491563385, 3.7909210339734343, 5.692803995869415, -2.5882091838048957]
Epoch: 4458  loss: 60.66702552431168
Learned parameters: [2.158360050135697, 3.791004204284828, 5.692923665586471, -2.588371694553855]
Epoch: 4459  loss: 60.66553836318542
Learned parameters: [2.158300604666696, 3.791087299353005, 5.693043227461439, -2.58853405852219]
Epoch: 4460  loss: 60.66405464307896
Learned parameters: [2.1582412127303297, 3.7911703192060324, 5.693162681533629, -2.5886962757637595]
Epoch: 4461  loss: 60.66257435745961
Learned parameters: [2.1581818743073025, 3.791253263872036, 5.693282027841972, -2.5888583463324224]
Epoch: 4462  loss: 60.66109749981275
Learned parameters: [2.158122589378254, 3.791336133379144, 5.693401266425349, -2.5890202702820737]
Epoch: 4463  loss: 60.65962406363255
Learned parameters: [2.1580633579240875, 3.791418927755402, 5.693520397323043, -2.589182047666693]
Epoch: 4464  loss: 60.65815404241718
Learned parameters: [2.1580041799256366, 3.7915016470288614, 5.693639420574277, -2.5893436785402946]
Epoch: 4465  loss: 60.65668742967922
Learned parameters: [2.1579450553634785, 3.7915842912276294, 5.693758336217949, -2.589505162956899]
Epoch: 4466  loss: 60.655224218942664
Learned parameters: [2.1578859842183404, 3.7916668603797654, 5.693877144293213, -2.5896665009705937]
Epoch: 4467  loss: 60.653764403730705
Learned parameters: [2.1578269664710854, 3.791749354513286, 5.693995844839445, -2.589827692635531]
Epoch: 4468  loss: 60.65230797758966
Learned parameters: [2.1577680021023395, 3.791831773656265, 5.694114437895732, -2.5899887380058693]
Epoch: 4469  loss: 60.65085493406619
Learned parameters: [2.1577090910926997, 3.7919141178367792, 5.69423292350116, -2.5901496371358057]
Epoch: 4470  loss: 60.649405266720734
Learned parameters: [2.157650233422939, 3.7919963870828592, 5.694351301695104, -2.5903103900796047]
Epoch: 4471  loss: 60.64795896912233
Learned parameters: [2.157591429073747, 3.7920785814225564, 5.694469572516856, -2.5904709968915567]
Epoch: 4472  loss: 60.646516034846094
Learned parameters: [2.1575326780256803, 3.792160700883958, 5.694587736005569, -2.59063145762597]
Epoch: 4473  loss: 60.645076457484095
Learned parameters: [2.1574739802593714, 3.792242745495144, 5.694705792200548, -2.5907917723372105]
Epoch: 4474  loss: 60.64364023062703
Learned parameters: [2.157415335755543, 3.7923247152842277, 5.6948237411413025, -2.590951941079705]
Epoch: 4475  loss: 60.642207347886036
Learned parameters: [2.1573567444946824, 3.7924066102792513, 5.694941582866975, -2.59111196390788]
Epoch: 4476  loss: 60.64077780287554
Learned parameters: [2.1572982064573805, 3.792488430508237, 5.69505931741689, -2.591271840876212]
Epoch: 4477  loss: 60.63935158922703
Learned parameters: [2.1572397216243493, 3.7925701759991974, 5.6951769448305924, -2.5914315720392307]
Epoch: 4478  loss: 60.63792870057314
Learned parameters: [2.157181289976116, 3.792651846780215, 5.695294465147414, -2.591591157451469]
Epoch: 4479  loss: 60.63650913055804
Learned parameters: [2.157122911493151, 3.7927334428794097, 5.695411878406658, -2.5917505971674824]
Epoch: 4480  loss: 60.6350928728358
Learned parameters: [2.1570645861560616, 3.7928149643248905, 5.69552918464786, -2.591909891241877]
Epoch: 4481  loss: 60.63367992106998
Learned parameters: [2.1570063139454523, 3.792896411144791, 5.695646383910604, -2.5920690397292887]
Epoch: 4482  loss: 60.632270268930974
Learned parameters: [2.15694809484175, 3.792977783367315, 5.695763476234267, -2.592228042684355]
Epoch: 4483  loss: 60.630863910099336
Learned parameters: [2.1568899288254544, 3.7930590810206737, 5.695880461658376, -2.5923869001617543]
Epoch: 4484  loss: 60.62946083826929
Learned parameters: [2.1568318158771254, 3.7931403041330864, 5.69599734022259, -2.5925456122162025]
Epoch: 4485  loss: 60.62806104714224
Learned parameters: [2.1567737559772526, 3.7932214527328165, 5.696114111966511, -2.5927041789024337]
Epoch: 4486  loss: 60.62666453042631
Learned parameters: [2.1567157491062314, 3.7933025268481755, 5.696230776929659, -2.5928626002751978]
Epoch: 4487  loss: 60.625271281838415
Learned parameters: [2.156657795244555, 3.793383526507474, 5.696347335151734, -2.593020876389289]
Epoch: 4488  loss: 60.62388129510955
Learned parameters: [2.1565998943727176, 3.793464451739049, 5.696463786672486, -2.5931790072995335]
Epoch: 4489  loss: 60.62249456397498
Learned parameters: [2.156542046471107, 3.7935453025712884, 5.6965801315315625, -2.5933369930607744]
Epoch: 4490  loss: 60.62111108218212
Learned parameters: [2.1564842515201166, 3.7936260790326015, 5.696696369768666, -2.593494833727885]
Epoch: 4491  loss: 60.619730843487254
Learned parameters: [2.156426509500209, 3.7937067811514025, 5.696812501423638, -2.593652529355782]
Epoch: 4492  loss: 60.6183538416536
Learned parameters: [2.1563688203917724, 3.7937874089561605, 5.696928526536278, -2.5938100799994093]
Epoch: 4493  loss: 60.61698007046074
Learned parameters: [2.156311184175129, 3.7938679624753093, 5.697044445146284, -2.593967485713716]
Epoch: 4494  loss: 60.61560952368898
Learned parameters: [2.1562536008307194, 3.7939484417373115, 5.697160257293589, -2.5941247465537027]
Epoch: 4495  loss: 60.61424219513215
Learned parameters: [2.1561960703389107, 3.7940288467706695, 5.69727596301807, -2.594281862574392]
Epoch: 4496  loss: 60.61287807859469
Learned parameters: [2.156138592679998, 3.794109177603926, 5.697391562359549, -2.5944388338308304]
Epoch: 4497  loss: 60.611517167884514
Learned parameters: [2.156081167834321, 3.794189434265635, 5.697507055357962, -2.594595660378108]
Epoch: 4498  loss: 60.610159456825194
Learned parameters: [2.156023795782247, 3.7942696167843617, 5.6976224420533255, -2.594752342271354]
Epoch: 4499  loss: 60.60880493924532
Learned parameters: [2.155966476504058, 3.79434972518871, 5.697737722485586, -2.594908879565718]
Epoch: 4500  loss: 60.607453608981984
Learned parameters: [2.15590920998001, 3.7944297595073064, 5.697852896694696, -2.5950652723163805]
Epoch: 4501  loss: 60.606105459887615
Learned parameters: [2.155851996190414, 3.794509719768779, 5.69796796472073, -2.5952215205785665]
Epoch: 4502  loss: 60.60476048581385
Learned parameters: [2.155794835115572, 3.794589606001773, 5.698082926603795, -2.595377624407535]
Epoch: 4503  loss: 60.60341868063095
Learned parameters: [2.155737726735687, 3.794669418234973, 5.698197782383906, -2.595533583858567]
Epoch: 4504  loss: 60.602080038214325
Learned parameters: [2.1556806710309924, 3.7947491564970703, 5.698312532101163, -2.5956893989869836]
Epoch: 4505  loss: 60.600744552446685
Learned parameters: [2.1556236679817564, 3.7948288208167593, 5.6984271757957625, -2.5958450698481492]
Epoch: 4506  loss: 60.599412217225684
Learned parameters: [2.155566717568182, 3.794908411222764, 5.698541713507855, -2.596000596497455]
Epoch: 4507  loss: 60.598083026450595
Learned parameters: [2.1555098197704443, 3.794987927743828, 5.698656145277595, -2.596155978990326]
Epoch: 4508  loss: 60.596756974033646
Learned parameters: [2.155452974568742, 3.795067370408701, 5.698770471145217, -2.5963112173822287]
Epoch: 4509  loss: 60.595434053898735
Learned parameters: [2.155396181943259, 3.795146739246148, 5.6988846911509805, -2.596466311728665]
Epoch: 4510  loss: 60.59411425997356
Learned parameters: [2.155339441874143, 3.795226034284955, 5.698998805335139, -2.59662126208517]
Epoch: 4511  loss: 60.59279758619567
Learned parameters: [2.1552827543415374, 3.7953052555539175, 5.699112813737982, -2.5967760685073147]
Epoch: 4512  loss: 60.591484026518174
Learned parameters: [2.1552261193255755, 3.7953844030818304, 5.699226716399824, -2.5969307310507026]
Epoch: 4513  loss: 60.59017357489658
Learned parameters: [2.15516953680639, 3.795463476897529, 5.69934051336104, -2.5970852497709807]
Epoch: 4514  loss: 60.58886622529856
Learned parameters: [2.155113006764035, 3.795542477029821, 5.699454204661909, -2.597239624723825]
Epoch: 4515  loss: 60.587561971697035
Learned parameters: [2.1550565291786525, 3.79562140350751, 5.699567790342881, -2.597393855964963]
Epoch: 4516  loss: 60.58626080807958
Learned parameters: [2.1550001040303286, 3.795700256359428, 5.699681270444376, -2.597547943550152]
Epoch: 4517  loss: 60.5849627284409
Learned parameters: [2.154943731299097, 3.7957790356144363, 5.699794645006789, -2.5977018875351776]
Epoch: 4518  loss: 60.58366772678112
Learned parameters: [2.1548874109650034, 3.7958577413014103, 5.699907914070578, -2.597855687975866]
Epoch: 4519  loss: 60.582375797115354
Learned parameters: [2.1548311430081197, 3.795936373449234, 5.700021077676286, -2.5980093449280837]
Epoch: 4520  loss: 60.58108693345634
Learned parameters: [2.154774927408462, 3.796014932086821, 5.700134135864426, -2.598162858447725]
Epoch: 4521  loss: 60.57980112984475
Learned parameters: [2.1547187641460037, 3.796093417243113, 5.700247088675494, -2.598316228590716]
Epoch: 4522  loss: 60.57851838030906
Learned parameters: [2.1546626532007687, 3.7961718289470525, 5.700359936150107, -2.598469455413027]
Epoch: 4523  loss: 60.57723867890185
Learned parameters: [2.1546065945527593, 3.7962501672276043, 5.7004726783289, -2.5986225389706608]
Epoch: 4524  loss: 60.57596201967908
Learned parameters: [2.154550588181901, 3.796328432113768, 5.700585315252443, -2.598775479319646]
Epoch: 4525  loss: 60.57468839670447
Learned parameters: [2.1544946340681594, 3.7964066236345477, 5.700697846961411, -2.598928276516054]
Epoch: 4526  loss: 60.57341780405109
Learned parameters: [2.1544387321915046, 3.796484741818963, 5.700810273496532, -2.599080930615993]
Epoch: 4527  loss: 60.57215023580431
Learned parameters: [2.154382882531847, 3.7965627866960676, 5.7009225948985005, -2.599233441675605]
Epoch: 4528  loss: 60.57088568605438
Learned parameters: [2.154327085069068, 3.796640758294939, 5.701034811208019, -2.599385809751064]
Epoch: 4529  loss: 60.56962414890445
Learned parameters: [2.154271339783099, 3.7967186566446554, 5.701146922465906, -2.599538034898589]
Epoch: 4530  loss: 60.56836561846053
Learned parameters: [2.154215646653833, 3.79679648177432, 5.701258928712972, -2.5996901171744287]
Epoch: 4531  loss: 60.56711008884208
Learned parameters: [2.154160005661111, 3.796874233713056, 5.701370829989994, -2.5998420566348566]
Epoch: 4532  loss: 60.56585755417989
Learned parameters: [2.1541044167847927, 3.796951912489937, 5.701482626337777, -2.5999938533361697]
Epoch: 4533  loss: 60.564608008607266
Learned parameters: [2.1540488800048796, 3.797029518134325, 5.701594317797546, -2.6001455073347084]
Epoch: 4534  loss: 60.563361446257616
Learned parameters: [2.1539933953010015, 3.7971070506757107, 5.701705904410064, -2.6002970186867986]
Epoch: 4535  loss: 60.56211786128769
Learned parameters: [2.1539379626528787, 3.797184510143544, 5.701817386216251, -2.600448387448823]
Epoch: 4536  loss: 60.56087724785612
Learned parameters: [2.15388258204048, 3.797261896567192, 5.701928763257412, -2.600599613677246]
Epoch: 4537  loss: 60.55963960013304
Learned parameters: [2.1538272534435867, 3.7973392099760535, 5.702040035574618, -2.6007506974285493]
Epoch: 4538  loss: 60.55840491230113
Learned parameters: [2.153771976841783, 3.7974164503995627, 5.702151203208704, -2.600901638759232]
Epoch: 4539  loss: 60.55717317854547
Learned parameters: [2.1537167522149, 3.7974936178670755, 5.702262266200885, -2.601052437725876]
Epoch: 4540  loss: 60.55594439306987
Learned parameters: [2.153661579542784, 3.7975707124079308, 5.702373224592434, -2.6012030943851117]
Epoch: 4541  loss: 60.55471855007238
Learned parameters: [2.153606458805046, 3.797647734051517, 5.702484078424336, -2.6013536087935796]
Epoch: 4542  loss: 60.55349564377309
Learned parameters: [2.1535513899813257, 3.797724682827206, 5.70259482773765, -2.6015039810079705]
Epoch: 4543  loss: 60.55227566839762
Learned parameters: [2.1534963730514547, 3.797801558764313, 5.70270547257375, -2.601654211085049]
Epoch: 4544  loss: 60.55105861817459
Learned parameters: [2.1534414079951096, 3.7978783618921863, 5.702816012973827, -2.6018042990815995]
Epoch: 4545  loss: 60.5498444873468
Learned parameters: [2.1533864947918255, 3.7979550922402083, 5.702926448978918, -2.6019542450544284]
Epoch: 4546  loss: 60.54863327016709
Learned parameters: [2.153331633421326, 3.7980317498377123, 5.703036780630364, -2.6021040490604137]
Epoch: 4547  loss: 60.54742496089006
Learned parameters: [2.1532768238633295, 3.798108334714033, 5.703147007969542, -2.6022537111564734]
Epoch: 4548  loss: 60.54621955378836
Learned parameters: [2.1532220660973596, 3.7981848468985584, 5.7032571310375975, -2.6024032313995376]
Epoch: 4549  loss: 60.545017043135196
Learned parameters: [2.1531673601030104, 3.7982612864206637, 5.703367149875819, -2.602552609846586]
Epoch: 4550  loss: 60.54381742321573
Learned parameters: [2.1531127058599653, 3.7983376533097077, 5.703477064525663, -2.6027018465546505]
Epoch: 4551  loss: 60.54262068832605
Learned parameters: [2.153058103347789, 3.798413947595088, 5.703586875028463, -2.6028509415807837]
Epoch: 4552  loss: 60.54142683276644
Learned parameters: [2.153003552545994, 3.798490169306251, 5.703696581425538, -2.602999894982072]
Epoch: 4553  loss: 60.540235850851495
Learned parameters: [2.152949053434133, 3.798566318472558, 5.703806183758265, -2.6031487068156522]
Epoch: 4554  loss: 60.53904773689915
Learned parameters: [2.152894605991854, 3.7986423951233754, 5.7039156820682075, -2.6032973771387136]
Epoch: 4555  loss: 60.53786248523902
Learned parameters: [2.1528402101986304, 3.7987183992881333, 5.704025076396732, -2.603445906008452]
Epoch: 4556  loss: 60.53668009020802
Learned parameters: [2.152785866033937, 3.7987943309962837, 5.704134366785252, -2.603594293482095]
Epoch: 4557  loss: 60.535500546154005
Learned parameters: [2.1527315734773342, 3.798870190277278, 5.7042435532753455, -2.603742539616912]
Epoch: 4558  loss: 60.53432384743154
Learned parameters: [2.152677332508352, 3.798945977160595, 5.704352635908595, -2.6038906444701966]
Epoch: 4559  loss: 60.533149988401654
Learned parameters: [2.152623143106392, 3.7990216916757706, 5.704461614726445, -2.6040386080992515]
Epoch: 4560  loss: 60.53197896344044
Learned parameters: [2.152569005250947, 3.7990973338523406, 5.704570489770518, -2.604186430561424]
Epoch: 4561  loss: 60.53081076692309
Learned parameters: [2.152514918921524, 3.7991729037198616, 5.704679261082498, -2.604334111914094]
Epoch: 4562  loss: 60.52964539324265
Learned parameters: [2.1524608840975215, 3.7992484013079415, 5.704787928703969, -2.604481652214655]
Epoch: 4563  loss: 60.528482836795504
Learned parameters: [2.152406900758359, 3.7993238266462064, 5.704896492676586, -2.604629051520534]
Epoch: 4564  loss: 60.527323091987654
Learned parameters: [2.152352968883489, 3.799399179764298, 5.705004953042098, -2.6047763098891945]
Epoch: 4565  loss: 60.52616615323518
Learned parameters: [2.152299088452327, 3.7994744606918904, 5.705113309842249, -2.604923427378124]
Epoch: 4566  loss: 60.52501201495717
Learned parameters: [2.1522452594442187, 3.7995496694586985, 5.7052215631187275, -2.6050704040448314]
Epoch: 4567  loss: 60.52386067159313
Learned parameters: [2.1521914818385715, 3.799624806094443, 5.705329712913359, -2.6052172399468674]
Epoch: 4568  loss: 60.522712117574635
Learned parameters: [2.152137755614773, 3.799699870628871, 5.705437759267985, -2.6053639351418103]
Epoch: 4569  loss: 60.521566347355645
Learned parameters: [2.1520840807521537, 3.7997748630917667, 5.705545702224411, -2.605510489687264]
Epoch: 4570  loss: 60.5204233553914
Learned parameters: [2.1520304572300373, 3.799849783512934, 5.70565354182448, -2.6056569036408637]
Epoch: 4571  loss: 60.51928313615094
Learned parameters: [2.151976885027803, 3.799924631922184, 5.7057612781101605, -2.605803177060287]
Epoch: 4572  loss: 60.51814568410459
Learned parameters: [2.151923364124743, 3.799999408349371, 5.705868911123343, -2.605949310003234]
Epoch: 4573  loss: 60.517010993737784
Learned parameters: [2.1518698945001224, 3.800074112824346, 5.705976440905911, -2.606095302527432]
Epoch: 4574  loss: 60.515879059542996
Learned parameters: [2.1518164761332974, 3.8001487453769607, 5.706083867499922, -2.6062411546906556]
Epoch: 4575  loss: 60.51474987601757
Learned parameters: [2.151763109003531, 3.8002233060371093, 5.706191190947352, -2.6063868665507033]
Epoch: 4576  loss: 60.513623437673836
Learned parameters: [2.1517097930900504, 3.8002977948347145, 5.706298411290173, -2.606532438165403]
Epoch: 4577  loss: 60.512499739024534
Learned parameters: [2.151656528372137, 3.8003722117997043, 5.706405528570481, -2.6066778695926294]
Epoch: 4578  loss: 60.51137877459675
Learned parameters: [2.151603314829047, 3.8004465569620294, 5.7065125428303825, -2.6068231608902885]
Epoch: 4579  loss: 60.51026053892035
Learned parameters: [2.1515501524399667, 3.8005208303516786, 5.706619454111939, -2.6069683121163165]
Epoch: 4580  loss: 60.50914502654378
Learned parameters: [2.1514970411841112, 3.8005950319986517, 5.706726262457299, -2.6071133233286927]
Epoch: 4581  loss: 60.508032232011075
Learned parameters: [2.151443981040702, 3.800669161932962, 5.7068329679086665, -2.6072581945854343]
Epoch: 4582  loss: 60.50692214988539
Learned parameters: [2.1513909719889015, 3.8007432201846503, 5.706939570508208, -2.6074029259445863]
Epoch: 4583  loss: 60.505814774730155
Learned parameters: [2.151338014007861, 3.8008172067837758, 5.707046070298122, -2.60754751746423]
Epoch: 4584  loss: 60.50471010112129
Learned parameters: [2.151285107076766, 3.8008911217604022, 5.707152467320701, -2.6076919692024907]
Epoch: 4585  loss: 60.50360812364437
Learned parameters: [2.1512322511747586, 3.8009649651446176, 5.707258761618225, -2.607836281217526]
Epoch: 4586  loss: 60.502508836889916
Learned parameters: [2.1511794462809264, 3.801038736966536, 5.7073649532329425, -2.607980453567523]
Epoch: 4587  loss: 60.50141223546058
Learned parameters: [2.1511266923744023, 3.801112437256273, 5.707471042207213, -2.608124486310714]
Epoch: 4588  loss: 60.50031831396359
Learned parameters: [2.151073989434312, 3.8011860660439565, 5.707577028583431, -2.6082683795053683]
Epoch: 4589  loss: 60.49922706701549
Learned parameters: [2.151021337439698, 3.8012596233597495, 5.707682912403923, -2.6084121332097823]
Epoch: 4590  loss: 60.49813848924268
Learned parameters: [2.1509687363696437, 3.801333109233815, 5.707788693711117, -2.608555747482296]
Epoch: 4591  loss: 60.49705257528169
Learned parameters: [2.15091618620322, 3.801406523696331, 5.707894372547471, -2.608699222381287]
Epoch: 4592  loss: 60.49596931977051
Learned parameters: [2.150863686919449, 3.801479866777499, 5.70799994895542, -2.6088425579651644]
Epoch: 4593  loss: 60.4948887173604
Learned parameters: [2.15081123849737, 3.80155313850753, 5.7081054229774715, -2.6089857542923784]
Epoch: 4594  loss: 60.493810762711696
Learned parameters: [2.1507588409159877, 3.801626338916633, 5.708210794656121, -2.6091288114214164]
Epoch: 4595  loss: 60.49273545049205
Learned parameters: [2.1507064941543046, 3.801699468035028, 5.7083160640339035, -2.6092717294108048]
Epoch: 4596  loss: 60.49166277537527
Learned parameters: [2.150654198191323, 3.801772525892947, 5.708421231153404, -2.609414508319108]
Epoch: 4597  loss: 60.490592732048114
Learned parameters: [2.1506019530060057, 3.80184551252065, 5.708526296057197, -2.6095571482049222]
Epoch: 4598  loss: 60.489525315196786
Learned parameters: [2.1505497585773, 3.8019184279484133, 5.708631258787885, -2.6096996491268802]
Epoch: 4599  loss: 60.48846051952782
Learned parameters: [2.150497614884174, 3.8019912722065237, 5.708736119388146, -2.6098420111436544]
Epoch: 4600  loss: 60.487398339745646
Learned parameters: [2.150445521905552, 3.802064045325294, 5.708840877900642, -2.609984234313949]
Epoch: 4601  loss: 60.48633877056709
Learned parameters: [2.150393479620339, 3.8021367473350565, 5.708945534368059, -2.6101263186965027]
Epoch: 4602  loss: 60.48528180671761
Learned parameters: [2.1503414880074527, 3.8022093782661566, 5.709050088833143, -2.6102682643500934]
Epoch: 4603  loss: 60.48422744293166
Learned parameters: [2.1502895470457877, 3.802281938148959, 5.709154541338658, -2.610410071333533]
Epoch: 4604  loss: 60.48317567394616
Learned parameters: [2.150237656714195, 3.8023544270138565, 5.7092588919273535, -2.6105517397056652]
Epoch: 4605  loss: 60.48212649451549
Learned parameters: [2.1501858169915606, 3.802426844891246, 5.709363140642071, -2.6106932695253744]
Epoch: 4606  loss: 60.481079899394125
Learned parameters: [2.15013402785673, 3.8024991918115507, 5.709467287525647, -2.610834660851578]
Epoch: 4607  loss: 60.48003588334754
Learned parameters: [2.15008228928853, 3.8025714678052136, 5.709571332620935, -2.6109759137432276]
Epoch: 4608  loss: 60.478994441150114
Learned parameters: [2.150030601265787, 3.802643672902693, 5.709675275970835, -2.611117028259312]
Epoch: 4609  loss: 60.47795556758615
Learned parameters: [2.1499789637673006, 3.8027158071344687, 5.709779117618257, -2.6112580044588527]
Epoch: 4610  loss: 60.47691925747959
Learned parameters: [2.14992737677247, 3.802787870531503, 5.709882857605746, -2.6113988423993226]
Epoch: 4611  loss: 60.47588550563272
Learned parameters: [2.149875840259612, 3.8028598631243478, 5.709986495975753, -2.611539542139922]
Epoch: 4612  loss: 60.47485430681898
Learned parameters: [2.1498243542077793, 3.802931784943378, 5.7100900327717925, -2.611680103739989]
Epoch: 4613  loss: 60.47382565585018
Learned parameters: [2.1497729185958643, 3.8030036360190227, 5.710193468037195, -2.6118205272588697]
Epoch: 4614  loss: 60.47279954755068
Learned parameters: [2.149721533402177, 3.8030754163818807, 5.7102968018145175, -2.611960812755857]
Epoch: 4615  loss: 60.471775976746414
Learned parameters: [2.149670198605504, 3.8031471260626177, 5.710400034147118, -2.612100960290332]
Epoch: 4616  loss: 60.47075493826904
Learned parameters: [2.1496189141847513, 3.8032187650919287, 5.710503165078577, -2.6122409699217024]
Epoch: 4617  loss: 60.4697364269671
Learned parameters: [2.1495676801182992, 3.8032903335006285, 5.710606194651758, -2.6123808417093266]
Epoch: 4618  loss: 60.468720437691374
Learned parameters: [2.1495164963847366, 3.8033618313194713, 5.710709122909847, -2.6125205757126286]
Epoch: 4619  loss: 60.46770696530649
Learned parameters: [2.149465362962953, 3.8034332585791293, 5.710811949896485, -2.612660171991113]
Epoch: 4620  loss: 60.46669600468289
Learned parameters: [2.1494142798314817, 3.8035046153103615, 5.71091467565484, -2.612799630604266]
Epoch: 4621  loss: 60.46568755070136
Learned parameters: [2.149363246968758, 3.8035759015439496, 5.711017300227983, -2.6129389516115973]
Epoch: 4622  loss: 60.464681598240084
Learned parameters: [2.1493122643535485, 3.8036471173105912, 5.711119823659479, -2.6130781350727017]
Epoch: 4623  loss: 60.46367814220245
Learned parameters: [2.149261331964504, 3.8037182626410133, 5.711222245992772, -2.613217181047194]
Epoch: 4624  loss: 60.462677177487905
Learned parameters: [2.1492104497800137, 3.803789337566013, 5.711324567270973, -2.613356089594685]
Epoch: 4625  loss: 60.46167869900792
Learned parameters: [2.14915961777868, 3.803860342116337, 5.711426787537528, -2.6134948607748556]
Epoch: 4626  loss: 60.46068270167831
Learned parameters: [2.149108835939204, 3.803931276322712, 5.711528906836066, -2.6136334946474364]
Epoch: 4627  loss: 60.459689180428754
Learned parameters: [2.1490581042400096, 3.804002140215945, 5.711630925209861, -2.6137719912721527]
Epoch: 4628  loss: 60.45869813019349
Learned parameters: [2.1490074226595293, 3.804072933826847, 5.711732842702242, -2.6139103507087667]
Epoch: 4629  loss: 60.45770954591852
Learned parameters: [2.148956791176461, 3.804143657186172, 5.71183465935695, -2.614048573017115]
Epoch: 4630  loss: 60.45672342254835
Learned parameters: [2.1489062097692613, 3.8042143103247463, 5.711936375217431, -2.6141866582570334]
Epoch: 4631  loss: 60.45573975504628
Learned parameters: [2.148855678416288, 3.804284893273434, 5.7120379903270315, -2.6143246064883767]
Epoch: 4632  loss: 60.45475853838003
Learned parameters: [2.148805197096136, 3.8043554060630513, 5.712139504729475, -2.61446241777107]
Epoch: 4633  loss: 60.453779767520544
Learned parameters: [2.1487547657873094, 3.804425848724452, 5.712240918468399, -2.6146000921650576]
Epoch: 4634  loss: 60.45280343745603
Learned parameters: [2.1487043844681377, 3.8044962212885496, 5.7123422315872405, -2.614737629730293]
Epoch: 4635  loss: 60.451829543170874
Learned parameters: [2.148654053117088, 3.8045665237862374, 5.712443444129674, -2.614875030526783]
Epoch: 4636  loss: 60.45085807966707
Learned parameters: [2.1486037717126742, 3.804636756248413, 5.7125445561394805, -2.6150122946145737]
Epoch: 4637  loss: 60.44988904195346
Learned parameters: [2.1485535402332103, 3.8047069187059424, 5.712645567660151, -2.6151494220537193]
Epoch: 4638  loss: 60.44892242504501
Learned parameters: [2.1485033586571056, 3.8047770111896897, 5.71274647873536, -2.615286412904324]
Epoch: 4639  loss: 60.447958223967376
Learned parameters: [2.148453226962866, 3.8048470337305242, 5.712847289408965, -2.6154232672265376]
Epoch: 4640  loss: 60.446996433746406
Learned parameters: [2.1484031451288006, 3.8049169863593995, 5.712947999724606, -2.6155599850805156]
Epoch: 4641  loss: 60.4460370494232
Learned parameters: [2.1483531131332088, 3.804986869107305, 5.713048609725959, -2.6156965665264447]
Epoch: 4642  loss: 60.44508006604384
Learned parameters: [2.1483031309545484, 3.805056682005218, 5.713149119456972, -2.615833011624565]
Epoch: 4643  loss: 60.444125478661675
Learned parameters: [2.1482531985711595, 3.805126425084172, 5.713249528961475, -2.6159693204351284]
Epoch: 4644  loss: 60.44317328233663
Learned parameters: [2.1482033159612692, 3.8051960983752555, 5.713349838283186, -2.6161054930184]
Epoch: 4645  loss: 60.44222347214319
Learned parameters: [2.1481534831032487, 3.805265701909547, 5.713450047466075, -2.6162415294346966]
Epoch: 4646  loss: 60.44127604315538
Learned parameters: [2.1481036999754592, 3.805335235718151, 5.713550156554145, -2.6163774297443645]
Epoch: 4647  loss: 60.44033099045808
Learned parameters: [2.1480539665560996, 3.8054046998322395, 5.7136501655912175, -2.6165131940077564]
Epoch: 4648  loss: 60.43938830914482
Learned parameters: [2.1480042828234365, 3.8054740942829888, 5.713750074621256, -2.6166488222852684]
Epoch: 4649  loss: 60.43844799431734
Learned parameters: [2.147954648755819, 3.8055434191015762, 5.713849883688389, -2.61678431463734]
Epoch: 4650  loss: 60.43751004108529
Learned parameters: [2.147905064331452, 3.8056126743192378, 5.7139495928365855, -2.6169196711244243]
Epoch: 4651  loss: 60.436574444562254
Learned parameters: [2.147855529528525, 3.8056818599672333, 5.714049202109844, -2.617054891807004]
Epoch: 4652  loss: 60.435641199875455
Learned parameters: [2.147806044325315, 3.805750976076818, 5.714148711552329, -2.617189976745609]
Epoch: 4653  loss: 60.43471030215608
Learned parameters: [2.147756608700045, 3.8058200226792778, 5.714248121208174, -2.6173249260007942]
Epoch: 4654  loss: 60.43378174654518
Learned parameters: [2.1477072226308502, 3.805888999805939, 5.714347431121436, -2.617459739633137]
Epoch: 4655  loss: 60.432855528186025
Learned parameters: [2.1476578860959314, 3.805957907488127, 5.714446641336311, -2.6175944177032626]
Epoch: 4656  loss: 60.43193164223629
Learned parameters: [2.147608599073517, 3.806026745757178, 5.714545751897079, -2.6177289602718363]
Epoch: 4657  loss: 60.43101008386198
Learned parameters: [2.1475593615417, 3.806095514644476, 5.714644762847881, -2.617863367399542]
Epoch: 4658  loss: 60.4300908482314
Learned parameters: [2.1475101734785955, 3.806164214181415, 5.71474367423293, -2.6179976391471054]
Epoch: 4659  loss: 60.429173930524
Learned parameters: [2.147461034862417, 3.806232844399383, 5.714842486096631, -2.6181317755753044]
Epoch: 4660  loss: 60.42825932592129
Learned parameters: [2.147411945671222, 3.8063014053297715, 5.7149411984831815, -2.618265776744924]
Epoch: 4661  loss: 60.42734702962583
Learned parameters: [2.1473629058831043, 3.8063698970039863, 5.71503981143688, -2.6183996427167964]
Epoch: 4662  loss: 60.426437036837854
Learned parameters: [2.147313915476204, 3.806438319453436, 5.715138325002144, -2.618533373551799]
Epoch: 4663  loss: 60.42552934276125
Learned parameters: [2.1472649744285732, 3.8065066727095695, 5.715236739223309, -2.6186669693108358]
Epoch: 4664  loss: 60.42462394261872
Learned parameters: [2.1472160827182565, 3.806574956803853, 5.715335054144755, -2.6188004300548497]
Epoch: 4665  loss: 60.423720831632686
Learned parameters: [2.1471672403233133, 3.806643171767764, 5.715433269810926, -2.618933755844826]
Epoch: 4666  loss: 60.42282000503381
Learned parameters: [2.1471184472217986, 3.806711317632798, 5.71553138626631, -2.619066946741789]
Epoch: 4667  loss: 60.42192145806617
Learned parameters: [2.1470697033916974, 3.806779394430483, 5.715629403555346, -2.6192000028067937]
Epoch: 4668  loss: 60.421025185974074
Learned parameters: [2.1470210088110235, 3.806847402192355, 5.715727321722561, -2.619332924100938]
Epoch: 4669  loss: 60.42013118401251
Learned parameters: [2.146972363457781, 3.80691534094997, 5.71582514081252, -2.619465710685363]
Epoch: 4670  loss: 60.41923944744691
Learned parameters: [2.14692376730993, 3.8069832107349124, 5.715922860869775, -2.6195983626212436]
Epoch: 4671  loss: 60.41834997154434
Learned parameters: [2.1468752203454313, 3.8070510115787783, 5.71602048193893, -2.619730879969794]
Epoch: 4672  loss: 60.41746275158334
Learned parameters: [2.1468267225422255, 3.8071187435131817, 5.716118004064602, -2.619863262792265]
Epoch: 4673  loss: 60.41657778285047
Learned parameters: [2.146778273878263, 3.807186406569747, 5.716215427291472, -2.6199955111499458]
Epoch: 4674  loss: 60.415695060636196
Learned parameters: [2.146729874331455, 3.8072540007801208, 5.716312751664211, -2.6201276251041596]
Epoch: 4675  loss: 60.41481458024444
Learned parameters: [2.146681523879693, 3.807321526175967, 5.716409977227513, -2.620259604716266]
Epoch: 4676  loss: 60.41393633698469
Learned parameters: [2.146633222500877, 3.807388982788961, 5.7165071040261255, -2.6203914500476624]
Epoch: 4677  loss: 60.41306032616793
Learned parameters: [2.1465849701728863, 3.807456370650794, 5.716604132104818, -2.6205231611597837]
Epoch: 4678  loss: 60.4121865431196
Learned parameters: [2.1465367668735698, 3.8075236897931783, 5.716701061508363, -2.620654738114098]
Epoch: 4679  loss: 60.41131498317101
Learned parameters: [2.146488612580795, 3.8075909402478345, 5.7167978922816065, -2.620786180972115]
Epoch: 4680  loss: 60.41044564166228
Learned parameters: [2.146440507272373, 3.8076581220465093, 5.71689462446936, -2.6209174897953744]
Epoch: 4681  loss: 60.40957851393657
Learned parameters: [2.146392450926135, 3.807725235220952, 5.716991258116509, -2.6210486646454574]
Epoch: 4682  loss: 60.40871359535059
Learned parameters: [2.1463444435198853, 3.807792279802896, 5.717087793267932, -2.621179705583988]
Epoch: 4683  loss: 60.4078508812611
Learned parameters: [2.1462964850314274, 3.8078592558241273, 5.717184229968574, -2.6213106126726258]
Epoch: 4684  loss: 60.40699036704186
Learned parameters: [2.146248575438523, 3.807926163316454, 5.717280568263365, -2.6214413859730614]
Epoch: 4685  loss: 60.40613204806616
Learned parameters: [2.146200714718937, 3.8079930023116977, 5.71737680819729, -2.621572025547023]
Epoch: 4686  loss: 60.40527591971442
Learned parameters: [2.1461529028504303, 3.8080597728416956, 5.717472949815372, -2.6217025314562754]
Epoch: 4687  loss: 60.404421977381105
Learned parameters: [2.146105139810721, 3.8081264749383115, 5.717568993162622, -2.621832903762616]
Epoch: 4688  loss: 60.403570216464665
Learned parameters: [2.1460574255775513, 3.808193108633418, 5.717664938284134, -2.6219631425278833]
Epoch: 4689  loss: 60.40272063237037
Learned parameters: [2.146009760128614, 3.808259673958914, 5.717760785224978, -2.6220932478139467]
Epoch: 4690  loss: 60.40187322051067
Learned parameters: [2.1459621434416007, 3.808326170946714, 5.7178565340302665, -2.6222232196827107]
Epoch: 4691  loss: 60.40102797630616
Learned parameters: [2.1459145754942024, 3.8083925996287467, 5.71795218474516, -2.622353058196117]
Epoch: 4692  loss: 60.4001848951874
Learned parameters: [2.145867056264095, 3.808458960036958, 5.718047737414842, -2.6224827634161425]
Epoch: 4693  loss: 60.39934397258723
Learned parameters: [2.1458195857289084, 3.8085252522033213, 5.7181431920844785, -2.622612335404793]
Epoch: 4694  loss: 60.398505203952276
Learned parameters: [2.1457721638662886, 3.80859147615982, 5.718238548799303, -2.622741774224114]
Epoch: 4695  loss: 60.397668584727796
Learned parameters: [2.145724790653886, 3.8086576319384506, 5.718333807604601, -2.622871079936189]
Epoch: 4696  loss: 60.396834110375714
Learned parameters: [2.145677466069287, 3.808723719571241, 5.7184289685456156, -2.6230002526031284]
Epoch: 4697  loss: 60.39600177636023
Learned parameters: [2.14563019009009, 3.8087897390902294, 5.718524031667648, -2.6231292922870804]
Epoch: 4698  loss: 60.39517157815494
Learned parameters: [2.1455829626939145, 3.8088556905274644, 5.718618997016081, -2.623258199050234]
Epoch: 4699  loss: 60.39434351123929
Learned parameters: [2.1455357838582927, 3.8089215739150304, 5.718713864636214, -2.623386972954803]
Epoch: 4700  loss: 60.39351757109885
Learned parameters: [2.1454886535608, 3.808987389285016, 5.718808634573459, -2.623515614063044]
Epoch: 4701  loss: 60.39269375323125
Learned parameters: [2.1454415717789908, 3.8090531366695286, 5.71890330687324, -2.6236441224372475]
Epoch: 4702  loss: 60.39187205313671
Learned parameters: [2.145394538490392, 3.8091188161006984, 5.718997881580989, -2.6237724981397386]
Epoch: 4703  loss: 60.39105246632637
Learned parameters: [2.1453475536725093, 3.809184427610675, 5.719092358742156, -2.6239007412328754]
Epoch: 4704  loss: 60.39023498831437
Learned parameters: [2.1453006173028664, 3.8092499712316177, 5.719186738402259, -2.6240288517790558]
Epoch: 4705  loss: 60.389419614626455
Learned parameters: [2.1452537293590264, 3.8093154469959205, 5.719281020607051, -2.6241568298407163]
Epoch: 4706  loss: 60.38860634078392
Learned parameters: [2.145206889818291, 3.80938085493607, 5.719375205401962, -2.6242846754802804]
Epoch: 4707  loss: 60.38779516232358
Learned parameters: [2.1451600986581068, 3.8094461950844947, 5.7194692928326605, -2.6244123887602373]
Epoch: 4708  loss: 60.386986074797974
Learned parameters: [2.1451133558560556, 3.8095114674735577, 5.71956328294502, -2.6245399697431298]
Epoch: 4709  loss: 60.386179073756885
Learned parameters: [2.1450666613894724, 3.809576672135663, 5.719657175784598, -2.6246674184915046]
Epoch: 4710  loss: 60.385374154759006
Learned parameters: [2.1450200152356884, 3.8096418091032054, 5.7197509713969845, -2.6247947350679546]
Epoch: 4711  loss: 60.38457131337785
Learned parameters: [2.1449734173722597, 3.8097068784085133, 5.719844669828123, -2.6249219195351516]
Epoch: 4712  loss: 60.38377054518028
Learned parameters: [2.1449268677765234, 3.809771880083964, 5.719938271123692, -2.625048971955782]
Epoch: 4713  loss: 60.38297184575725
Learned parameters: [2.1448803664257543, 3.809836814161944, 5.720031775329323, -2.6251758923925688]
Epoch: 4714  loss: 60.38217521069102
Learned parameters: [2.1448339132974006, 3.8099016806747916, 5.720125182490931, -2.625302680908305]
Epoch: 4715  loss: 60.38138063558378
Learned parameters: [2.14478750836885, 3.8099664796548582, 5.7202184926543875, -2.6254293375658193]
Epoch: 4716  loss: 60.38058811603687
Learned parameters: [2.144741151617304, 3.810031211134542, 5.720311705865344, -2.625555862427958]
Epoch: 4717  loss: 60.37979764766262
Learned parameters: [2.1446948430201367, 3.810095875146197, 5.720404822169739, -2.6256822555576336]
Epoch: 4718  loss: 60.37900922607875
Learned parameters: [2.144648582554722, 3.810160471722182, 5.72049784161355, -2.625808517017801]
Epoch: 4719  loss: 60.37822284691056
Learned parameters: [2.1446023701982426, 3.810225000894908, 5.720590764242533, -2.625934646871429]
Epoch: 4720  loss: 60.3774385057922
Learned parameters: [2.1445562059279846, 3.8102894626967667, 5.720683590102629, -2.626060645181539]
Epoch: 4721  loss: 60.376656198363094
Learned parameters: [2.144510089721305, 3.81035385716014, 5.720776319239925, -2.6261865120112042]
Epoch: 4722  loss: 60.37587592027265
Learned parameters: [2.144464021555364, 3.8104181843174683, 5.7208689517002735, -2.626312247423505]
Epoch: 4723  loss: 60.37509766717453
Learned parameters: [2.1444180014073746, 3.8104824442011913, 5.720961487529647, -2.6264378514815676]
Epoch: 4724  loss: 60.37432143472864
Learned parameters: [2.1443720292546504, 3.8105466368437346, 5.7210539267742, -2.6265633242485684]
Epoch: 4725  loss: 60.37354721860668
Learned parameters: [2.1443261050743683, 3.8106107622775727, 5.721146269479943, -2.6266886657877007]
Epoch: 4726  loss: 60.37277501448394
Learned parameters: [2.1442802288436544, 3.8106748205352083, 5.72123851569286, -2.6268138761621835]
Epoch: 4727  loss: 60.37200481804234
Learned parameters: [2.144234400539763, 3.810738811649127, 5.721330665459155, -2.6269389554352904]
Epoch: 4728  loss: 60.371236624974756
Learned parameters: [2.144188620139887, 3.8108027356518472, 5.7214227188249955, -2.627063903670319]
Epoch: 4729  loss: 60.370470430975814
Learned parameters: [2.144142887621072, 3.8108665925758602, 5.721514675836336, -2.627188720930578]
Epoch: 4730  loss: 60.36970623175763
Learned parameters: [2.144097202960554, 3.8109303824536065, 5.721606536539435, -2.6273134072794413]
Epoch: 4731  loss: 60.36894402303059
Learned parameters: [2.1440515661355395, 3.810994105317582, 5.721698300980568, -2.6274379627803115]
Epoch: 4732  loss: 60.36818380051142
Learned parameters: [2.1440059771230167, 3.811057761200368, 5.721789969205758, -2.62756238749659]
Epoch: 4733  loss: 60.36742555992794
Learned parameters: [2.143960435900134, 3.8111213501345342, 5.721881541261297, -2.6276866814917317]
Epoch: 4734  loss: 60.36666929701356
Learned parameters: [2.143914942444092, 3.811184872152667, 5.7219730171936005, -2.6278108448292277]
Epoch: 4735  loss: 60.36591500750761
Learned parameters: [2.1438694967318646, 3.811248327287444, 5.722064397048819, -2.62793487757257]
Epoch: 4736  loss: 60.36516268716013
Learned parameters: [2.1438240987405144, 3.8113117155715535, 5.722155680873281, -2.6280587797852974]
Epoch: 4737  loss: 60.36441233172238
Learned parameters: [2.1437787484472013, 3.8113750370376858, 5.722246868713495, -2.628182551530992]
Epoch: 4738  loss: 60.36366393695433
Learned parameters: [2.1437334458289024, 3.8114382917186025, 5.7223379606157625, -2.6283061928732376]
Epoch: 4739  loss: 60.362917498629656
Learned parameters: [2.1436881908626213, 3.8115014796470836, 5.722428956626466, -2.628429703875654]
Epoch: 4740  loss: 60.36217301252026
Learned parameters: [2.1436429835254476, 3.8115646008559105, 5.7225198567921565, -2.6285530846019025]
Epoch: 4741  loss: 60.36143047440741
Learned parameters: [2.143597823794371, 3.811627655377913, 5.7226106611592895, -2.628676335115663]
Epoch: 4742  loss: 60.360689880085985
Learned parameters: [2.143552711646341, 3.811690643245952, 5.7227013697743105, -2.62879945548064]
Epoch: 4743  loss: 60.35995122534699
Learned parameters: [2.143507647058386, 3.8117535644928897, 5.722791982683823, -2.6289224457605846]
Epoch: 4744  loss: 60.35921450599852
Learned parameters: [2.1434626300074795, 3.811816419151621, 5.722882499934398, -2.6290453060192718]
Epoch: 4745  loss: 60.35847971784952
Learned parameters: [2.143417660470534, 3.8118792072550742, 5.722972921572567, -2.629168036320502]
Epoch: 4746  loss: 60.35774685671665
Learned parameters: [2.1433727384245174, 3.8119419288361827, 5.723063247644985, -2.6292906367281197]
Epoch: 4747  loss: 60.35701591842469
Learned parameters: [2.1433278638463826, 3.8120045839278984, 5.7231534781983315, -2.6294131073060014]
Epoch: 4748  loss: 60.356286898806275
Learned parameters: [2.143283036713006, 3.8120671725632094, 5.723243613279224, -2.6295354481180495]
Epoch: 4749  loss: 60.35555979370023
Learned parameters: [2.1432382570012884, 3.8121296947751113, 5.723333652934363, -2.629657659228207]
Epoch: 4750  loss: 60.35483459895115
Learned parameters: [2.143193524688169, 3.8121921505966054, 5.723423597210543, -2.6297797407004593]
Epoch: 4751  loss: 60.35411131041268
Learned parameters: [2.1431488397504816, 3.812254540060732, 5.72351344615446, -2.6299016925988137]
Epoch: 4752  loss: 60.35338992394236
Learned parameters: [2.143104202165067, 3.8123168632005426, 5.723603199812863, -2.6300235149873172]
Epoch: 4753  loss: 60.35267043540917
Learned parameters: [2.1430596119088365, 3.812379120049083, 5.723692858232648, -2.6301452079300653]
Epoch: 4754  loss: 60.3519528406837
Learned parameters: [2.143015068958595, 3.812441310639456, 5.723782421460616, -2.630266771491178]
Epoch: 4755  loss: 60.3512371356466
Learned parameters: [2.142970573291118, 3.8125034350047513, 5.72387188954355, -2.630388205734801]
Epoch: 4756  loss: 60.350523316187534
Learned parameters: [2.142926124883275, 3.8125654931780346, 5.7239612625284035, -2.6305095107251346]
Epoch: 4757  loss: 60.3498113782002
Learned parameters: [2.1428817237118687, 3.812627485192406, 5.724050540462086, -2.6306306865264077]
Epoch: 4758  loss: 60.34910131758601
Learned parameters: [2.142837369753629, 3.812689411080996, 5.724139723391451, -2.630751733202878]
Epoch: 4759  loss: 60.348393130253015
Learned parameters: [2.142793062985357, 3.812751270876931, 5.7242288113634965, -2.630872650818853]
Epoch: 4760  loss: 60.347686812113466
Learned parameters: [2.1427488033838267, 3.812813064613357, 5.724317804425231, -2.6309934394386767]
Epoch: 4761  loss: 60.34698235909265
Learned parameters: [2.142704590925731, 3.8128747923234543, 5.724406702623598, -2.631114099126721]
Epoch: 4762  loss: 60.346279767113884
Learned parameters: [2.142660425587824, 3.8129364540404, 5.724495506005667, -2.6312346299474054]
Epoch: 4763  loss: 60.345579032118934
Learned parameters: [2.142616307346827, 3.8129980497973928, 5.724584214618513, -2.6313550319651844]
Epoch: 4764  loss: 60.344880150046606
Learned parameters: [2.142572236179428, 3.813059579627652, 5.72467282850921, -2.6314753052445456]
Epoch: 4765  loss: 60.344183116844206
Learned parameters: [2.142528212062301, 3.813121043564414, 5.724761347724855, -2.6315954498500136]
Epoch: 4766  loss: 60.343487928471376
Learned parameters: [2.14248423497214, 3.8131824416409223, 5.724849772312622, -2.6317154658461535]
Epoch: 4767  loss: 60.34279458088924
Learned parameters: [2.142440304885601, 3.813243773890444, 5.724938102319674, -2.631835353297564]
Epoch: 4768  loss: 60.34210307006674
Learned parameters: [2.1423964217792952, 3.8133050403462745, 5.725026337793167, -2.631955112268879]
Epoch: 4769  loss: 60.34141339198065
Learned parameters: [2.142352585629896, 3.813366241041708, 5.7251144787803865, -2.632074742824781]
Epoch: 4770  loss: 60.340725542614855
Learned parameters: [2.1423087964140044, 3.8134273760100696, 5.725202525328564, -2.6321942450299787]
Epoch: 4771  loss: 60.340039517955496
Learned parameters: [2.142265054108188, 3.813488445284705, 5.725290477484928, -2.6323136189492122]
Epoch: 4772  loss: 60.33935531400334
Learned parameters: [2.1422213586890893, 3.813549448898953, 5.725378335296859, -2.6324328646472703]
Epoch: 4773  loss: 60.338672926758555
Learned parameters: [2.1421777101332684, 3.8136103868861877, 5.7254660988116655, -2.632551982188966]
Epoch: 4774  loss: 60.337992352235524
Learned parameters: [2.142134108417242, 3.8136712592798054, 5.72555376807664, -2.6326709716391434]
Epoch: 4775  loss: 60.33731358644845
Learned parameters: [2.1420905535176247, 3.8137320661131913, 5.72564134313926, -2.632789833062697]
Epoch: 4776  loss: 60.33663662542125
Learned parameters: [2.1420470454109286, 3.81379280741977, 5.725728824046901, -2.6329085665245424]
Epoch: 4777  loss: 60.33596146518466
Learned parameters: [2.1420035840736347, 3.8138534832329873, 5.725816210846943, -2.633027172089628]
Epoch: 4778  loss: 60.33528810177838
Learned parameters: [2.141960169482285, 3.8139140935862264, 5.725903503586862, -2.6331456498229513]
Epoch: 4779  loss: 60.334616531245125
Learned parameters: [2.1419168016134202, 3.8139746385128808, 5.725990702314174, -2.6332639997895475]
Epoch: 4780  loss: 60.33394674963438
Learned parameters: [2.1418734804434783, 3.8140351180464642, 5.726077807076351, -2.6333822220544794]
Epoch: 4781  loss: 60.33327875300547
Learned parameters: [2.1418302059488945, 3.8140955322204815, 5.726164817920883, -2.6335003166828366]
Epoch: 4782  loss: 60.3326125374211
Learned parameters: [2.141786978106186, 3.814155881068434, 5.726251734895422, -2.6336182837397564]
Epoch: 4783  loss: 60.33194809895171
Learned parameters: [2.1417437968917894, 3.8142161646238613, 5.726338558047556, -2.6337361232903995]
Epoch: 4784  loss: 60.33128543367559
Learned parameters: [2.1417006622820796, 3.8142763829203328, 5.726425287424828, -2.633853835399953]
Epoch: 4785  loss: 60.330624537678226
Learned parameters: [2.141657574253503, 3.814336535991417, 5.726511923074927, -2.633971420133649]
Epoch: 4786  loss: 60.32996540704899
Learned parameters: [2.1416145327825054, 3.8143966238706963, 5.726598465045587, -2.6340888775567546]
Epoch: 4787  loss: 60.32930803788503
Learned parameters: [2.1415715378454045, 3.814456646591802, 5.726684913384405, -2.6342062077345534]
Epoch: 4788  loss: 60.32865242629104
Learned parameters: [2.1415285894186065, 3.814516604188358, 5.726771268139149, -2.6343234107323767]
Epoch: 4789  loss: 60.327998568379485
Learned parameters: [2.141485687478497, 3.814576496694007, 5.726857529357601, -2.6344404866155893]
Epoch: 4790  loss: 60.3273464602637
Learned parameters: [2.1414428320014047, 3.8146363241424233, 5.726943697087508, -2.6345574354495813]
Epoch: 4791  loss: 60.32669609807559
Learned parameters: [2.1414000229636474, 3.8146960865672965, 5.727029771376646, -2.6346742572997783]
Epoch: 4792  loss: 60.32604747793665
Learned parameters: [2.14135726034159, 3.81475578400232, 5.727115752272901, -2.6347909522316484]
Epoch: 4793  loss: 60.32540059599103
Learned parameters: [2.141314544111532, 3.814815416481217, 5.727201639824114, -2.6349075203106853]
Epoch: 4794  loss: 60.32475544838012
Learned parameters: [2.141271874249738, 3.8148749840377354, 5.727287434078116, -2.635023961602414]
Epoch: 4795  loss: 60.324112031255765
Learned parameters: [2.141229250732538, 3.814934486705619, 5.72737313508288, -2.635140276172405]
Epoch: 4796  loss: 60.323470340772985
Learned parameters: [2.141186673536198, 3.814993924518643, 5.727458742886331, -2.6352564640862557]
Epoch: 4797  loss: 60.322830373100025
Learned parameters: [2.1411441426369415, 3.815053297510606, 5.727544257536375, -2.635372525409592]
Epoch: 4798  loss: 60.32219212440073
Learned parameters: [2.1411016580110487, 3.815112605715307, 5.727629679081047, -2.635488460208085]
Epoch: 4799  loss: 60.32155559085911
Learned parameters: [2.141059219634746, 3.81517184916657, 5.727715007568346, -2.635604268547434]
Epoch: 4800  loss: 60.32092076865497
Learned parameters: [2.1410168274842554, 3.815231027898236, 5.727800243046311, -2.635719950493373]
Epoch: 4801  loss: 60.320287653979186
Learned parameters: [2.1409744815357694, 3.8152901419441663, 5.727885385562984, -2.635835506111669]
Epoch: 4802  loss: 60.31965624302888
Learned parameters: [2.1409321817654936, 3.815349191338232, 5.727970435166469, -2.6359509354681285]
Epoch: 4803  loss: 60.31902653200822
Learned parameters: [2.140889928149615, 3.815408176114323, 5.728055391904889, -2.6360662386285907]
Epoch: 4804  loss: 60.318398517123164
Learned parameters: [2.140847720664334, 3.815467096306495, 5.728140255826521, -2.636181415658931]
Epoch: 4805  loss: 60.317772194584
Learned parameters: [2.140805559285744, 3.8155259519489957, 5.728225026979619, -2.6362964666250432]
Epoch: 4806  loss: 60.317147560615965
Learned parameters: [2.140763443989844, 3.815584743075979, 5.728309705412276, -2.6364113915928367]
Epoch: 4807  loss: 60.31652461144506
Learned parameters: [2.1407213747529203, 3.8156434697215107, 5.728394291173015, -2.6365261906283055]
Epoch: 4808  loss: 60.315903343310225
Learned parameters: [2.1406793515510585, 3.8157021319196964, 5.728478784310121, -2.636640863797458]
Epoch: 4809  loss: 60.31528375245153
Learned parameters: [2.140637374360191, 3.815760729704669, 5.728563184871694, -2.6367554111663245]
Epoch: 4810  loss: 60.31466583512076
Learned parameters: [2.1405954431565335, 3.8158192631104524, 5.728647492906245, -2.6368698328010014]
Epoch: 4811  loss: 60.31404958757171
Learned parameters: [2.140553557916212, 3.815877732171082, 5.7287317084621945, -2.636984128767614]
Epoch: 4812  loss: 60.313435006067394
Learned parameters: [2.140511718615097, 3.8159361369206555, 5.728815831587645, -2.637098299132296]
Epoch: 4813  loss: 60.312822086874725
Learned parameters: [2.1404699252293304, 3.8159944773932053, 5.7288998623311285, -2.6372123439612714]
Epoch: 4814  loss: 60.31221082627111
Learned parameters: [2.1404281777350267, 3.8160527536227704, 5.728983800741177, -2.637326263320801]
Epoch: 4815  loss: 60.31160122053357
Learned parameters: [2.14038647610804, 3.816110965643457, 5.729067646866, -2.6374400572771513]
Epoch: 4816  loss: 60.310993265953286
Learned parameters: [2.1403448203244086, 3.816169113489327, 5.7291514007541045, -2.6375537258966553]
Epoch: 4817  loss: 60.31038695882279
Learned parameters: [2.1403032103602366, 3.8162271971944324, 5.729235062454134, -2.637667269245697]
Epoch: 4818  loss: 60.3097822954425
Learned parameters: [2.1402616461913686, 3.816285216792896, 5.72931863201441, -2.6377806873906597]
Epoch: 4819  loss: 60.30917927211987
Learned parameters: [2.140220127793769, 3.816343172318818, 5.729402109483461, -2.637893980397984]
Epoch: 4820  loss: 60.30857788516977
Learned parameters: [2.140178655143496, 3.816401063806287, 5.729485494909991, -2.63800714833416]
Epoch: 4821  loss: 60.30797813090823
Learned parameters: [2.140137228216396, 3.8164588912894537, 5.729568788342449, -2.6381201912656826]
Epoch: 4822  loss: 60.30738000566404
Learned parameters: [2.140095846988362, 3.816516654802471, 5.7296519898293905, -2.638233109259089]
Epoch: 4823  loss: 60.306783505770504
Learned parameters: [2.1400545114354026, 3.816574354379475, 5.729735099419578, -2.6383459023809683]
Epoch: 4824  loss: 60.30618862756469
Learned parameters: [2.1400132215333754, 3.816631990054655, 5.729818117161604, -2.6384585706979204]
Epoch: 4825  loss: 60.30559536739452
Learned parameters: [2.1399719772581056, 3.8166895618622245, 5.729901043104056, -2.6385711142765738]
Epoch: 4826  loss: 60.30500372160963
Learned parameters: [2.1399307785855437, 3.8167470698363815, 5.729983877295744, -2.638683533183608]
Epoch: 4827  loss: 60.30441368656762
Learned parameters: [2.1398896254915543, 3.8168045140113627, 5.730066619785397, -2.6387958274857213]
Epoch: 4828  loss: 60.30382525863584
Learned parameters: [2.1398485179519056, 3.816861894421446, 5.730149270621654, -2.6389079972496305]
Epoch: 4829  loss: 60.30323843418442
Learned parameters: [2.139807455942498, 3.8169192111008954, 5.730231829853381, -2.6390200425421027]
Epoch: 4830  loss: 60.30265320958562
Learned parameters: [2.1397664394391724, 3.8169764640840076, 5.730314297529405, -2.6391319634299273]
Epoch: 4831  loss: 60.30206958123167
Learned parameters: [2.1397254684176596, 3.8170336534050726, 5.730396673698408, -2.6392437599799083]
Epoch: 4832  loss: 60.30148754550733
Learned parameters: [2.1396845428538227, 3.817090779098322, 5.730478958409276, -2.6393554322588995]
Epoch: 4833  loss: 60.300907098814946
Learned parameters: [2.1396436627235063, 3.8171478411980466, 5.730561151710935, -2.639466980333785]
Epoch: 4834  loss: 60.30032823755018
Learned parameters: [2.139602828002412, 3.8172048397386065, 5.730643253652159, -2.639578404271459]
Epoch: 4835  loss: 60.29975095812846
Learned parameters: [2.1395620386663, 3.817261774754373, 5.730725264281851, -2.639689704138853]
Epoch: 4836  loss: 60.29917525696116
Learned parameters: [2.1395212946910207, 3.8173186462797206, 5.730807183649084, -2.6398008800029404]
Epoch: 4837  loss: 60.29860113046999
Learned parameters: [2.1394805960522407, 3.817375454349096, 5.73088901180272, -2.639911931930697]
Epoch: 4838  loss: 60.298028575086114
Learned parameters: [2.139439942725676, 3.8174321989969573, 5.730970748791734, -2.6400228599891356]
Epoch: 4839  loss: 60.297457587236465
Learned parameters: [2.1393993346871096, 3.8174888802577702, 5.73105239466524, -2.6401336642453086]
Epoch: 4840  loss: 60.29688816336908
Learned parameters: [2.1393587719122262, 3.817545498166048, 5.73113394947226, -2.6402443447662844]
Epoch: 4841  loss: 60.296320299925796
Learned parameters: [2.1393182543766693, 3.8176020527563437, 5.7312154132618085, -2.640354901619163]
Epoch: 4842  loss: 60.29575399336183
Learned parameters: [2.1392777820561837, 3.817658544063206, 5.731296786083087, -2.640465334871091]
Epoch: 4843  loss: 60.29518924013253
Learned parameters: [2.1392373549264283, 3.8177149721212227, 5.731378067985221, -2.6405756445892328]
Epoch: 4844  loss: 60.29462603670443
Learned parameters: [2.1391969729630005, 3.8177713369650164, 5.731459259017292, -2.640685830840776]
Epoch: 4845  loss: 60.294064379551806
Learned parameters: [2.1391566361416046, 3.8178276386291987, 5.731540359228574, -2.6407958936929576]
Epoch: 4846  loss: 60.29350426515042
Learned parameters: [2.139116344437871, 3.817883877148416, 5.731621368668281, -2.640905833213036]
Epoch: 4847  loss: 60.292945689982815
Learned parameters: [2.139076097827363, 3.817940052557346, 5.731702287385577, -2.6410156494682937]
Epoch: 4848  loss: 60.292388650540616
Learned parameters: [2.139035896285729, 3.8179961648906606, 5.731783115429788, -2.6411253425260606]
Epoch: 4849  loss: 60.2918331433185
Learned parameters: [2.138995739788577, 3.8180522141830537, 5.731863852850225, -2.6412349124536956]
Epoch: 4850  loss: 60.29127916482322
Learned parameters: [2.138955628311436, 3.8181082004692524, 5.731944499696134, -2.641344359318581]
Epoch: 4851  loss: 60.29072671155864
Learned parameters: [2.1389155618299047, 3.818164123783979, 5.7320250560169, -2.641453683188145]
Epoch: 4852  loss: 60.290175780041764
Learned parameters: [2.138875540319539, 3.8182199841619773, 5.732105521861892, -2.641562884129846]
Epoch: 4853  loss: 60.28962636679303
Learned parameters: [2.13883556375587, 3.8182757816380097, 5.732185897280486, -2.6416719622111753]
Epoch: 4854  loss: 60.289078468339916
Learned parameters: [2.13879563211442, 3.8183315162468503, 5.73226618232209, -2.641780917499659]
Epoch: 4855  loss: 60.28853208121457
Learned parameters: [2.1387557453707147, 3.8183871880232836, 5.7323463770361585, -2.641889750062861]
Epoch: 4856  loss: 60.28798720195822
Learned parameters: [2.13871590350026, 3.8184427970021093, 5.73242648147216, -2.6419984599683786]
Epoch: 4857  loss: 60.28744382711673
Learned parameters: [2.138676106478538, 3.8184983432181436, 5.7325064956795755, -2.6421070472838433]
Epoch: 4858  loss: 60.286901953242285
Learned parameters: [2.1386363542810143, 3.8185538267062165, 5.7325864197079035, -2.6422155120769206]
Epoch: 4859  loss: 60.28636157688844
Learned parameters: [2.13859664688317, 3.8186092475011812, 5.732666253606718, -2.642323854415317]
Epoch: 4860  loss: 60.28582269462279
Learned parameters: [2.1385569842604526, 3.818664605637918, 5.732745997425593, -2.6424320743667704]
Epoch: 4861  loss: 60.28528530301323
Learned parameters: [2.1385173663882675, 3.818719901151299, 5.732825651214067, -2.6425401719990442]
Epoch: 4862  loss: 60.28474939863712
Learned parameters: [2.1384777932420693, 3.818775134076178, 5.732905215021779, -2.642648147379944]
Epoch: 4863  loss: 60.284214978080854
Learned parameters: [2.1384382647972946, 3.81883030444743, 5.73298468889839, -2.642756000577311]
Epoch: 4864  loss: 60.28368203792707
Learned parameters: [2.1383987810292866, 3.8188854122999674, 5.733064072893476, -2.6428637316590113]
Epoch: 4865  loss: 60.28315057477408
Learned parameters: [2.1383593419134677, 3.8189404576686945, 5.7331433670567655, -2.642971340692959]
Epoch: 4866  loss: 60.282620585222396
Learned parameters: [2.1383199474252317, 3.8189954405885347, 5.7332225714379925, -2.6430788277471]
Epoch: 4867  loss: 60.28209206587465
Learned parameters: [2.1382805975398855, 3.8190503610944453, 5.73330168608681, -2.6431861928894036]
Epoch: 4868  loss: 60.281565013347326
Learned parameters: [2.1382412922328227, 3.8191052192213752, 5.733380711053035, -2.6432934361878884]
Epoch: 4869  loss: 60.28103942425788
Learned parameters: [2.13820203147937, 3.8191600150043024, 5.733459646386434, -2.6434005577105975]
Epoch: 4870  loss: 60.28051529523221
Learned parameters: [2.1381628152548386, 3.8192147484782213, 5.7335384921367964, -2.6435075575256075]
Epoch: 4871  loss: 60.27999262290032
Learned parameters: [2.138123643534547, 3.8192694196781383, 5.73361724835396, -2.643614435701031]
Epoch: 4872  loss: 60.2794714038977
Learned parameters: [2.1380845162938003, 3.8193240286390755, 5.7336959150877895, -2.643721192305013]
Epoch: 4873  loss: 60.27895163486818
Learned parameters: [2.1380454335078753, 3.819378575396076, 5.733774492388151, -2.643827827405729]
Epoch: 4874  loss: 60.2784333124639
Learned parameters: [2.138006395152037, 3.8194330599841995, 5.7338529803049365, -2.6439343410713882]
Epoch: 4875  loss: 60.27791643333411
Learned parameters: [2.1379674012015832, 3.8194874824385106, 5.733931378888125, -2.644040733370236]
Epoch: 4876  loss: 60.27740099414324
Learned parameters: [2.137928451631719, 3.8195418427941092, 5.7340096881876095, -2.644147004370539]
Epoch: 4877  loss: 60.276886991557305
Learned parameters: [2.1378895464176924, 3.819596141086099, 5.734087908253381, -2.6442531541406025]
Epoch: 4878  loss: 60.27637442224842
Learned parameters: [2.1378506855347554, 3.8196503773495976, 5.734166039135483, -2.6443591827487682]
Epoch: 4879  loss: 60.275863282896594
Learned parameters: [2.13781186895809, 3.8197045516197594, 5.734244080883908, -2.6444650902634064]
Epoch: 4880  loss: 60.27535357018675
Learned parameters: [2.1377730966628867, 3.81975866393175, 5.734322033548701, -2.6445708767529217]
Epoch: 4881  loss: 60.274845280809096
Learned parameters: [2.137734368624371, 3.8198127143207397, 5.7343998971799985, -2.644676542285756]
Epoch: 4882  loss: 60.27433841145836
Learned parameters: [2.137695684817677, 3.819866702821935, 5.73447767182785, -2.644782086930372]
Epoch: 4883  loss: 60.27383295883935
Learned parameters: [2.137657045217964, 3.819920629470549, 5.734555357542382, -2.6448875107552685]
Epoch: 4884  loss: 60.27332891966176
Learned parameters: [2.13761844980043, 3.819974494301797, 5.734632954373814, -2.644992813828982]
Epoch: 4885  loss: 60.27282629063835
Learned parameters: [2.1375798985401553, 3.8200282973509374, 5.734710462372244, -2.6450979962200645]
Epoch: 4886  loss: 60.27232506848807
Learned parameters: [2.1375413914122787, 3.820082038653183, 5.734787881587868, -2.6452030579971115]
Epoch: 4887  loss: 60.271825249943724
Learned parameters: [2.1375029283919518, 3.820135718243761, 5.734865212070943, -2.645307999228754]
Epoch: 4888  loss: 60.2713268317313
Learned parameters: [2.1374645094542606, 3.8201893361579944, 5.734942453871717, -2.64541281998365]
Epoch: 4889  loss: 60.27082981058979
Learned parameters: [2.137426134574264, 3.820242892431247, 5.735019607040454, -2.6455175203304893]
Epoch: 4890  loss: 60.27033418326368
Learned parameters: [2.1373878037270373, 3.820296387098874, 5.73509667162747, -2.6456221003379916]
Epoch: 4891  loss: 60.26983994650355
Learned parameters: [2.1373495168876646, 3.820349820196229, 5.735173647683124, -2.6457265600749094]
Epoch: 4892  loss: 60.269347097065456
Learned parameters: [2.1373112740311755, 3.8204031917586883, 5.73525053525774, -2.6458308996100204]
Epoch: 4893  loss: 60.26885563170782
Learned parameters: [2.1372730751326263, 3.8204565018216363, 5.735327334401723, -2.6459351190121416]
Epoch: 4894  loss: 60.26836554720249
Learned parameters: [2.1372349201670238, 3.8205097504204804, 5.735404045165447, -2.646039218350117]
Epoch: 4895  loss: 60.26787684032082
Learned parameters: [2.13719680910939, 3.8205629375906356, 5.735480667599351, -2.646143197692826]
Epoch: 4896  loss: 60.26738950784227
Learned parameters: [2.1371587419347366, 3.82061606336753, 5.735557201753896, -2.6462470571091807]
Epoch: 4897  loss: 60.26690354655384
Learned parameters: [2.137120718618034, 3.8206691277866134, 5.735633647679528, -2.6463507966681212]
Epoch: 4898  loss: 60.26641895324105
Learned parameters: [2.1370827391342595, 3.8207221308833446, 5.735710005426743, -2.646454416438622]
Epoch: 4899  loss: 60.265935724706765
Learned parameters: [2.1370448034584055, 3.8207750726931904, 5.735786275046098, -2.6465579164896944]
Epoch: 4900  loss: 60.26545385775193
Learned parameters: [2.1370069115653947, 3.820827953251646, 5.735862456588094, -2.646661296890373]
Epoch: 4901  loss: 60.264973349186064
Learned parameters: [2.136969063430182, 3.82088077259421, 5.735938550103315, -2.646764557709731]
Epoch: 4902  loss: 60.26449419582023
Learned parameters: [2.1369312590276865, 3.8209335307564025, 5.736014555642337, -2.64686769901687]
Epoch: 4903  loss: 60.26401639447472
Learned parameters: [2.1368934983328454, 3.820986227773749, 5.7360904732558025, -2.6469707208809283]
Epoch: 4904  loss: 60.263539941980966
Learned parameters: [2.1368557813205484, 3.8210388636818013, 5.7361663029943255, -2.6470736233710705]
Epoch: 4905  loss: 60.263064835163256
Learned parameters: [2.1368181079656727, 3.821091438516124, 5.736242044908545, -2.647176406556493]
Epoch: 4906  loss: 60.26259107086438
Learned parameters: [2.1367804782431348, 3.821143952312285, 5.736317699049194, -2.6472790705064306]
Epoch: 4907  loss: 60.26211864592754
Learned parameters: [2.1367428921277782, 3.8211964051058827, 5.736393265466946, -2.6473816152901426]
Epoch: 4908  loss: 60.261647557196895
Learned parameters: [2.136705349594453, 3.8212487969325255, 5.7364687442125195, -2.647484040976921]
Epoch: 4909  loss: 60.261177801531225
Learned parameters: [2.1366678506180445, 3.821301127827826, 5.736544135336727, -2.6475863476360963]
Epoch: 4910  loss: 60.26070937579094
Learned parameters: [2.1366303951733436, 3.8213533978274334, 5.736619438890287, -2.6476885353370188]
Epoch: 4911  loss: 60.26024227684127
Learned parameters: [2.1365929832351807, 3.821405606966999, 5.7366946549240145, -2.647790604149076]
Epoch: 4912  loss: 60.25977650155501
Learned parameters: [2.13655561477838, 3.821457755282188, 5.736769783488756, -2.647892554141689]
Epoch: 4913  loss: 60.25931204680809
Learned parameters: [2.136518289777728, 3.8215098428086884, 5.736844824635345, -2.6479943853843055]
Epoch: 4914  loss: 60.25884890948633
Learned parameters: [2.136481008207997, 3.8215618695822045, 5.736919778414635, -2.648096097946403]
Epoch: 4915  loss: 60.25838708647797
Learned parameters: [2.136443770044025, 3.8216138356385105, 5.736994644877656, -2.6481976918975016]
Epoch: 4916  loss: 60.257926574674194
Learned parameters: [2.1364065752605197, 3.821665741013607, 5.737069424075398, -2.64829916730713]
Epoch: 4917  loss: 60.25746737097342
Learned parameters: [2.1363694238321025, 3.8217175857434977, 5.7371441160587535, -2.6484005242448414]
Epoch: 4918  loss: 60.25700947227986
Learned parameters: [2.136332315733618, 3.821769369864054, 5.73721872087892, -2.6485017627802505]
Epoch: 4919  loss: 60.25655287550869
Learned parameters: [2.1362952509397672, 3.8218210934111547, 5.737293238586911, -2.648602882982989]
Epoch: 4920  loss: 60.25609757757731
Learned parameters: [2.13625822942517, 3.8218727564206945, 5.737367669233666, -2.6487038849227154]
Epoch: 4921  loss: 60.255643575408214
Learned parameters: [2.136221251164618, 3.8219243589285234, 5.737442012870399, -2.6488047686691543]
Epoch: 4922  loss: 60.25519086593124
Learned parameters: [2.136184316132762, 3.8219759009705214, 5.737516269548165, -2.6489055342920493]
Epoch: 4923  loss: 60.25473944607937
Learned parameters: [2.1361474243042062, 3.8220273825825757, 5.73759043931799, -2.649006181861175]
Epoch: 4924  loss: 60.25428931279319
Learned parameters: [2.1361105756536842, 3.8220788038005313, 5.737664522231105, -2.649106711446357]
Epoch: 4925  loss: 60.253840463022215
Learned parameters: [2.1360737701558317, 3.822130164660229, 5.7377385183386185, -2.6492071231174275]
Epoch: 4926  loss: 60.25339289371543
Learned parameters: [2.13603700778524, 3.822181465197526, 5.7378124276916145, -2.649307416944249]
Epoch: 4927  loss: 60.25294660183122
Learned parameters: [2.13600028851659, 3.8222327054482625, 5.737886250341341, -2.6494075929967362]
Epoch: 4928  loss: 60.252501584332954
Learned parameters: [2.135963612324482, 3.822283885448307, 5.737959986338976, -2.649507651344828]
Epoch: 4929  loss: 60.25205783818981
Learned parameters: [2.1359269791834836, 3.8223350052335454, 5.738033635735685, -2.649607592058495]
Epoch: 4930  loss: 60.251615360373805
Learned parameters: [2.135890389068228, 3.822386064839857, 5.738107198582769, -2.649707415207752]
Epoch: 4931  loss: 60.25117414786507
Learned parameters: [2.1358538419532986, 3.8224370643031467, 5.738180674931497, -2.649807120862641]
Epoch: 4932  loss: 60.250734197651845
Learned parameters: [2.1358173378131964, 3.8224880036593536, 5.738254064833064, -2.6499067090932256]
Epoch: 4933  loss: 60.25029550672261
Learned parameters: [2.135780876622539, 3.822538882944401, 5.738327368338865, -2.6500061799696195]
Epoch: 4934  loss: 60.24985807207406
Learned parameters: [2.1357444583558873, 3.8225897021942408, 5.738400585500256, -2.6501055335619577]
Epoch: 4935  loss: 60.24942189070792
Learned parameters: [2.1357080829876813, 3.8226404614448715, 5.738473716368461, -2.6502047699403897]
Epoch: 4936  loss: 60.24898695963334
Learned parameters: [2.1356717504925182, 3.8226911607322673, 5.738546760994967, -2.650303889175119]
Epoch: 4937  loss: 60.2485532758637
Learned parameters: [2.1356354608449237, 3.822741800092437, 5.738619719431196, -2.650402891336367]
Epoch: 4938  loss: 60.24812083641435
Learned parameters: [2.1355992140193143, 3.822792379561433, 5.738692591728459, -2.6505017764943686]
Epoch: 4939  loss: 60.24768963831287
Learned parameters: [2.1355630099902476, 3.82284289917529, 5.7387653779383, -2.650600544719407]
Epoch: 4940  loss: 60.24725967858792
Learned parameters: [2.1355268487321966, 3.8228933589700795, 5.738838078112187, -2.650699196081782]
Epoch: 4941  loss: 60.246830954275076
Learned parameters: [2.1354907302195745, 3.8229437589819057, 5.738910692301541, -2.6507977306518113]
Epoch: 4942  loss: 60.24640346241759
Learned parameters: [2.1354546544268938, 3.822994099246865, 5.738983220557963, -2.650896148499857]
Epoch: 4943  loss: 60.24597720005885
Learned parameters: [2.1354186213285833, 3.823044379801091, 5.739055662932975, -2.650994449696296]
Epoch: 4944  loss: 60.24555216425123
Learned parameters: [2.13538263089905, 3.823094600680741, 5.739128019478105, -2.6510926343115297]
Epoch: 4945  loss: 60.245128352053634
Learned parameters: [2.135346683112732, 3.823144761921979, 5.739200290244969, -2.6511907024159935]
Epoch: 4946  loss: 60.24470576052924
Learned parameters: [2.135310777944054, 3.823194863560943, 5.739272475285171, -2.6512886540801475]
Epoch: 4947  loss: 60.24428438674698
Learned parameters: [2.1352749153673845, 3.823244905633744, 5.739344574650242, -2.6513864893744716]
Epoch: 4948  loss: 60.24386422778372
Learned parameters: [2.135239095357184, 3.823294888176496, 5.739416588391889, -2.651484208369486]
Epoch: 4949  loss: 60.243445280714894
Learned parameters: [2.135203317887801, 3.823344811225387, 5.739488516561716, -2.651581811135726]
Epoch: 4950  loss: 60.243027542630166
Learned parameters: [2.1351675829336036, 3.8233946748166328, 5.7395603592114, -2.651679297743756]
Epoch: 4951  loss: 60.24261101061454
Learned parameters: [2.1351318904689665, 3.823444478986472, 5.739632116392674, -2.6517766682641697]
Epoch: 4952  loss: 60.242195681769616
Learned parameters: [2.1350962404682337, 3.8234942237711715, 5.739703788157263, -2.6518739227675816]
Epoch: 4953  loss: 60.241781553193114
Learned parameters: [2.135060632905739, 3.823543909207022, 5.7397753745569196, -2.6519710613246326]
Epoch: 4954  loss: 60.241368621993985
Learned parameters: [2.1350250677558162, 3.823593535330335, 5.739846875643438, -2.65206808400599]
Epoch: 4955  loss: 60.2409568852824
Learned parameters: [2.1349895449927665, 3.8236431021774506, 5.739918291468605, -2.652164990882347]
Epoch: 4956  loss: 60.240546340177524
Learned parameters: [2.1349540645909264, 3.823692609784719, 5.739989622084299, -2.652261782024428]
Epoch: 4957  loss: 60.24013698380149
Learned parameters: [2.1349186265245494, 3.823742058188529, 5.740060867542321, -2.652358457502976]
Epoch: 4958  loss: 60.239728813283605
Learned parameters: [2.134883230767941, 3.8237914474252723, 5.7401320278945835, -2.6524550173887698]
Epoch: 4959  loss: 60.23932182575716
Learned parameters: [2.1348478772953845, 3.8238407775313643, 5.74020310319301, -2.652551461752618]
Epoch: 4960  loss: 60.238916018362026
Learned parameters: [2.1348125660810986, 3.823890048543252, 5.7402740934894725, -2.65264779066535]
Epoch: 4961  loss: 60.23851138824161
Learned parameters: [2.1347772970993666, 3.823939260497387, 5.740344998835981, -2.6527440041978423]
Epoch: 4962  loss: 60.2381079325456
Learned parameters: [2.134742070324404, 3.8239884134302478, 5.740415819284488, -2.6528401024209916]
Epoch: 4963  loss: 60.23770564843221
Learned parameters: [2.134706885730439, 3.824037507378323, 5.740486554886998, -2.652936085405728]
Epoch: 4964  loss: 60.237304533059636
Learned parameters: [2.134671743291693, 3.824086542378113, 5.740557205695551, -2.6530319532230116]
Epoch: 4965  loss: 60.23690458359543
Learned parameters: [2.1346366429823433, 3.824135518466139, 5.740627771762159, -2.653127705943829]
Epoch: 4966  loss: 60.23650579720961
Learned parameters: [2.134601584776596, 3.8241844356789243, 5.740698253138914, -2.6532233436392043]
Epoch: 4967  loss: 60.23610817108072
Learned parameters: [2.1345665686486304, 3.824233294053008, 5.74076864987791, -2.653318866380189]
Epoch: 4968  loss: 60.23571170238672
Learned parameters: [2.134531594572605, 3.8242820936249444, 5.740838962031247, -2.653414274237865]
Epoch: 4969  loss: 60.23531638831984
Learned parameters: [2.1344966625226602, 3.824330834431299, 5.74090918965104, -2.653509567283345]
Epoch: 4970  loss: 60.234922226073905
Learned parameters: [2.134461772472971, 3.824379516508637, 5.7409793327894905, -2.6536047455877787]
Epoch: 4971  loss: 60.23452921284249
Learned parameters: [2.1344269243976415, 3.824428139893551, 5.741049391498738, -2.6536998092223403]
Epoch: 4972  loss: 60.23413734583261
Learned parameters: [2.1343921182707986, 3.824476704622635, 5.741119365830991, -2.653794758258239]
Epoch: 4973  loss: 60.23374662225031
Learned parameters: [2.134357354066555, 3.824525210732495, 5.741189255838478, -2.6538895927667157]
Epoch: 4974  loss: 60.2333570393129
Learned parameters: [2.134322631758987, 3.8245736582597534, 5.741259061573413, -2.6539843128190386]
Epoch: 4975  loss: 60.2329685942361
Learned parameters: [2.134287951322215, 3.8246220472410313, 5.74132878308811, -2.6540789184865154]
Epoch: 4976  loss: 60.23258128424935
Learned parameters: [2.13425331273028, 3.8246703777129776, 5.74139842043481, -2.654173409840475]
Epoch: 4977  loss: 60.23219510657678
Learned parameters: [2.1342187159572483, 3.824718649712244, 5.7414679736658245, -2.654267786952282]
Epoch: 4978  loss: 60.231810058460226
Learned parameters: [2.1341841609771968, 3.8247668632754968, 5.7415374428335255, -2.654362049893335]
Epoch: 4979  loss: 60.23142613713427
Learned parameters: [2.1341496477641364, 3.8248150184394505, 5.741606827990242, -2.6544561987350566]
Epoch: 4980  loss: 60.23104333984792
Learned parameters: [2.13411517629208, 3.8248631152408237, 5.741676129188339, -2.654550233548901]
Epoch: 4981  loss: 60.230661663851315
Learned parameters: [2.134080746535077, 3.8249111537163256, 5.741745346480267, -2.654644154406359]
Epoch: 4982  loss: 60.230281106398905
Learned parameters: [2.1340463584670926, 3.8249591339026576, 5.741814479918366, -2.6547379613789324]
Epoch: 4983  loss: 60.22990166475583
Learned parameters: [2.1340120120621657, 3.8250070558365143, 5.741883529555119, -2.6548316545381656]
Epoch: 4984  loss: 60.22952333618925
Learned parameters: [2.1339777072942767, 3.825054919554618, 5.741952495442966, -2.6549252339556264]
Epoch: 4985  loss: 60.229146117967446
Learned parameters: [2.133943444137361, 3.825102725093717, 5.742021377634325, -2.6550186997029095]
Epoch: 4986  loss: 60.228770007373
Learned parameters: [2.1339092225654257, 3.825150472490555, 5.742090176181749, -2.6551120518516496]
Epoch: 4987  loss: 60.228395001684426
Learned parameters: [2.1338750425524196, 3.8251981617819024, 5.74215889113775, -2.655205290473504]
Epoch: 4988  loss: 60.22802109818923
Learned parameters: [2.133840904072249, 3.8252457930045547, 5.742227522554816, -2.655298415640154]
Epoch: 4989  loss: 60.227648294184306
Learned parameters: [2.1338068070988796, 3.825293366195304, 5.742296070485557, -2.6553914274233192]
Epoch: 4990  loss: 60.22727658696267
Learned parameters: [2.133772751606228, 3.8253408813909697, 5.742364534982548, -2.655484325894741]
Epoch: 4991  loss: 60.226905973831066
Learned parameters: [2.133738737568168, 3.825388338628394, 5.742432916098345, -2.6555771111261843]
Epoch: 4992  loss: 60.22653645209712
Learned parameters: [2.1337047649586522, 3.825435737944414, 5.742501213885647, -2.6556697831894547]
Epoch: 4993  loss: 60.22616801907432
Learned parameters: [2.133670833751529, 3.8254830793759056, 5.742569428397047, -2.6557623421563714]
Epoch: 4994  loss: 60.225800672079885
Learned parameters: [2.133636943920668, 3.825530362959753, 5.742637559685203, -2.6558547880987855]
Epoch: 4995  loss: 60.22543440844075
Learned parameters: [2.1336030954399883, 3.825577588732841, 5.74270560780288, -2.6559471210885843]
Epoch: 4996  loss: 60.225069225487154
Learned parameters: [2.1335692882832977, 3.825624756732096, 5.742773572802722, -2.6560393411976677]
Epoch: 4997  loss: 60.22470512054612
Learned parameters: [2.1335355224244315, 3.82567186699445, 5.74284145473745, -2.6561314484979675]
Epoch: 4998  loss: 60.22434209096513
Learned parameters: [2.1335017978372903, 3.8257189195568317, 5.742909253659911, -2.656223443061454]
Epoch: 4999  loss: 60.223980134084826
Learned parameters: [2.133468114495628, 3.8257659144562206, 5.742976969622783, -2.6563153249601044]
Epoch: 5000  loss: 60.2236192472549
Learned parameters: [2.133434472373277, 3.8258128517295873, 5.743044602678893, -2.6564070942659366]
Epoch: 5001  loss: 60.223259427831124
Learned parameters: [2.1334008714440733, 3.8258597314139156, 5.743112152881106, -2.6564987510509974]
Epoch: 5002  loss: 60.22290067317158
Learned parameters: [2.1333673116817695, 3.8259065535462207, 5.743179620282208, -2.65659029538735]
Epoch: 5003  loss: 60.222542980644846
Learned parameters: [2.1333337930601473, 3.825953318163524, 5.743247004935063, -2.656681727347091]
Epoch: 5004  loss: 60.2221863476173
Learned parameters: [2.1333003155530226, 3.82600002530285, 5.743314306892618, -2.656773047002349]
Epoch: 5005  loss: 60.221830771466145
Learned parameters: [2.133266879134102, 3.826046675001265, 5.7433815262077035, -2.65686425442527]
Epoch: 5006  loss: 60.221476249571104
Learned parameters: [2.1332334837771483, 3.8260932672958354, 5.743448662933272, -2.6569553496880385]
Epoch: 5007  loss: 60.22112277931714
Learned parameters: [2.1332001294559264, 3.8261398022236386, 5.74351571712231, -2.657046332862868]
Epoch: 5008  loss: 60.2207703580962
Learned parameters: [2.1331668161441235, 3.8261862798217874, 5.743582688827739, -2.6571372040219896]
Epoch: 5009  loss: 60.220418983298785
Learned parameters: [2.1331335438154855, 3.8262327001274143, 5.743649578102606, -2.657227963237669]
Epoch: 5010  loss: 60.22006865233138
Learned parameters: [2.133100312443712, 3.82627906317767, 5.743716384999931, -2.6573186105821955]
Epoch: 5011  loss: 60.219719362594454
Learned parameters: [2.1330671220024464, 3.826325369009726, 5.743783109572685, -2.657409146127879]
Epoch: 5012  loss: 60.21937111150159
Learned parameters: [2.133033972465471, 3.8263716176607923, 5.743849751874113, -2.6574995699470847]
Epoch: 5013  loss: 60.21902389646573
Learned parameters: [2.1330008638063602, 3.8264178091681487, 5.743916311957209, -2.6575898821121777]
Epoch: 5014  loss: 60.21867771490844
Learned parameters: [2.1329677959987468, 3.826463943569058, 5.7439827898750755, -2.657680082695562]
Epoch: 5015  loss: 60.21833256425134
Learned parameters: [2.132934769016393, 3.826510020900742, 5.7440491856810265, -2.65777017176969]
Epoch: 5016  loss: 60.217988441928426
Learned parameters: [2.1329017828328203, 3.8265560412004653, 5.744115499428054, -2.6578601494070067]
Epoch: 5017  loss: 60.217645345379495
Learned parameters: [2.1328688374216815, 3.8266020045054603, 5.74418173116937, -2.6579500156800058]
Epoch: 5018  loss: 60.217303272038166
Learned parameters: [2.13283593275666, 3.826647910852953, 5.744247880958256, -2.658039770661219]
Epoch: 5019  loss: 60.2169622193548
Learned parameters: [2.132803068811277, 3.8266937602802136, 5.744313948847807, -2.658129414423186]
Epoch: 5020  loss: 60.21662218477866
Learned parameters: [2.132770245559152, 3.8267395528244927, 5.744379934891286, -2.6582189470384945]
Epoch: 5021  loss: 60.21628316576468
Learned parameters: [2.132737462973928, 3.8267852885230393, 5.744445839142023, -2.6583083685797653]
Epoch: 5022  loss: 60.215945159773455
Learned parameters: [2.1327047210290795, 3.826830967413149, 5.744511661653145, -2.6583976791196253]
Epoch: 5023  loss: 60.21560816427266
Learned parameters: [2.1326720196982367, 3.8268765895320827, 5.744577402478029, -2.6584868787307543]
Epoch: 5024  loss: 60.2152721767321
Learned parameters: [2.132639358954968, 3.8269221549171233, 5.74464306167, -2.6585759674858522]
Epoch: 5025  loss: 60.21493719462612
Learned parameters: [2.132606738772734, 3.826967663605588, 5.744708639282261, -2.6586649454576325]
Epoch: 5026  loss: 60.21460321543521
Learned parameters: [2.1325741591251584, 3.8270131156347604, 5.744774135368281, -2.6587538127188615]
Epoch: 5027  loss: 60.214270236649234
Learned parameters: [2.132541619985729, 3.827058511041967, 5.744839549981369, -2.658842569342313]
Epoch: 5028  loss: 60.213938255751714
Learned parameters: [2.1325091213279253, 3.827103849864545, 5.744904883174854, -2.6589312154007874]
Epoch: 5029  loss: 60.21360727024445
Learned parameters: [2.132476663125332, 3.827149132139817, 5.744970135002249, -2.6590197509671287]
Epoch: 5030  loss: 60.213277277624634
Learned parameters: [2.132444245351367, 3.8271943579051553, 5.745035305516862, -2.659108176114183]
Epoch: 5031  loss: 60.2129482753995
Learned parameters: [2.132411867979544, 3.827239527197922, 5.745100394772173, -2.6591964909148365]
Epoch: 5032  loss: 60.21262026107494
Learned parameters: [2.132379530983359, 3.8272846400554936, 5.745165402821666, -2.6592846954419995]
Epoch: 5033  loss: 60.21229323216923
Learned parameters: [2.1323472343362386, 3.827329696515277, 5.745230329718763, -2.659372789768598]
Epoch: 5034  loss: 60.211967186204014
Learned parameters: [2.132314978011669, 3.8273746966146764, 5.745295175517002, -2.6594607739675924]
Epoch: 5035  loss: 60.21164212070234
Learned parameters: [2.132282761983093, 3.827419640391119, 5.745359940269895, -2.6595486481119623]
Epoch: 5036  loss: 60.21131803319152
Learned parameters: [2.132250586223907, 3.827464527882057, 5.74542462403092, -2.6596364122747063]
Epoch: 5037  loss: 60.210994921209746
Learned parameters: [2.132218450707616, 3.8275093591249285, 5.745489226853739, -2.659724066528864]
Epoch: 5038  loss: 60.210672782296854
Learned parameters: [2.132186355407571, 3.827554134157223, 5.745553748791836, -2.659811610947477]
Epoch: 5039  loss: 60.21035161399513
Learned parameters: [2.1321543002971795, 3.827598853016428, 5.745618189898803, -2.659899045603621]
Epoch: 5040  loss: 60.210031413852946
Learned parameters: [2.132122285349915, 3.8276435157400295, 5.74568255022836, -2.6599863705704068]
Epoch: 5041  loss: 60.20971217942804
Learned parameters: [2.132090310539082, 3.8276881223655677, 5.7457468298340215, -2.660073585920945]
Epoch: 5042  loss: 60.20939390827673
Learned parameters: [2.1320583758380742, 3.8277326729305727, 5.745811028769463, -2.660160691728384]
Epoch: 5043  loss: 60.209076597964156
Learned parameters: [2.132026481220376, 3.82777716747268, 5.745875147088583, -2.6602476880659105]
Epoch: 5044  loss: 60.20876024605377
Learned parameters: [2.1319946266591536, 3.8278216060297137, 5.745939184844924, -2.6603345750066874]
Epoch: 5045  loss: 60.208444850119264
Learned parameters: [2.1319628121278043, 3.827865988639427, 5.746003142092374, -2.660421352623941]
Epoch: 5046  loss: 60.208130407736206
Learned parameters: [2.131931037599719, 3.82791031533956, 5.746067018884836, -2.6605080209909273]
Epoch: 5047  loss: 60.20781691649177
Learned parameters: [2.1318993030480677, 3.8279545861678526, 5.746130815275897, -2.6605945801808963]
Epoch: 5048  loss: 60.20750437397365
Learned parameters: [2.1318676084462957, 3.827998801161948, 5.746194531319546, -2.6606810302671673]
Epoch: 5049  loss: 60.20719277777194
Learned parameters: [2.131835953767689, 3.828042960359523, 5.746258167069574, -2.6607673713230695]
Epoch: 5050  loss: 60.2068821254862
Learned parameters: [2.131804338985447, 3.828087063798272, 5.746321722579686, -2.660853603421952]
Epoch: 5051  loss: 60.206572414718856
Learned parameters: [2.131772764072974, 3.828131111515841, 5.746385197903903, -2.660939726637227]
Epoch: 5052  loss: 60.20626364307739
Learned parameters: [2.1317412290034756, 3.828175103549925, 5.746448593096002, -2.6610257410423115]
Epoch: 5053  loss: 60.205955808169534
Learned parameters: [2.131709733750205, 3.8282190399382054, 5.746511908209852, -2.6611116467106584]
Epoch: 5054  loss: 60.205648907616755
Learned parameters: [2.1316782782864476, 3.828262920718356, 5.746575143299402, -2.6611974437157566]
Epoch: 5055  loss: 60.2053429390386
Learned parameters: [2.1316468625854488, 3.828306745928061, 5.74663829841857, -2.661283132131118]
Epoch: 5056  loss: 60.205037900059324
Learned parameters: [2.1316154866203907, 3.8283505156050244, 5.746701373621218, -2.6613687120302747]
Epoch: 5057  loss: 60.20473378831299
Learned parameters: [2.1315841503645583, 3.828394229786901, 5.746764368961356, -2.6614541834867835]
Epoch: 5058  loss: 60.20443060143441
Learned parameters: [2.1315528537911685, 3.8284378885113637, 5.746827284492926, -2.6615395465742155]
Epoch: 5059  loss: 60.2041283370659
Learned parameters: [2.1315215968733803, 3.8284814918161105, 5.746890120269818, -2.6616248013661616]
Epoch: 5060  loss: 60.20382699284969
Learned parameters: [2.1314903795844606, 3.8285250397388237, 5.74695287634611, -2.6617099479362563]
Epoch: 5061  loss: 60.203526566435784
Learned parameters: [2.1314592018975773, 3.828568532317223, 5.74701555277577, -2.661794986358146]
Epoch: 5062  loss: 60.20322705548409
Learned parameters: [2.131428063785893, 3.828611969589043, 5.747078149612793, -2.661879916705502]
Epoch: 5063  loss: 60.20292845764838
Learned parameters: [2.1313969652226157, 3.8286553515920203, 5.747140666911269, -2.661964739052028]
Epoch: 5064  loss: 60.20263077059443
Learned parameters: [2.1313659061809003, 3.8286986783639203, 5.747203104725245, -2.6620494534714436]
Epoch: 5065  loss: 60.202333991992575
Learned parameters: [2.1313348866338875, 3.8287419499425264, 5.747265463108781, -2.6621340600374914]
Epoch: 5066  loss: 60.20203811951262
Learned parameters: [2.131303906554744, 3.8287851663656314, 5.7473277421160045, -2.6622185588239407]
Epoch: 5067  loss: 60.20174315083521
Learned parameters: [2.1312729659165996, 3.8288283276710526, 5.747389941801021, -2.662302949904578]
Epoch: 5068  loss: 60.201449083642316
Learned parameters: [2.1312420646925876, 3.828871433896622, 5.7474520622179766, -2.6623872333532144]
Epoch: 5069  loss: 60.20115591562187
Learned parameters: [2.131211202855832, 3.828914485080191, 5.747514103421034, -2.662471409243682]
Epoch: 5070  loss: 60.20086364446723
Learned parameters: [2.131180380379426, 3.828957481259633, 5.747576065464346, -2.662555477649833]
Epoch: 5071  loss: 60.200572267871905
Learned parameters: [2.131149597236504, 3.829000422472827, 5.747637948402157, -2.662639438645546]
Epoch: 5072  loss: 60.2002817835392
Learned parameters: [2.1311188534001335, 3.8290433087576843, 5.7476997522886455, -2.6627232923047144]
Epoch: 5073  loss: 60.19999218917438
Learned parameters: [2.131088148843403, 3.829086140152124, 5.747761477178053, -2.662807038701255]
Epoch: 5074  loss: 60.19970348249026
Learned parameters: [2.1310574835394176, 3.8291289166940747, 5.747823123124677, -2.662890677909111]
Epoch: 5075  loss: 60.199415661203005
Learned parameters: [2.131026857461195, 3.8291716384215015, 5.747884690182722, -2.662974210002235]
Epoch: 5076  loss: 60.19912872302537
Learned parameters: [2.1309962705818193, 3.8292143053723646, 5.747946178406518, -2.663057635054612]
Epoch: 5077  loss: 60.19884266568916
Learned parameters: [2.130965722874381, 3.8292569175846363, 5.748007587850436, -2.6631409531402515]
Epoch: 5078  loss: 60.19855748692115
Learned parameters: [2.1309352143118216, 3.8292994750963367, 5.748068918568671, -2.663224164333165]
Epoch: 5079  loss: 60.19827318445448
Learned parameters: [2.1309047448672613, 3.829341977945443, 5.748130170615691, -2.6633072687074124]
Epoch: 5080  loss: 60.19798975602939
Learned parameters: [2.1308743145136724, 3.829384426169889, 5.748191344045734, -2.6633902663370557]
Epoch: 5081  loss: 60.19770719938904
Learned parameters: [2.1308439232241247, 3.829426819807605, 5.748252438913215, -2.6634731572961936]
Epoch: 5082  loss: 60.19742551228317
Learned parameters: [2.1308135709715907, 3.82946915889657, 5.748313455272446, -2.663555941658934]
Epoch: 5083  loss: 60.19714469246203
Learned parameters: [2.1307832577291053, 3.8295114434747686, 5.748374393177863, -2.6636386194994155]
Epoch: 5084  loss: 60.196864737684145
Learned parameters: [2.1307529834696655, 3.829553673580236, 5.748435252683898, -2.6637211908917973]
Epoch: 5085  loss: 60.19658564570797
Learned parameters: [2.1307227481661837, 3.8295958492510502, 5.748496033844901, -2.663803655910249]
Epoch: 5086  loss: 60.19630741430017
Learned parameters: [2.130692551791727, 3.829637970525269, 5.74855673671547, -2.663886014628985]
Epoch: 5087  loss: 60.19603004123222
Learned parameters: [2.130662394319209, 3.8296800374410034, 5.7486173613500196, -2.663968267122219]
Epoch: 5088  loss: 60.19575352427902
Learned parameters: [2.1306322757215415, 3.8297220500363798, 5.748677907802995, -2.6640504134641882]
Epoch: 5089  loss: 60.19547786121944
Learned parameters: [2.130602195971762, 3.829764008349506, 5.748738376129049, -2.6641324537291706]
Epoch: 5090  loss: 60.19520304983873
Learned parameters: [2.1305721550427545, 3.8298059124185424, 5.74879876638265, -2.6642143879914455]
Epoch: 5091  loss: 60.19492908792346
Learned parameters: [2.130542152907418, 3.829847762281658, 5.748859078618317, -2.6642962163253183]
Epoch: 5092  loss: 60.194655973268205
Learned parameters: [2.130512189538747, 3.8298895579770087, 5.748919312890736, -2.664377938805133]
Epoch: 5093  loss: 60.19438370367065
Learned parameters: [2.1304822649095843, 3.8299312995428, 5.748979469254414, -2.6644595555052364]
Epoch: 5094  loss: 60.194112276931264
Learned parameters: [2.130452378992847, 3.829972987017229, 5.749039547763989, -2.66454106650001]
Epoch: 5095  loss: 60.193841690856786
Learned parameters: [2.130422531761464, 3.830014620438499, 5.749099548474146, -2.664622471863864]
Epoch: 5096  loss: 60.19357194326229
Learned parameters: [2.130392723188252, 3.83005619984485, 5.749159471439448, -2.6647037716712165]
Epoch: 5097  loss: 60.19330303196091
Learned parameters: [2.1303629532461215, 3.830097725274506, 5.7492193167146155, -2.664784965996526]
Epoch: 5098  loss: 60.19303495476917
Learned parameters: [2.1303332219079656, 3.8301391967657046, 5.749279084354376, -2.6648660549142735]
Epoch: 5099  loss: 60.19276770951791
Learned parameters: [2.130303529146549, 3.830180614356721, 5.749338774413308, -2.6649470384989487]
Epoch: 5100  loss: 60.19250129403151
Learned parameters: [2.1302738749348222, 3.8302219780857962, 5.749398386946285, -2.665027916825095]
Epoch: 5101  loss: 60.19223570614401
Learned parameters: [2.130244259245546, 3.8302632879912286, 5.749457922007946, -2.66510868996726]
Epoch: 5102  loss: 60.1919709436944
Learned parameters: [2.1302146820515526, 3.830304544111305, 5.749517379653061, -2.6651893580000254]
Epoch: 5103  loss: 60.191707004524375
Learned parameters: [2.1301851433257193, 3.8303457464843063, 5.7495767599364935, -2.665269920998006]
Epoch: 5104  loss: 60.19144388648367
Learned parameters: [2.130155643040759, 3.83038689514856, 5.749636062912905, -2.665350379035819]
Epoch: 5105  loss: 60.191181587419514
Learned parameters: [2.1301261811695418, 3.83042799014236, 5.749695288637206, -2.665430732188127]
Epoch: 5106  loss: 60.19092010518752
Learned parameters: [2.130096757684842, 3.830469031504029, 5.749754437164201, -2.6655109805296076]
Epoch: 5107  loss: 60.19065943765083
Learned parameters: [2.130067372559408, 3.8305100192719035, 5.749813508548691, -2.6655911241349575]
Epoch: 5108  loss: 60.19039958267346
Learned parameters: [2.1300380257660487, 3.8305509534843094, 5.749872502845587, -2.6656711630789083]
Epoch: 5109  loss: 60.19014053812247
Learned parameters: [2.1300087172775175, 3.8305918341795935, 5.749931420109754, -2.6657510974362078]
Epoch: 5110  loss: 60.1898823018723
Learned parameters: [2.1299794470665496, 3.830632661396113, 5.749990260396057, -2.6658309272816263]
Epoch: 5111  loss: 60.18962487180181
Learned parameters: [2.12995021510591, 3.8306734351722245, 5.750049023759435, -2.6659106526899627]
Epoch: 5112  loss: 60.18936824581656
Learned parameters: [2.1299210213689133, 3.8307141555468274, 5.750107710254376, -2.6659902737344954]
Epoch: 5113  loss: 60.18911242178491
Learned parameters: [2.129891865827818, 3.8307548225583306, 5.750166319935292, -2.6660697904901727]
Epoch: 5114  loss: 60.18885739759733
Learned parameters: [2.129862748455867, 3.8307954362448973, 5.750224852857995, -2.666149203032102]
Epoch: 5115  loss: 60.1886031711417
Learned parameters: [2.129833669225405, 3.8308359966449173, 5.750283309077057, -2.666228511435278]
Epoch: 5116  loss: 60.18834974032412
Learned parameters: [2.129804628108969, 3.8308765037967367, 5.750341688647339, -2.6663077157747375]
Epoch: 5117  loss: 60.188097103043276
Learned parameters: [2.12977562507966, 3.8309169577385718, 5.750399991624513, -2.6663868161256135]
Epoch: 5118  loss: 60.18784525721348
Learned parameters: [2.129746660109687, 3.8309573585088983, 5.750458218063034, -2.6664658125629255]
Epoch: 5119  loss: 60.187594200740136
Learned parameters: [2.129717733171835, 3.8309977061460674, 5.750516368018193, -2.6665447051617894]
Epoch: 5120  loss: 60.18734393154417
Learned parameters: [2.129688844238926, 3.831038000688433, 5.7505744415453455, -2.666623493997339]
Epoch: 5121  loss: 60.187094447546976
Learned parameters: [2.1296599932832514, 3.8310782421744918, 5.750632438699125, -2.6667021791446452]
Epoch: 5122  loss: 60.18684574667233
Learned parameters: [2.1296311802776846, 3.8311184306426114, 5.750690359535, -2.6667807606788747]
Epoch: 5123  loss: 60.186597826853024
Learned parameters: [2.1296024051948255, 3.8311585661312053, 5.7507482041080475, -2.6668592386751593]
Epoch: 5124  loss: 60.18635068602047
Learned parameters: [2.129573668007123, 3.831198648678746, 5.7508059724731595, -2.6669376132086233]
Epoch: 5125  loss: 60.186104322114716
Learned parameters: [2.1295449686874286, 3.831238678323625, 5.750863664685812, -2.6670158843544614]
Epoch: 5126  loss: 60.185858733081155
Learned parameters: [2.129516307208207, 3.8312786551043523, 5.750921280800964, -2.6670940521878252]
Epoch: 5127  loss: 60.18561391686309
Learned parameters: [2.12948768354202, 3.831318579059433, 5.750978820873732, -2.667172116783895]
Epoch: 5128  loss: 60.185369871415055
Learned parameters: [2.1294590976616576, 3.831358450227337, 5.751036284959578, -2.6672500782178963]
Epoch: 5129  loss: 60.18512659469462
Learned parameters: [2.1294305495395007, 3.8313982686466566, 5.751093673113415, -2.6673279365650098]
Epoch: 5130  loss: 60.18488408465777
Learned parameters: [2.1294020391482267, 3.8314380343559287, 5.751150985390594, -2.667405691900472]
Epoch: 5131  loss: 60.184642339270965
Learned parameters: [2.12937356646048, 3.8314777473937163, 5.751208221846446, -2.6674833442995296]
Epoch: 5132  loss: 60.1844013565024
Learned parameters: [2.129345131448666, 3.8315174077986582, 5.75126538253599, -2.6675608938374094]
Epoch: 5133  loss: 60.18416113432581
Learned parameters: [2.129316734085508, 3.8315570156093313, 5.751322467514717, -2.667638340589399]
Epoch: 5134  loss: 60.18392167071885
Learned parameters: [2.1292883743435174, 3.83159657086438, 5.751379476837845, -2.6677156846307724]
Epoch: 5135  loss: 60.18368296366289
Learned parameters: [2.1292600521951615, 3.8316360736024735, 5.751436410560558, -2.6677929260368134]
Epoch: 5136  loss: 60.183445011142744
Learned parameters: [2.129231767613142, 3.831675523862236, 5.751493268738394, -2.667870064882857]
Epoch: 5137  loss: 60.183207811149444
Learned parameters: [2.129203520569855, 3.83171492168238, 5.751550051426491, -2.667947101244214]
Epoch: 5138  loss: 60.18297136167503
Learned parameters: [2.129175311037871, 3.8317542671015854, 5.751606758680255, -2.668024035196239]
Epoch: 5139  loss: 60.18273566072142
Learned parameters: [2.129147138989796, 3.831793560158533, 5.751663390555172, -2.6681008668143105]
Epoch: 5140  loss: 60.182500706290774
Learned parameters: [2.1291190043979964, 3.831832800891972, 5.751719947106417, -2.668177596173792]
Epoch: 5141  loss: 60.182266496389246
Learned parameters: [2.1290909072350788, 3.8318719893406, 5.751776428389527, -2.6682542233501025]
Epoch: 5142  loss: 60.182033029026016
Learned parameters: [2.129062847473553, 3.831911125543145, 5.7518328344599325, -2.6683307484186676]
Epoch: 5143  loss: 60.18180030222074
Learned parameters: [2.1290348250858058, 3.831950209538373, 5.751889165372917, -2.6684071714549167]
Epoch: 5144  loss: 60.18156831398948
Learned parameters: [2.1290068400444224, 3.831989241365005, 5.751945421184069, -2.668483492534329]
Epoch: 5145  loss: 60.18133706235639
Learned parameters: [2.1289788923218627, 3.8320282210618006, 5.752001601948826, -2.6685597117323883]
Epoch: 5146  loss: 60.18110654535262
Learned parameters: [2.128950981890502, 3.832067148667544, 5.7520577077225346, -2.6686358291245877]
Epoch: 5147  loss: 60.180876761006516
Learned parameters: [2.1289231087229306, 3.8321060242209706, 5.75211373856087, -2.6687118447864746]
Epoch: 5148  loss: 60.18064770735664
Learned parameters: [2.128895272791507, 3.832144847760879, 5.752169694519207, -2.6687877587935853]
Epoch: 5149  loss: 60.18041938243985
Learned parameters: [2.128867474068667, 3.8321836193260523, 5.752225575653055, -2.6688635712214905]
Epoch: 5150  loss: 60.180191784308064
Learned parameters: [2.128839712526944, 3.832222338955254, 5.752281382018086, -2.6689392821457973]
Epoch: 5151  loss: 60.1799649110024
Learned parameters: [2.128811988138633, 3.8322610066873106, 5.752337113669662, -2.669014891642102]
Epoch: 5152  loss: 60.17973876057949
Learned parameters: [2.128784300876224, 3.8322996225610053, 5.752392770663446, -2.669090399786052]
Epoch: 5153  loss: 60.17951333109648
Learned parameters: [2.128756650712174, 3.832338186615139, 5.752448353055082, -2.6691658066533117]
Epoch: 5154  loss: 60.179288620612006
Learned parameters: [2.128729037618738, 3.832376698888577, 5.75250386089996, -2.669241112319539]
Epoch: 5155  loss: 60.17906462719492
Learned parameters: [2.1287014615684665, 3.832415159420115, 5.752559294253911, -2.6693163168604586]
Epoch: 5156  loss: 60.1788413489136
Learned parameters: [2.128673922533661, 3.832453568248619, 5.7526146531724445, -2.669391420351786]
Epoch: 5157  loss: 60.1786187838395
Learned parameters: [2.1286464204866813, 3.8324919254129437, 5.752669937711177, -2.6694664228692666]
Epoch: 5158  loss: 60.17839693005165
Learned parameters: [2.1286189553999795, 3.832530230951937, 5.752725147925886, -2.669541324488683]
Epoch: 5159  loss: 60.178175785632206
Learned parameters: [2.1285915272458356, 3.8325684849045407, 5.752780283872159, -2.6696161252858195]
Epoch: 5160  loss: 60.17795534866468
Learned parameters: [2.1285641359965983, 3.8326066873096774, 5.752835345605705, -2.6696908253364904]
Epoch: 5161  loss: 60.17773561723896
Learned parameters: [2.1285367816247023, 3.832644838206245, 5.75289033318237, -2.6697654247165445]
Epoch: 5162  loss: 60.177516589451926
Learned parameters: [2.1285094641023354, 3.8326829376332, 5.752945246657676, -2.6698399235018173]
Epoch: 5163  loss: 60.17729826339709
Learned parameters: [2.1284821834019305, 3.8327209856294364, 5.753000086087509, -2.6699143217682013]
Epoch: 5164  loss: 60.177080637182414
Learned parameters: [2.1284549394958217, 3.832758982233851, 5.753054851527623, -2.66998861959159]
Epoch: 5165  loss: 60.17686370890894
Learned parameters: [2.128427732356204, 3.832796927485376, 5.7531095430336014, -2.6700628170478793]
Epoch: 5166  loss: 60.176647476689425
Learned parameters: [2.128400561955552, 3.8328348214228782, 5.753164160661441, -2.670136914213025]
Epoch: 5167  loss: 60.1764319386391
Learned parameters: [2.128373428266045, 3.8328726640853006, 5.75321870446675, -2.6702109111629637]
Epoch: 5168  loss: 60.17621709287791
Learned parameters: [2.12834633126, 3.8329104555115565, 5.753273174505349, -2.6702848079736703]
Epoch: 5169  loss: 60.17600293752289
Learned parameters: [2.1283192709097785, 3.832948195740554, 5.753327570833148, -2.670358604721147]
Epoch: 5170  loss: 60.175789470703705
Learned parameters: [2.128292247187546, 3.8329858848112592, 5.753381893505808, -2.67043230148139]
Epoch: 5171  loss: 60.17557669055211
Learned parameters: [2.1282652600656675, 3.833023522762596, 5.753436142579291, -2.670505898330441]
Epoch: 5172  loss: 60.17536459520186
Learned parameters: [2.1282383095163713, 3.8330611096335283, 5.7534903181093915, -2.670579395344343]
Epoch: 5173  loss: 60.175153182791306
Learned parameters: [2.1282113955119, 3.8330986454630236, 5.753544420151946, -2.670652792599158]
Epoch: 5174  loss: 60.174942451462684
Learned parameters: [2.1281845180245615, 3.833136130290041, 5.753598448762905, -2.6707260901709744]
Epoch: 5175  loss: 60.17473239936367
Learned parameters: [2.1281576770265462, 3.8331735641535776, 5.753652403998078, -2.6707992881358824]
Epoch: 5176  loss: 60.17452302464389
Learned parameters: [2.128130872490103, 3.833210947092624, 5.753706285913377, -2.670872386569997]
Epoch: 5177  loss: 60.17431432546015
Learned parameters: [2.12810410438753, 3.8332482791461677, 5.753760094564807, -2.670945385549458]
Epoch: 5178  loss: 60.174106299967455
Learned parameters: [2.128077372690934, 3.833285560353252, 5.753813830008126, -2.6710182851503927]
Epoch: 5179  loss: 60.17389894633101
Learned parameters: [2.12805067737266, 3.8333227907528693, 5.75386749229945, -2.67109108544898]
Epoch: 5180  loss: 60.17369226271943
Learned parameters: [2.1280240184048513, 3.833359970384073, 5.75392108149463, -2.6711637865213858]
Epoch: 5181  loss: 60.17348624729732
Learned parameters: [2.1279973957597025, 3.833397099285912, 5.753974597649616, -2.6712363884438006]
Epoch: 5182  loss: 60.173280898245025
Learned parameters: [2.127970809409507, 3.833434177497421, 5.754028040820518, -2.671308891292446]
Epoch: 5183  loss: 60.17307621373796
Learned parameters: [2.1279442593263287, 3.833471205057701, 5.754081411063146, -2.6713812951435263]
Epoch: 5184  loss: 60.172872191958675
Learned parameters: [2.127917745482458, 3.833508182005805, 5.754134708433649, -2.671453600073296]
Epoch: 5185  loss: 60.172668831099486
Learned parameters: [2.127891267850069, 3.8335451083808243, 5.754187932988037, -2.6715258061580087]
Epoch: 5186  loss: 60.17246612934241
Learned parameters: [2.1278648264012543, 3.8335819842218806, 5.754241084782226, -2.6715979134739234]
Epoch: 5187  loss: 60.17226408488373
Learned parameters: [2.1278384211082924, 3.8336188095680566, 5.754294163872418, -2.6716699220973426]
Epoch: 5188  loss: 60.172062695923884
Learned parameters: [2.127812051943281, 3.83365558445849, 5.754347170314579, -2.67174183210456]
Epoch: 5189  loss: 60.17186196066733
Learned parameters: [2.1277857188783686, 3.8336923089323123, 5.754400104164775, -2.671813643571893]
Epoch: 5190  loss: 60.17166187731439
Learned parameters: [2.12775942188577, 3.833728983028648, 5.75445296547918, -2.6718853565756855]
Epoch: 5191  loss: 60.171462444078344
Learned parameters: [2.1277331609375563, 3.833765606786665, 5.754505754313792, -2.6719569711922784]
Epoch: 5192  loss: 60.17126365917279
Learned parameters: [2.127706936005906, 3.8338021802455113, 5.754558470724783, -2.6720284874980447]
Epoch: 5193  loss: 60.17106552081674
Learned parameters: [2.1276807470629495, 3.833838703444355, 5.754611114768277, -2.672099905569368]
Epoch: 5194  loss: 60.17086802722838
Learned parameters: [2.127654594080787, 3.8338751764223784, 5.754663686500378, -2.672171225482645]
Epoch: 5195  loss: 60.17067117663494
Learned parameters: [2.127628477031566, 3.833911599218759, 5.754716185977279, -2.6722424473142965]
Epoch: 5196  loss: 60.17047496726768
Learned parameters: [2.127602395887437, 3.8339479718728446, 5.754768613255292, -2.6723135711407573]
Epoch: 5197  loss: 60.17027939735589
Learned parameters: [2.1275763506203225, 3.8339842944240514, 5.754820968390436, -2.6723845970384494]
Epoch: 5198  loss: 60.170084465135986
Learned parameters: [2.1275503412024745, 3.8340205669116973, 5.754873251439204, -2.672455525083863]
Epoch: 5199  loss: 60.169890168849
Learned parameters: [2.127524367605907, 3.834056789375144, 5.754925462457766, -2.6725263553534755]
Epoch: 5200  loss: 60.16969650674052
Learned parameters: [2.1274984298026216, 3.8340929618537394, 5.7549776015022935, -2.672597087923787]
Epoch: 5201  loss: 60.16950347705776
Learned parameters: [2.1274725277648288, 3.834129084386756, 5.755029668629255, -2.672667722871349]
Epoch: 5202  loss: 60.16931107805687
Learned parameters: [2.1274466614644694, 3.8341651570134787, 5.755081663894731, -2.6727382602726926]
Epoch: 5203  loss: 60.169119307992084
Learned parameters: [2.1274208308736426, 3.834201179773144, 5.755133587355044, -2.6728087002043956]
Epoch: 5204  loss: 60.16892816512407
Learned parameters: [2.1273950359644633, 3.834237152704981, 5.755185439066557, -2.6728790427430607]
Epoch: 5205  loss: 60.168737647719226
Learned parameters: [2.127369276708849, 3.834273075848261, 5.755237219085376, -2.6729492879652845]
Epoch: 5206  loss: 60.16854775404117
Learned parameters: [2.127343553078954, 3.834308949242195, 5.755288927467955, -2.673019435947719]
Epoch: 5207  loss: 60.16835848236289
Learned parameters: [2.127317865046786, 3.834344772926032, 5.7553405642705675, -2.673089486767016]
Epoch: 5208  loss: 60.16816983096149
Learned parameters: [2.127292212584278, 3.834380546939043, 5.755392129549404, -2.6731594404998384]
Epoch: 5209  loss: 60.16798179811694
Learned parameters: [2.127266595663602, 3.8344162713204417, 5.755443623361006, -2.673229297222901]
Epoch: 5210  loss: 60.16779438211132
Learned parameters: [2.127241014256652, 3.8344519461095126, 5.755495045761546, -2.673299057012896]
Epoch: 5211  loss: 60.16760758123155
Learned parameters: [2.1272154683354523, 3.834487571345511, 5.755546396807398, -2.6733687199465503]
Epoch: 5212  loss: 60.1674213937695
Learned parameters: [2.1271899578720825, 3.8345231470676833, 5.755597676555031, -2.673438286100616]
Epoch: 5213  loss: 60.16723581801817
Learned parameters: [2.127164482838439, 3.8345586733153274, 5.755648885060676, -2.6735077555518334]
Epoch: 5214  loss: 60.16705085227522
Learned parameters: [2.127139043206558, 3.8345941501277134, 5.755700022380779, -2.6735771283769765]
Epoch: 5215  loss: 60.16686649484454
Learned parameters: [2.1271136389484546, 3.8346295775441246, 5.755751088571776, -2.673646404652831]
Epoch: 5216  loss: 60.16668274403364
Learned parameters: [2.127088270036045, 3.834664955603866, 5.75580208368997, -2.673715584456174]
Epoch: 5217  loss: 60.16649959814924
Learned parameters: [2.1270629364413516, 3.8347002843462104, 5.75585300779182, -2.6737846678638006]
Epoch: 5218  loss: 60.16631705550457
Learned parameters: [2.127037638136368, 3.8347355638104514, 5.755903860933764, -2.6738536549525156]
Epoch: 5219  loss: 60.16613511442024
Learned parameters: [2.1270123750929897, 3.8347707940359195, 5.755954643172126, -2.673922545799124]
Epoch: 5220  loss: 60.16595377321559
Learned parameters: [2.1269871472832826, 3.834805975061916, 5.756005354563485, -2.673991340480467]
Epoch: 5221  loss: 60.16577303021748
Learned parameters: [2.1269619546791234, 3.834841106927802, 5.756055995164178, -2.674060039073373]
Epoch: 5222  loss: 60.165592883750676
Learned parameters: [2.126936797252483, 3.8348761896729298, 5.756106565030691, -2.6741286416546957]
Epoch: 5223  loss: 60.16541333214859
Learned parameters: [2.126911674975365, 3.8349112233366554, 5.756157064219577, -2.6741971483013063]
Epoch: 5224  loss: 60.16523437374592
Learned parameters: [2.1268865878196226, 3.8349462079583847, 5.756207492787199, -2.674265559090067]
Epoch: 5225  loss: 60.16505600688501
Learned parameters: [2.126861535757269, 3.8349811435774965, 5.7562578507901625, -2.6743338740978753]
Epoch: 5226  loss: 60.16487822990804
Learned parameters: [2.1268365187602063, 3.8350160302334086, 5.756308138284934, -2.6744020934016253]
Epoch: 5227  loss: 60.16470104116132
Learned parameters: [2.1268115368003504, 3.8350508679655464, 5.756358355328024, -2.6744702170782255]
Epoch: 5228  loss: 60.164524438997596
Learned parameters: [2.126786589849661, 3.8350856568133347, 5.75640850197602, -2.6745382452046043]
Epoch: 5229  loss: 60.16434842176665
Learned parameters: [2.1267616778800136, 3.8351203968162295, 5.756458578285411, -2.6746061778576897]
Epoch: 5230  loss: 60.16417298783145
Learned parameters: [2.126736800863339, 3.8351550880136815, 5.756508584312783, -2.674674015114433]
Epoch: 5231  loss: 60.16399813554948
Learned parameters: [2.126711958771569, 3.83518973044515, 5.756558520114745, -2.674741757051797]
Epoch: 5232  loss: 60.16382386329025
Learned parameters: [2.1266871515765415, 3.8352243241501256, 5.756608385747789, -2.6748094037467456]
Epoch: 5233  loss: 60.16365016942
Learned parameters: [2.1266623792502126, 3.8352588691680762, 5.756658181268595, -2.6748769552762743]
Epoch: 5234  loss: 60.16347705231209
Learned parameters: [2.126637641764454, 3.8352933655384978, 5.756707906733742, -2.67494441171738]
Epoch: 5235  loss: 60.163304510343366
Learned parameters: [2.1266129390911246, 3.8353278133008954, 5.7567575621998115, -2.675011773147073]
Epoch: 5236  loss: 60.16313254189262
Learned parameters: [2.126588271202138, 3.835362212494766, 5.75680714772348, -2.6750790396423847]
Epoch: 5237  loss: 60.16296114534545
Learned parameters: [2.126563638069349, 3.8353965631596276, 5.7568566633613605, -2.6751462112803552]
Epoch: 5238  loss: 60.16279031908748
Learned parameters: [2.1265390396646184, 3.8354308653349998, 5.756906109170094, -2.67521328813804]
Epoch: 5239  loss: 60.162620061509905
Learned parameters: [2.126514475959842, 3.8354651190603994, 5.7569554852063884, -2.6752802702925145]
Epoch: 5240  loss: 60.16245037100835
Learned parameters: [2.1264899469268133, 3.835499324375372, 5.757004791526827, -2.675347157820855]
Epoch: 5241  loss: 60.16228124597955
Learned parameters: [2.1264654525374405, 3.83553348131938, 5.757054028188137, -2.675413950800168]
Epoch: 5242  loss: 60.162112684826305
Learned parameters: [2.126440992763558, 3.8355675899318826, 5.757103195246946, -2.675480649307566]
Epoch: 5243  loss: 60.16194468595511
Learned parameters: [2.1264165675770106, 3.835601650252349, 5.7571522927599155, -2.6755472534201736]
Epoch: 5244  loss: 60.161777247776
Learned parameters: [2.1263921769496643, 3.835635662320257, 5.757201320783762, -2.675613763215135]
Epoch: 5245  loss: 60.16161036869916
Learned parameters: [2.1263678208533077, 3.835669626175119, 5.757250279375113, -2.675680178769594]
Epoch: 5246  loss: 60.1614440471434
Learned parameters: [2.12634349925983, 3.8357035418564345, 5.757299168590759, -2.6757465001607232]
Epoch: 5247  loss: 60.161278281525725
Learned parameters: [2.126319212141012, 3.83573740940375, 5.757347988487362, -2.6758127274656918]
Epoch: 5248  loss: 60.16111307027161
Learned parameters: [2.126294959468674, 3.8357712288566264, 5.757396739121668, -2.6758788607616895]
Epoch: 5249  loss: 60.16094841180649
Learned parameters: [2.1262707412146766, 3.835805000254625, 5.757445420550496, -2.675944900125924]
Epoch: 5250  loss: 60.16078430456208
Learned parameters: [2.1262465573507305, 3.8358387236373535, 5.757494032830475, -2.676010845635593]
Epoch: 5251  loss: 60.160620746969535
Learned parameters: [2.1262224078487484, 3.8358723990443777, 5.757542576018533, -2.6760766973679364]
Epoch: 5252  loss: 60.16045773747051
Learned parameters: [2.1261982926804595, 3.8359060265153175, 5.757591050171362, -2.6761424554001803]
Epoch: 5253  loss: 60.160295274504215
Learned parameters: [2.126174211817653, 3.835939606089785, 5.75763945534575, -2.676208119809572]
Epoch: 5254  loss: 60.160133356515885
Learned parameters: [2.126150165232174, 3.8359731378073785, 5.75768779159858, -2.676273690673377]
Epoch: 5255  loss: 60.159971981952495
Learned parameters: [2.1261261528957363, 3.836006621707736, 5.757736058986567, -2.6763391680688553]
Epoch: 5256  loss: 60.159811149265494
Learned parameters: [2.1261021747801685, 3.836040057830473, 5.7577842575666045, -2.6764045520732975]
Epoch: 5257  loss: 60.15965085691186
Learned parameters: [2.1260782308572237, 3.836073446215228, 5.7578323873954975, -2.6764698427639964]
Epoch: 5258  loss: 60.15949110335111
Learned parameters: [2.1260543210986675, 3.836106786901644, 5.757880448530085, -2.6765350402182606]
Epoch: 5259  loss: 60.15933188704432
Learned parameters: [2.1260304454762737, 3.836140079929365, 5.757928441027235, -2.676600144513414]